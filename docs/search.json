[
  {
    "objectID": "01-introductions.html",
    "href": "01-introductions.html",
    "title": "Welcome to the course!",
    "section": "",
    "text": "Welcome to Intermediate Data Science! I’m thrilled to be your partners in journeying this brand new (!) course in MSCS.\nOur goals for today are as follows:\n\nWhat is this course about?\nGet to know your classmates\nShaping our syllabus together\nCreate your personal website!\n\nWebsite content building + connecting with classmates\n\n\nWe’ll primarily be using slides today–following along here."
  },
  {
    "objectID": "02-adv-ggplot.html",
    "href": "02-adv-ggplot.html",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nNavigate the ggplot2 reference page to find the functions needed to create a desired visualization\nUse the information on a function help page to construct desired plot features\n\nScan the information in the Usage section to identify function arguments that must be set\nUnderstand how the function arguments work by using information in the Arguments section\nUse the information in the the Aesthetics and Examples sections to control plot appearance\n\nIdentify when it would be necessary to use different data arguments within the ggplot() and geom_() layers\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)"
  },
  {
    "objectID": "02-adv-ggplot.html#pair-programming-background",
    "href": "02-adv-ggplot.html#pair-programming-background",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "Pair programming background",
    "text": "Pair programming background\nIn pair programming, two individuals use one computer and work together to solve the problem at hand. Each individual takes turns in one of two roles:\n\nDriver: The Driver is at the computer typing and speaking their thought process out loud.\nNavigator: The Navigator reviews all code that the Driver writes as it’s typed, guides the overall direction of the code (keeps the instructions in mind), and pulls up references.\n\nWhy are we using pair programming? Pair programming is used effectively in industry to speed up individual employee’s learning of a company’s codebase and reduce time wasted on fixing bugs."
  },
  {
    "objectID": "02-adv-ggplot.html#your-task",
    "href": "02-adv-ggplot.html#your-task",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "Your task",
    "text": "Your task\nBefore diving in to plot creation, get to know your partner by telling each other about the general themes in your 12 favorite problems (FPs). Try to find some overlap in your themes and share one of your FPs that relates to that overlapping theme.\nWork together until your precipitation plot looks as below.\n\nThe culmPrec variable contains cumulative precipitation for the month up to the given day.\nThe recordP variable is a TRUE/FALSE indicator of whether a day was a precipitation record. These are marked by the downward pointing triangles.\nThe numbers on the plot indicate the total precipitation for the month. Do some searching about the hjust and vjust options to adjust the alignment of the numbers.\nThe blue and tan colors are \"#32a3d8\" and \"#ebeae2\".\n\n\n\n\n\n\n\n\n\n\nWhen should the Driver and Navigator switch roles? For this exercise, you will switch roles once a particular plot layer (one geom) has been implemented correctly. You can send code back and forth via email or a direct message on Slack.\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nAs you pair program, be aware of your comforts and discomforts in the roles of driver and navigator. Pay attention to the comforts and discomforts of your partner. What could you do to support them in becoming more comfortable and confident in both roles?\n\n\n\n\n\n\n\n\n\nRecord Errors\n\n\n\n\n\nEvery time you run into a new error, record the error message and your process for fixing the error in the “Error Log” section of the Quarto file for these exercises."
  },
  {
    "objectID": "03-adv-maps.html",
    "href": "03-adv-maps.html",
    "title": "Advanced Spatial Visualizations",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nUnderstand the basics of a CRS (coordinate reference system)\nUnderstand and recognize different spatial file types and data types in R\nImplement some of the basic plotting with the sf package\nUnderstand foundational ideas in working with spatial data (aggregating spatial point data to a spatial region, joining spatial data sets)\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)\n\nYou can download a template Quarto file to start from here. Put this file in an activities folder within a folder for this course."
  },
  {
    "objectID": "03-adv-maps.html#ellipsoid",
    "href": "03-adv-maps.html#ellipsoid",
    "title": "Advanced Spatial Visualizations",
    "section": "Ellipsoid",
    "text": "Ellipsoid\nWhile you might have learned that the Earth is a sphere, it is actually closer to an ellipsoid with a bulge at the equator. Additionally, the surface is irregular and not smooth. To define a CRS, we first need to choose a mathematical model represent a smooth approximation to the shape of the Earth. The common ellipsoid models are known as WGS84 and GRS80. See the illustration below of one ellipsoid model (shown in black) as compared to Earth’s true irregular surface (shown in red).\n\n\n\nIllustration of ellipsoid model and Earth’s irregular surface, centered to have an overall best fit. Source: www.icsm.gov.au"
  },
  {
    "objectID": "03-adv-maps.html#datum",
    "href": "03-adv-maps.html#datum",
    "title": "Advanced Spatial Visualizations",
    "section": "Datum",
    "text": "Datum\nEach ellipsoid model has different ways to position it self relative to Earth depending on the center or origin. Each potential position and reference frame for representing the position of locations on Earth is called a datum.\nFor example, two different datum for the same ellipsoid model can provide a more accurate fit or approximation of the Earth’s surface depending on the region of interest (South America v. North America). For example, the NAD83 datum is a good fit for the GRS80 ellipsoid in North America, but SIRGAS2000 is a better fit for the GRS80 ellipsoid in South America. The illustration below shows one datum in which the center of the ellipsoid does not coincide with the center of Earth’s mass. With this position of the ellipsoid, we gain a better fit for the southern half of the Earth.\n\n\n\nIllustration of ellipsoid model and Earth’s irregular surface for a datum that better fits southern part (bottom right) of the Earth. Source: www.icsm.gov.au\n\n\nIt is useful to know that the Global Positioning System (GPS) uses the WGS84 ellipsoid model and a datum by the same name, which provides an overall best fit of the Earth.\nIf you have longitude and latitude coordinates for a location, it is important to know what datum and ellipsoid were used to define those positions.\nNote: In practice, the horizontal distance between WGS84 and NAD83 coordinates is about 3-4 feet in the US, which may not be significant for most applications.\n\nExercise 1\nGo to https://epsg.io/. Search for a location important to you (state, country, etc.). Filter based on Datum (Geodetic) on the right. Click on one geodetic datum option for your region of interest. Make sure your location is listed under the “Area of use” attribute.\nProvide the region of interest (e.g. United States), the full datum name (e.g. North American Datum 1983), the shorthand name (e.g. NAD83, EPSG: 6269), and the ellipsoid (e.g. GRS 1980).\n\nLocation:\n\n\n\nExample Solution\n\n\nLocation 1: South Africa, Cape, EPSG:6222, Ellipsoid: Clarke 1880 (Arc)\n\n\nLocation 2: Thailand, Indian 1975, EPSG:6240, Ellipsoid: Everest 1830 (1937 Adjustment)\n\n\nLocation 3: Colombia, Marco Geocentrico Nacional de Referencia, EPSG:6686, Ellipsoid: GRS 1980\n\n\n\n\nExercise 2\nLet’s now practice specifying coordinates in a CRS.\nFor geographic coordinate reference systems, the coordinates of locations are specified by latitude (degrees, minutes, and seconds north or south of the equator), longitude (degrees, minutes, and seconds west or east of a prime meridian), and sometimes height.\nUse the “Get position on a map” feature of https://epsg.io/ to locate the Olin-Rice Science Center at Macalester. The two boxes at the top allow you to specify a longitude (left box) and latitude (right box) in degrees. Enter the following to focus OLRI:\n\nLongitude: -93.168855\nLatitude: 44.936611\n\nFor projected coordinate reference systems, the coordinates of locations are typically specified by easting (x) and northing (y).\nClick the “Transform” button at the top to find the location of OLRI in northing and easting coordinates (in meters) for the CRS EPSG:26993.\n\nEasting:\nNorthing:\n\n\n\nSolution\n\n\nEasting: 865601.0163401571\nNorthing: 315516.10931633075"
  },
  {
    "objectID": "03-adv-maps.html#projection",
    "href": "03-adv-maps.html#projection",
    "title": "Advanced Spatial Visualizations",
    "section": "Projection",
    "text": "Projection\nLastly, the Earth lives in a 3 dimensional (3D) world and most visualizations are on a 2 dimensional (2D) surface. We must choose a projection method to represent points, regions, and lines on Earth on a 2D map with distance units (typically meter, international foot, US survey foot). In that projection process, a 3D element will lose angle, area, and/or distance when projected onto a 2D surface, no matter which method is chosen.\nFor a good overview of common projection methods, see https://pubs.usgs.gov/gip/70047422/report.pdf.\nOne of the most commonly used projection is the Mercator projection which is a cylindrical map projection from the 1500’s. It became popular for navigation because it represented north as up and south as down everywhere and preserves local directions and shape. However, it inflates the size of regions far from the equator. Thus, Greenland, Antarctica, Canada, and Russia appear large relative to their actual land mass as compared to Central Africa. See the illustration below to compare the area/shape of the countries with the Mercator projection of the world (light blue) with the true areas/shapes (dark blue).\n\n\n\nSource: @neilrkaye\n\n\nBelow you can see four different world projections. Take note of what is lost in terms of angle, area, or distance in these projections.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Basic Map w/ labels\nggplot(data = world) + \n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    labs(x = \"Longitude\", y = \"Latitude\", title = \"World Map - Mercator Projection\", subtitle = paste0(\"(\", length(unique(world$name)), \" countries)\")) +\n    theme_bw() \n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs\") + \n    labs(title = \"Lambert Azimuthal Equal-Area Projection\", subtitle = \"Correctly represents area but not angles\") + \n    theme_bw()\n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=fouc\") + \n    labs(title = \"Foucaut Projection\", subtitle = \"Correctly represents area, lots of shape distortion in high latitudes\") + \n    theme_bw() \n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=natearth2\") + \n    labs(title = \"Natural Earth II Projection\", subtitle = \"Represents globe shape, distorted at high latitudes\") + \n    theme_bw()\n\n\n\n\n\nExercise 3\nCreate a world map with a different projection (beyond the four above). Go to https://proj.org/en/9.2/operations/projections/index.html and find another projection. Look for the proj-string and copy that to the crs = argument in coord_sf().\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"??\") + \n    labs(title = \"?? Projection\", subtitle = \"??\") + \n  theme_bw() \n\nWhat is interesting, surprising, or different to you about the map of the Earth based on this projection?\n\nANSWER:\n\nTalk with a neighbor about the projection they tried. What projection did they use and how is it different from the one you chose?\n\nANSWER:\n\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nIf coordinate reference systems are new to you, how do you feel about all of this new information? What are the most important points to take away? What are the documents and sites you can refer back to when you need more details?\nWhen you learn about a new area of study, it can feel overwhelming. Pick out the 3-5 priority ideas to help you organize all of the details."
  },
  {
    "objectID": "03-adv-maps.html#data-models",
    "href": "03-adv-maps.html#data-models",
    "title": "Advanced Spatial Visualizations",
    "section": "Data Models",
    "text": "Data Models\n\nVector\nVector data represents the world as a set of spatial geometries that are defined in terms of location coordinates (with a specified CRS) with non-spatial attributes or properties.\nThe three basic vector geometries are\n\nPoints: Locations defined based on a (x, y) coordinates.\nLines: A set of ordered points connected by straight lines.\nPolygons: A set of ordered points connected by straight lines, first and last point are the same.\n\nFor example, city locations can be represented with points, roads and rivers can be represented by lines, and geo-political boundaries and lakes can be represented by polygons.\nHundreds of file formats exist to store spatial vector data. A text file (such as .csv) can store the coordinates in two columns (x,y) in addition to a group id (needed for lines and polygons) plus attributes or properties in additional columns. Note that text files do not store the CRS. However, shapefiles (.shp) developed by ESRI is one of the most widely supported spatial vector file format (that includes the CRS). Additionally, GeoJSON (.geojson) and KML (.kml) are additional popular formats.\n\n\nExercise 4\nTo create maps, we’ll need to have access to some spatial data.\nGo to the following websites and download the vector data files indicated. Put all of the downloaded files/folders in same folder as this Rmd file.\n\nURL: https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map\n\nDownload File Type: GeoJSON\nName of File: us_states_hexgrid.geojson\n\nURL: https://www2.census.gov/programs-surveys/decennial/2020/data/apportionment/apportionment.csv\n\nDownload File Type: csv\nName of File: apportionment.csv\n\nURL: https://gisdata.mn.gov/dataset/loc-pop-centers\n\nDownload File Type: shapefile (.shp)\nName of File: shp_loc_pop_centers.zip (unzip this file to get a folder with the name shp_loc_pop_centers)\n\nURL: https://gisdata.mn.gov/dataset/us-mn-state-metc-water-lakes-rivers\n\nDownload File Type: shapefile (.shp)\nName of File: shp_water_lakes_rivers.zip (unzip this file to get a folder with the name shp_water_lakes_rivers)\n\n\n\n\nRaster\nRaster data represents the world using a continuous grid of cells where each cell has a single value. These values could be continuous (e.g., elevation, precipitation) or categorical (e.g., land cover type, soil type).\nTypically regular cells are square in shape but they can be rotated and sheared. Rectilinear and curvilinear shapes are also possible, depending on the spatial region of interest and CRS.\n\n\n\nDifference between vector and raster formats. Source: gis.stackexchange.com\n\n\nBe aware that high resolution raster data involves a large number of small cells. This can slow down the computations and visualizations.\nMany raster file formats exist. One of the most popular is GeoTIFF (.tif or .tiff). More complex raster formats include NetCDF (.nc) and HDF (.hdf). To work with raster data in R, you’ll use the raster, terra, and the stars packages. If you are interested in learning more, check out https://r-spatial.github.io/stars/."
  },
  {
    "objectID": "03-adv-maps.html#working-with-spatial-data-in-r",
    "href": "03-adv-maps.html#working-with-spatial-data-in-r",
    "title": "Advanced Spatial Visualizations",
    "section": "Working with Spatial Data in R",
    "text": "Working with Spatial Data in R\n\nRead data into R\nFor each file format, we need to use a different function to read in the data. See the examples below for reading in GeoJSON, CSV, and shapefiles.\n\n# Read in GeoJSON file\nhex_spatial &lt;- geojsonio::geojson_read(\"data/us_states_hexgrid.geojson\", what = \"sp\") \n\n# Read in CSV File\npop_growth &lt;- readr::read_csv(\"data/apportionment.csv\") %&gt;% janitor::clean_names()\n\n# Read in Shapefiles\nmn_cities &lt;- sf::read_sf(\"data/shp_loc_pop_centers\") #shp file/folder\nmn_water &lt;- sf::read_sf(\"data/shp_water_lakes_rivers\") #shp file/folder\n\n\n\nData classes in R\nWhen data is read in, an R data object is created of a default class. Notice the classes of the R objects we read in. Also, notice that an object may have multiple classes, which indicate the type of structure it has and how functions may interact with the object.\n\nclass(hex_spatial)\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\nclass(pop_growth)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nclass(mn_cities)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(mn_water)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nOlder R Spatial classes\nIn the sp package, there are many spatial classes that hold slightly different data. All Spatial* classes have a bounding box (bbox) and a CRS.\n\nSpatialPoints, SpatialLines, and SpatialPolygons provide structure to hold the basic spatial geometries of points, lines, and polygons.\nSpatial*DataFrame extends the geometry classes to a data.frame-like object with non-spatial attribute data.\n\n\n\nExercise 5\nWe can look at the first bit of the hex_spatial object to get a sense for how information in the object is organized:\n\nhead(hex_spatial,1)\n\nAn object of class \"SpatialPolygonsDataFrame\"\nSlot \"data\":\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n            google_name\n1 Maine (United States)\n\nSlot \"polygons\":\n[[1]]\nAn object of class \"Polygons\"\nSlot \"Polygons\":\n[[1]]\nAn object of class \"Polygon\"\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"area\":\n[1] 15.28454\n\nSlot \"hole\":\n[1] FALSE\n\nSlot \"ringDir\":\n[1] 1\n\nSlot \"coords\":\n          [,1]     [,2]\n[1,] -72.62574 55.31320\n[2,] -69.90286 54.40843\n[3,] -69.90286 52.53744\n[4,] -72.62574 51.57081\n[5,] -75.34861 52.53744\n[6,] -75.34861 54.40843\n[7,] -72.62574 55.31320\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"ID\":\n[1] \"1\"\n\nSlot \"area\":\n[1] 15.28454\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"bbox\":\n        min       max\nx -75.34861 -69.90286\ny  51.57081  55.31320\n\nSlot \"proj4string\":\nCoordinate Reference System:\nDeprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs \nWKT2 2019 representation:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]] \n\n\nBased on this information, fill in the following:\n\nCRS:\nBBOX (extent):\nGeometry type:\n\n\n\nSolution\n\n\nCRS: EPSG:4326 (+proj=longlat +datum=WGS84 +no_defs) (From Slot \"proj4string\": Coordinate Reference System:)\nBBOX: x -75.34861 -69.90; y 51.57 55.31 (From Slot \"bbox\")\nGeometry type: Polygons (Inferred from An object of class \"SpatialPolygonsDataFrame\" and class \"Polygon\")\n\n\nNewer R Spatial classes\nThe community is moving away from using older sp classes to sf classes. It is useful for you to know that the older versions exist, but we will stick with the sf classes.\n\nsfc objects are modern, general versions of the spatial geometries from the sp package with a bbox, CRS, and many geometries available.\nsf objects are data.frame-like objects with a geometry column of class sfc.\n\n\nmn_cities\n\nSimple feature collection with 1081 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nProjected CRS: NAD83 / UTM zone 15N\n# A tibble: 1,081 × 9\n      GNIS Name        CTU_Type County      FIPS_Code Sym_Class Population Notes\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;\n 1 2393879 Ada         City     Norman Cou… 27107001… County S…       1681 &lt;NA&gt; \n 2 2393881 Adams       City     Mower Coun… 27099001… Small Ci…        742 &lt;NA&gt; \n 3 2393884 Adrian      City     Nobles Cou… 27105002… Small Ci…       1278 &lt;NA&gt; \n 4 2393887 Afton       City     Washington… 27163003… Small Ci…       2932 &lt;NA&gt; \n 5 2393894 Aitkin      City     Aitkin Cou… 27001004… County S…       2279 &lt;NA&gt; \n 6 2393895 Akeley      City     Hubbard Co… 27057004… Small Ci…        397 &lt;NA&gt; \n 7 2393898 Albany      City     Stearns Co… 27145006… Small Ci…       2618 &lt;NA&gt; \n 8 2393902 Albert Lea  City     Freeborn C… 27047006… County S…      17843 &lt;NA&gt; \n 9 2393903 Alberta     City     Stevens Co… 27149006… Small Ci…        122 &lt;NA&gt; \n10 2393904 Albertville City     Wright Cou… 27171007… Small Ci…       7226 &lt;NA&gt; \n# ℹ 1,071 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\n\n\nExercise 6\nBased on the summary of mn_cities, what are the following:\n\nCRS:\nBBOX:\nGeometry type:\n\n\n\nSolution\n\n\nCRS: NAD83 / UTM zone 15N\nBBOX: xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nGeometry type: Points\n\n\nPutting spatial data into a data.frame with fortify()\nThe data.frame and tbl (tibble) classes are standard data formats that are not specific to spatial data but are really nice for working with because of tidyverse. Our pop_growth data doesn’t include any coordinate information, so it can be stored simply as a data.frame (tbl, tbl_df, and spec_tbl_df are all subclasses of data.frame).\nYou may come across data.frames that contain spatial coordinate information, so let’s see what that might look like. We can fortify() our sp object (hex_spatial) to make it a data frame.\n\n# Convert Spatial*DataFrame to Data Frame\nhex_spatial_df &lt;- fortify(hex_spatial)\nclass(hex_spatial_df)\n\n[1] \"data.frame\"\n\n\n\n\nExercise 7\nWhenever we come across a new function (fortify), it is helpful to explore the structure of information contained within the object that it creates.\nWhat are the variables in hex_spatial_df? Compare the first seven rows with the first spatial polygon of hex_spatial. Using this comparison describe the meaning of the variables in hex_spatial_df. (piece, id, and group are trickier. We’ll talk about this together.)\n\n# Display the first 7 rows of hex_spatial_df\nhead(hex_spatial_df,7)\n\n       long      lat order  hole piece id group\n1 -72.62574 55.31320     1 FALSE     1  1   1.1\n2 -69.90286 54.40843     2 FALSE     1  1   1.1\n3 -69.90286 52.53744     3 FALSE     1  1   1.1\n4 -72.62574 51.57081     4 FALSE     1  1   1.1\n5 -75.34861 52.53744     5 FALSE     1  1   1.1\n6 -75.34861 54.40843     6 FALSE     1  1   1.1\n7 -72.62574 55.31320     7 FALSE     1  1   1.1\n\n# Look at the first polygon in the hex_spatial object (Maine)\nhex_spatial@polygons[[1]]\n\nAn object of class \"Polygons\"\nSlot \"Polygons\":\n[[1]]\nAn object of class \"Polygon\"\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"area\":\n[1] 15.28454\n\nSlot \"hole\":\n[1] FALSE\n\nSlot \"ringDir\":\n[1] 1\n\nSlot \"coords\":\n          [,1]     [,2]\n[1,] -72.62574 55.31320\n[2,] -69.90286 54.40843\n[3,] -69.90286 52.53744\n[4,] -72.62574 51.57081\n[5,] -75.34861 52.53744\n[6,] -75.34861 54.40843\n[7,] -72.62574 55.31320\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"ID\":\n[1] \"1\"\n\nSlot \"area\":\n[1] 15.28454\n\n\n\nANSWER:\n\n\n\nSolution\n\n\nVariables: long, lat, order, hole, piece, id, group\n\n\nlong and lat provide the x and y coordinates of the polygon for a particlar region or area id.\n\n\nThe order is the order in which you connect the coordinate points to make a polygon.\n\n\nhole indicates whether or not it should be included or excluded in the region as a hole.\n\n\npiece indicates the number of the polygon for an individual area\n\n\nid is a unique identifier for each polygon and allows linking to the original spatial object (hex_spatial). (There is a Slot \"ID\" part of the object.)\n\n\ngroup indicates which pieces belong to the same group or should be plotted together as a single entity. This can be useful when you want to apply different aesthetics (e.g., colors, linetypes) to different groups of polygons within your spatial object. It helps in specifying how to group and style the different pieces when creating plots.\n\n\n\n\nConverting between data classes\nSometimes functions for working with spatial data will only work on an object that is of a particular class (e.g., only works on sf objects). If we have an object of a different class, we need to know how to convert it to the right class.\nWe can convert objects between these data classes with the following functions:\n\nfortify(x): sp object x to data.frame\nst_as_sf(x): sp object x to sf\nst_as_sf(x, coords = c(\"long\", \"lat\")): data.frame x to sf as points\nTo convert a data.frame with columns of long, lat, and group containing polygon geometry information, you can use:\n\n\nst_as_sf(x, coords = c(\"long\", \"lat\")) %&gt;%\n    group_by(group) %&gt;%\n    summarise(geometry = st_combine(geometry)) %&gt;%\n    st_cast(\"POLYGON\")\n\n(Note: We won’t often want to convert our data to a Spatial* class from sp package, so we’ll exclude that in this activity.)\n\n\nExercise 8\nConvert the hex_spatial data to an sf object called hex_spatial_sf. Complete these two ways\n\nhex_spatial directly to hex_spatial_sf AND\nhex_spatial_df to hex_spatial_sf.\n\n\n# Convert to SF from hex_spatial_df  \nhex_spatial_sf &lt;- hex_spatial_df %&gt;% ???  \n  \n# Convert to SF from hex_spatial\nhex_spatial_sf &lt;- hex_spatial %&gt;% ???\n\n\n\nSolution\n\n\n# Convert to SF from hex_spatial_df  \nhex_spatial_sf &lt;- hex_spatial_df %&gt;%\n    st_as_sf(coords = c(\"long\", \"lat\")) %&gt;%\n    group_by(group) %&gt;%\n    summarise(geometry = st_combine(geometry)) %&gt;%\n    st_cast(\"POLYGON\") \n  \n# Convert to SF from hex_spatial\nhex_spatial_sf &lt;- hex_spatial %&gt;% st_as_sf()\n\n\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWe’ve now talked about CRSs and how spatial data is stored in R. Thinking on the lesson so far as a whole…\n\nWhat’s making sense? What’s not?\nWhat would help connect everything we’ve talked about?\n\nRecord observations in your Process and Reflection Log.\nShare your observations with your partner. Together try to figure out what themes emerge in what you’re still working on. Then try to come up with strategies that can help you move forward.\nExample themes: What is the “why” behind this? What is the full picture/pipeline/how this is used in practice?\nExample strategies: writing condensed summaries, drawing concept maps"
  },
  {
    "objectID": "03-adv-maps.html#hexbin-choropleth",
    "href": "03-adv-maps.html#hexbin-choropleth",
    "title": "Advanced Spatial Visualizations",
    "section": "Hexbin Choropleth",
    "text": "Hexbin Choropleth\nData Source: https://r-graph-gallery.com/328-hexbin-map-of-the-usa.html\nIn this example, we’ll create an alternative choropleth map. Instead of using the actual geo-political boundaries, we will use hexagons to represent the U.S. states and maintain their relative directional position to each together. This approach results in each state having the same area in the graphic so that large regions don’t dominate the visual story.\n\nExercise 9\nDescribe what the following code chunks are doing. Be sure to consider the class of the data object, what the data object looks like to start, and what it looks like at the end of the chunk.\n\n# Chunk A\nhex_spatial_df  &lt;- hex_spatial_df %&gt;% \n  left_join(\n        data.frame(id = as.character(1:nrow(hex_spatial)) , \n        name = str_replace(hex_spatial$google_name,' \\\\(United States\\\\)',''), \n        abbr = hex_spatial$iso3166_2))\n\n\nANSWER (Chunk A):\n\n\n\nSolution\n\n\n# Chunk A\nhead(hex_spatial_df) # Start with data frame of 357 rows and 7 columns\n\n       long      lat order  hole piece id group\n1 -72.62574 55.31320     1 FALSE     1  1   1.1\n2 -69.90286 54.40843     2 FALSE     1  1   1.1\n3 -69.90286 52.53744     3 FALSE     1  1   1.1\n4 -72.62574 51.57081     4 FALSE     1  1   1.1\n5 -75.34861 52.53744     5 FALSE     1  1   1.1\n6 -75.34861 54.40843     6 FALSE     1  1   1.1\n\nhex_spatial_df  &lt;- hex_spatial_df %&gt;% \n  left_join( # Left join, a mutating join, a dataset with information from hex_spatial\n        data.frame(id = as.character(1:nrow(hex_spatial)) , # Create a data frame with variables id (1,2,3...), name (defined as the google_name from hex_spatial after removing \"(United States)\"), and abbr (the state abbreviation in hex_spatial as variable iso3166_2)\n        name = str_replace(hex_spatial$google_name,' \\\\(United States\\\\)',''), \n        abbr = hex_spatial$iso3166_2))\n\nhead(hex_spatial_df) # End with data frame of 357 rows and 9 columns (new: name and abbr)\n\n       long      lat order  hole piece id group  name abbr\n1 -72.62574 55.31320     1 FALSE     1  1   1.1 Maine   ME\n2 -69.90286 54.40843     2 FALSE     1  1   1.1 Maine   ME\n3 -69.90286 52.53744     3 FALSE     1  1   1.1 Maine   ME\n4 -72.62574 51.57081     4 FALSE     1  1   1.1 Maine   ME\n5 -75.34861 52.53744     5 FALSE     1  1   1.1 Maine   ME\n6 -75.34861 54.40843     6 FALSE     1  1   1.1 Maine   ME\n\n\n\n\n# Chunk B\nhex_spatial_sf &lt;- hex_spatial_sf %&gt;% \n    mutate(\n        name = str_replace(google_name,' \\\\(United States\\\\)',''),\n        abbr = iso3166_2\n    )\n\n\nANSWER (Chunk B):\n\n\n\nSolution\n\n\n# Chunk B\n\nhead(hex_spatial_sf) # Start with sf object with 51 regions and 7 variables/features\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -113.4688 ymin: 30.53798 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1217 2015-05-13 17:24:35 2015-10-05 11:00:16  R.I. 47.8        RI\n3       1218 2015-05-13 17:25:00 2015-10-05 11:00:16   Vt. 33.9        VT\n4        231 2015-05-13 17:02:22 2015-10-05 11:00:16 Okla. 63.4        OK\n5        244 2015-05-13 17:02:22 2015-10-05 11:00:16  N.C. 41.5        NC\n6        259 2015-05-13 17:02:22 2015-10-05 11:00:16   Va. 45.6        VA\n                     google_name                       geometry\n1          Maine (United States) POLYGON ((-72.62574 55.3132...\n2   Rhode Island (United States) POLYGON ((-72.62574 49.5743...\n3        Vermont (United States) POLYGON ((-80.79436 52.5374...\n4       Oklahoma (United States) POLYGON ((-110.746 35.79821...\n5 North Carolina (United States) POLYGON ((-91.68585 39.5301...\n6       Virginia (United States) POLYGON ((-88.96298 43.0717...\n\nhex_spatial_sf &lt;- hex_spatial_sf %&gt;% # Create new variables: name (defined as the google_name after removing \"(United States)\"), and abbr (the state abbreviation from variable iso3166_2)\n    mutate(\n        name = str_replace(google_name,' \\\\(United States\\\\)',''),\n        abbr = iso3166_2\n    )\n\nhead(hex_spatial_sf) # Ends with sf object with 51 regions and 9 variables/features\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -113.4688 ymin: 30.53798 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1217 2015-05-13 17:24:35 2015-10-05 11:00:16  R.I. 47.8        RI\n3       1218 2015-05-13 17:25:00 2015-10-05 11:00:16   Vt. 33.9        VT\n4        231 2015-05-13 17:02:22 2015-10-05 11:00:16 Okla. 63.4        OK\n5        244 2015-05-13 17:02:22 2015-10-05 11:00:16  N.C. 41.5        NC\n6        259 2015-05-13 17:02:22 2015-10-05 11:00:16   Va. 45.6        VA\n                     google_name                       geometry           name\n1          Maine (United States) POLYGON ((-72.62574 55.3132...          Maine\n2   Rhode Island (United States) POLYGON ((-72.62574 49.5743...   Rhode Island\n3        Vermont (United States) POLYGON ((-80.79436 52.5374...        Vermont\n4       Oklahoma (United States) POLYGON ((-110.746 35.79821...       Oklahoma\n5 North Carolina (United States) POLYGON ((-91.68585 39.5301... North Carolina\n6       Virginia (United States) POLYGON ((-88.96298 43.0717...       Virginia\n  abbr\n1   ME\n2   RI\n3   VT\n4   OK\n5   NC\n6   VA\n\n\n\n\n# Chunk C\nhex_growth_df &lt;- left_join(hex_spatial_df, pop_growth, by = 'name')\nhex_growth_sf &lt;- left_join(hex_spatial_sf, pop_growth, by = 'name')\n\n\nANSWER (Chunk C):\n\n\n\nSolution\n\n\n# Chunk C\n\nhex_growth_df &lt;- left_join(hex_spatial_df, pop_growth, by = 'name') # Add in pop_growth variables to data frame using left_join; in the process duplicate the geometry for each region for each year\nhead(hex_growth_df)\n\n       long     lat order  hole piece id group  name abbr geography_type year\n1 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1910\n2 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1920\n3 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1930\n4 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1940\n5 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1950\n6 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1960\n  resident_population percent_change_in_resident_population\n1              742371                                   6.9\n2              768014                                   3.5\n3              797423                                   3.8\n4              847226                                   6.2\n5              913774                                   7.9\n6              969265                                   6.1\n  resident_population_density resident_population_density_rank\n1                        24.1                               33\n2                        24.9                               34\n3                        25.9                               36\n4                        27.5                               36\n5                        29.6                               37\n6                        31.4                               38\n  number_of_representatives change_in_number_of_representatives\n1                         4                                   0\n2                         4                                   0\n3                         3                                  -1\n4                         3                                   0\n5                         3                                   0\n6                         2                                  -1\n  average_apportionment_population_per_representative\n1                                              185593\n2                                              192004\n3                                              265806\n4                                              282409\n5                                              304591\n6                                              484633\n\ndim(hex_growth_df) # end with data frame of 4284 rows and 18 variables\n\n[1] 4284   18\n\nhex_growth_sf &lt;- left_join(hex_spatial_sf, pop_growth, by = 'name') # add in pop_growth variables to sf object using left join; in the process duplicate the geometry for each region for each year \nhead(hex_growth_sf)\n\nSimple feature collection with 6 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -75.34861 ymin: 51.57081 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n3       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n4       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n5       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n6       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n            google_name  name abbr geography_type year resident_population\n1 Maine (United States) Maine   ME          State 1910              742371\n2 Maine (United States) Maine   ME          State 1920              768014\n3 Maine (United States) Maine   ME          State 1930              797423\n4 Maine (United States) Maine   ME          State 1940              847226\n5 Maine (United States) Maine   ME          State 1950              913774\n6 Maine (United States) Maine   ME          State 1960              969265\n  percent_change_in_resident_population resident_population_density\n1                                   6.9                        24.1\n2                                   3.5                        24.9\n3                                   3.8                        25.9\n4                                   6.2                        27.5\n5                                   7.9                        29.6\n6                                   6.1                        31.4\n  resident_population_density_rank number_of_representatives\n1                               33                         4\n2                               34                         4\n3                               36                         3\n4                               36                         3\n5                               37                         3\n6                               38                         2\n  change_in_number_of_representatives\n1                                   0\n2                                   0\n3                                  -1\n4                                   0\n5                                   0\n6                                  -1\n  average_apportionment_population_per_representative\n1                                              185593\n2                                              192004\n3                                              265806\n4                                              282409\n5                                              304591\n6                                              484633\n                        geometry\n1 POLYGON ((-72.62574 55.3132...\n2 POLYGON ((-72.62574 55.3132...\n3 POLYGON ((-72.62574 55.3132...\n4 POLYGON ((-72.62574 55.3132...\n5 POLYGON ((-72.62574 55.3132...\n6 POLYGON ((-72.62574 55.3132...\n\ndim(hex_growth_sf) #end with sf object of 612 region/year combinations and 19 variables\n\n[1] 612  19\n\n\n\n\n# Chunk D\ncenters &lt;- data.frame(\n    rgeos::gCentroid(hex_spatial,byid = TRUE), \n    abbr = hex_spatial$iso3166_2\n)\n  \nhex_growth_df %&gt;% \n    filter(year == 2020) %&gt;%\n    ggplot(aes(x = long, y = lat)) +\n        geom_polygon(aes(group = group, fill = percent_change_in_resident_population)) + \n        geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') +\n        labs(fill = 'Population Change (%)') + \n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right')\n\n\nANSWER (Chunk D):\n\n\n\nSolution\n\n\n# Chunk D\ncenters &lt;- data.frame(\n    rgeos::gCentroid(hex_spatial,byid = TRUE), # Create data frame of the center of each region and the state abbreviation\n    abbr = hex_spatial$iso3166_2\n)\n  \nhex_growth_df %&gt;% \n    filter(year == 2020) %&gt;% # focus only on the data from 2020\n    ggplot(aes(x = long, y = lat)) + # create frame of longitude and latitude\n        geom_polygon(aes(group = group, fill = percent_change_in_resident_population)) +  # add hex polygons defined by x and y but grouped according to group and color filled by the percent_change in resident population\n        geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') + # add text at the centers of the polygons and add text labels from the abbr variable in the centers data we created\n        labs(fill = 'Population Change (%)') +  # change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\n\n\n\n# Chunk E\nhex_growth_sf %&gt;% \n    filter(year == 2020) %&gt;%\n    ggplot() +\n        geom_sf(aes(fill = percent_change_in_resident_population)) + \n        geom_sf_text( aes(label = abbr), color = 'white') +\n        labs(fill = 'Population Change (%)') + \n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right')\n\n\nANSWER (Chunk E):\n\n\n\nSolution\n\n\n# Chunk E\nhex_growth_sf %&gt;%  # start with sf object\n    filter(year == 2020) %&gt;% #filter to focus on data from 2020\n    ggplot() +\n        geom_sf(aes(fill = percent_change_in_resident_population)) + # plot the sf geometry (polygons) and fill color according to percent change in population\n        geom_sf_text( aes(label = abbr), color = 'white') + # add text labels to the sf geometry regions using abbr for the text\n        labs(fill = 'Population Change (%)') + # Change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right \n\n\n\n\n\n\n\nExercise 10\nUsing the hexbin spatial boundaries and the pop_growth data, make the following updates to the choropleth graphic:\n\nChange the outcome variable (different year or variable).\nChange the fill scale to be more meaningful and effective.\nMake one more update beyond the fill color to improve the effectiveness of the graphic.\n\nMake the graphic twice, once with geom_polygon() and once with geom_sf().\n\n\nExample Solution\n\n\nhex_growth_df %&gt;% \n    ggplot(aes(x = long, y = lat)) + # create frame of longitude and latitude\n        geom_polygon(aes(group = group, fill = change_in_number_of_representatives)) +  # add hex polygons defined by x and y but grouped according to group and color by change in number of representatives\n        # geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') + # add text at the centers of the polygons and add text labels from the abbr variable in the centers data we created\n        facet_wrap(~ year, ncol = 3) +\n        labs(fill = 'Population Change (%)') +  # change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\nhex_growth_sf %&gt;%  # start with sf object\n    ggplot() +\n        geom_sf(aes(fill = change_in_number_of_representatives)) + # plot the sf geometry (polygons) and fill color according to change in number of representatives\n        # geom_sf_text( aes(label = abbr), color = 'white') + # add text labels to the sf geometry regions using abbr for the text\n        facet_wrap(~ year, ncol = 3) +\n        labs(fill = 'Population Change (%)') + # Change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\n\n\n\n\nBonus Challenge\nFind external state-level data online, read it into R, join it, and create a U.S. state hexbin map displaying that new state-level outcome."
  },
  {
    "objectID": "03-adv-maps.html#mn-citycounty-example",
    "href": "03-adv-maps.html#mn-citycounty-example",
    "title": "Advanced Spatial Visualizations",
    "section": "MN City/County example",
    "text": "MN City/County example\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWhen looking through code examples, notice familiar functions and syntax patterns. Also, notice new functions and try figure out what they are doing.\nAdd comments to the code so that you can come back to the examples when you need them.\n\n\n\n\nUnifying CRSs across different spatial datasets\nTo demonstrate other spatial geometries beyond polygons (the hexagons in the last example were spatial polygons), we’ll walk through create a map of MN with different layers of information (city point locations, county polygon boundaries, rivers as lines and polygons, and a raster elevation map). To add all of this information on one map, we need to ensure that the CRS is the same for all spatial datasets.\n\n# Check CRS\nst_crs(mn_cities)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n# Check CRS\nst_crs(mn_water)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n# (They're both NAD83 / UTM zone 15N but we'll transform anyway)\n\n# Transform CRS of water to the same of the cities\nmn_water &lt;- mn_water %&gt;%\n    st_transform(crs = st_crs(mn_cities))\n\n\n# Load country boundaries data as sf object\nmn_counties &lt;- us_counties(resolution = \"high\", states = \"Minnesota\")\n\n# Remove duplicate column names\nnames_counties &lt;- names(mn_counties)\nnames(mn_counties)[names_counties == 'state_name'] &lt;- c(\"state_name1\", \"state_name2\")\n\n# Check CRS\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n# (They're different!)\n\n# Transform the CRS of county data to the more local CRS of the cities\nmn_counties &lt;- mn_counties %&gt;%\n  st_transform(crs = st_crs(mn_cities))\n\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n\n\n\nInitial map: counties and cities\n\nggplot() + # plot frame\n    geom_sf(data = mn_counties, fill = NA) + # county boundary layer\n    geom_sf(data = mn_cities, size = 0.5) + # city point layer\n    ggthemes::theme_map()\n\n\n\n\n\nggplot() +\n    geom_sf(data = mn_counties, fill = \"wheat\", color = \"tan\") + \n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population), alpha = 0.8)+ #cities layer\n    scale_color_viridis_c() + # continuous (gradient) color scale\n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"bottom\")  #move legend\n\n\n\n\n\n\nUpdated map: counties and cities plus elevation\n\nelevation &lt;- elevatr::get_elev_raster(mn_counties, z = 5, clip = 'bbox')\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to Data Frame for plotting\nelev_df &lt;- elevation %&gt;% terra::as.data.frame(xy = TRUE)\nnames(elev_df) &lt;-c('x','y','value')\n\nggplot() +\n    geom_raster(data = elev_df, aes(x = x,y = y,fill = value)) + # adding the elevation as first (bottom) layer\n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + \n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population,size = Population), alpha = 0.8)+ #cities layer\n    scale_color_viridis_c() + #continuous (gradient) color scale\n    scale_fill_gradient(low = 'darkgreen',high = 'white', guide = FALSE) + \n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"bottom\")  #move legend\n\n\n\n\n\n\nUpdated map: zoom in to Twin Cities\n\nseven_countyarea &lt;- st_bbox(mn_counties %&gt;% filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")))\n\n\nelevation &lt;- elevatr::get_elev_raster(mn_counties %&gt;% st_crop(seven_countyarea), z = 9, clip = 'bbox')\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation %&gt;% terra::as.data.frame(xy = TRUE)\nnames(elev_df) &lt;-c('x','y','value')\n\nggplot() +\n    geom_raster(data = elev_df, aes(x = x,y = y,fill = value)) + \n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + # county boundary layer\n    geom_sf(data = mn_water, fill = 'lightsteelblue1',color = 'lightsteelblue1') + # added a river/lake layer\n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population,size = Population)) + # cities layer\n    coord_sf(xlim = seven_countyarea[c(1,3)], ylim = seven_countyarea[c(2,4)]) + # crop map to coordinates of seven county area\n    scale_color_viridis_c(option = 'magma') + # continuous (gradient) color scale\n    scale_fill_gradient(low = 'darkgreen',high = 'white') + # continuous (gradient) fill scale\n    labs(title = \"Twin Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"none\")  # remove legend\n\n\n\n\n\n\nTwin Cities Leaflet\nBelow we show how to make the MN counties map in the leaflet package.\n\nlibrary(leaflet)\n\nmn_counties_leaf &lt;- mn_counties %&gt;% st_transform(4326) # Leaflet expects this CRS for vectors\nmn_cities_leaf &lt;- mn_cities %&gt;% st_transform(4326) # Leaflet expects this CRS for vectors\n\nCities_per_County &lt;- st_join(mn_cities_leaf, mn_counties_leaf) %&gt;%\n  st_drop_geometry() %&gt;% #removes geometry - makes the following calculation more efficient \n  count(name) \n\nmn_counties_leaf %&gt;% \n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) %&gt;%\n    left_join(Cities_per_County) %&gt;%\n    leaflet() %&gt;% \n    addProviderTiles(\"CartoDB.Positron\") %&gt;% \n    addPolygons(color = \"#444444\", weight = 1, smoothFactor = 0.5,\n    opacity = 1.0, fillOpacity = 0.5, fillColor = ~colorQuantile(\"YlOrRd\", n)(n), highlightOptions = highlightOptions(color = \"white\", weight = 2,\n      bringToFront = TRUE)) %&gt;%\n    addCircles(data = mn_cities_leaf %&gt;% filter(County %in% paste(c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\"),'County')), color = \"#444444\")"
  },
  {
    "objectID": "03-adv-maps.html#open-ended-exercise-homework",
    "href": "03-adv-maps.html#open-ended-exercise-homework",
    "title": "Advanced Spatial Visualizations",
    "section": "Open-ended Exercise (Homework)",
    "text": "Open-ended Exercise (Homework)\nThe following exercises will use census tract tidycensus data for Ramsey and Hennepin county and Crash.csv (2019-2022) from the pedestrian/bike crash database for St. Paul within Ramsey county in the Twin Cities. We provide several variables that you can choose from in order to create maps that best fit your interest.\nLoad the data with the following code:\n\ncensus2020 &lt;- tidycensus::get_acs(year = 2020, state = \"MN\", geography = \"tract\", variables = c(    \n\"B01003_001\", \"B19013_001\", \"B23006_023\", \"B25058_001\", \"B25107_001\", \"B25003_001\", \"B25003_002\", \"B25003_003\", \"B25077_001\"), output = 'wide', geometry = TRUE) %&gt;%\n  filter(word(NAME, 4) %in% c(\"Ramsey\",\"Hennepin\"))%&gt;%\n               mutate(tract = word(NAME, 3),\n                      tract = str_remove(tract, \",\"),\n                      county = word(NAME, 4)) %&gt;%\n               select(-NAME) %&gt;%\n               rename(\"population\" = \"B01003_001E\", \n                      \"medianIncome\" = \"B19013_001E\", \n                      \"bachelors\" = \"B23006_023E\",\n                      \"medContractRent\" = \"B25058_001E\", \n                      \"tenureTotal\" = \"B25003_001E\", \n                      \"tenureOwned\" = \"B25003_002E\", \n                      \"tenureRented\" = \"B25003_003E\",\n                      \"medianHomeValue\"= \"B25077_001E\") %&gt;%\n  select(-contains(\"_\"))\n\ncrashes &lt;- read_csv(\"https://lmyint.github.io/212_fall_2023/data/Crash.csv\") %&gt;%\n    filter(!is.na(Latitude), !is.na(Longitude))\n\n\nExercise: Joining and aggregation\nCreate a map of crashes per census tract in Ramsey county.\nFirst, transform the crashes data frame to a sf object have a point geometry using the code below.\n\ncrashes &lt;- st_as_sf(crashes, coords = c(\"Longitude\", \"Latitude\"), crs = \"NAD83\")\n\nCheck the CRS are the same for census2020 and crashes using st_crs() and transform if needed.\n\n# code here\n\nJoin the crashes and census dataset together and count the number of crashes per census tract. The function st_join can join to spatial data sets according to whether the spatial geometries of the right table intersect with the spatial geometries of the left table.\n\ncrashes_per_tract &lt;- st_join(??,??) %&gt;%\n    st_drop_geometry() %&gt;% # removes geometry - makes the following calculation more efficient \n    filter(!is.na(Accident_Datetime)) %&gt;%\n    count(??) \n\nJoin the census data with crashes_per_tract and then use a filter of n &gt; 0 to only keep the census tracts where crashes were recorded instead of all of Ramsey and Hennepin County.\n\ncrashes_per_tract_geo &lt;- ??? %&gt;% # sf object with census geometry goes first\n    left_join(??, by = ??) %&gt;%\n    filter(n &gt; 0)\n\nCreate the plot!!\n\nggplot() +\n    geom_sf(???) +\n    scale_fill_gradientn(colours = c(\"lightcyan\", \"lightcyan2\", \"lightskyblue3\", \"lightskyblue4\"))+\n    labs(fill = \"Crashes\", color = \"\", title = \"Number of pedestrian/bike crashes per census tract\") +\n    ggthemes::theme_map() + theme(legend.position = \"bottom\")\n\n\n\nExercise: Adding layers\nPlot a variable of your choice for census tracts in Hennepin and Ramsey County and add roads to the map.\nStart by downloading a shape file. For example, you could search for “Minnesota roads shape file”. For this example, visit this site and download the Shapefile Zip File. Unzip the file and put the folder in the same location as this Rmd file.\nLoad in the shapefile using st_read() and transform roads to have the same CRS as census2020 if necessary.\n\nroads &lt;- sf::st_read(\"tl_2019_27_prisecroads\")\n\n# Check CRS of roads and transform if necessary\n\nStart by using st_crop() to crop the roads map to the area we are interested in (Hennepin and Ramsey County).\n\nroads_sub &lt;- st_crop(roads,st_bbox(census2020))\n\nCreate the map!!\n\nggplot() +\n    geom_sf(??)+ #put census tracts on map and fill by your variable of interest\n    geom_sf(?? ,fill = \"gray\", color = \"gray\", lwd = 0.2)+ #roads data here\n    labs(??)+ # add labels to fit your variables \n    scale_fill_gradientn(colours = c(\"lightcyan\", \"lightcyan2\", \"lightskyblue3\", \"lightskyblue4\"))+ # change to preferred color palette\n    theme_classic()+\n    theme(axis.line = element_blank(), \n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        legend.position = \"bottom\", \n        plot.title.position = \"plot\", \n        plot.title = element_text(size = 8), \n        plot.subtitle = element_text(size = 8))\n\nHow to cite AI and other resources: If you use AI tools like ChatGPT or Google Bard, please copy and paste all prompts and output into an “Appendix” section of this assignment. If you use an AI tool, also list one environmentally-friendly action you could adopt (that you don’t already do) to offset the energy usage. Also list any websites used in this Appendix.\nSubmission details: Click the “Render” button to create an HTML report from your Quarto file. Open the HTML in your web browser and save the webpage as a PDF (Ctrl-P/Command P, choose “Save as PDF” as the Destination). Submit this PDF on Moodle AND the .qmd file by midnight on Wednesday, 9/20."
  },
  {
    "objectID": "03-adv-maps.html#additional-resources",
    "href": "03-adv-maps.html#additional-resources",
    "title": "Advanced Spatial Visualizations",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nSpatial Data Science https://r-spatial.org/book/\nLeaflet in R https://rstudio.github.io/leaflet/"
  },
  {
    "objectID": "04-interactive-viz.html",
    "href": "04-interactive-viz.html",
    "title": "Interactive visualization",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nEvaluate when it would be useful to use an interactive visualization or an animation and when it might not be necessary\nConstruct interactive visualizations and animations with plotly\nBuild a Shiny app that enables user to adjust visualization choices and explore linked visualizations\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)"
  },
  {
    "objectID": "04-interactive-viz.html#why-use-interactivity",
    "href": "04-interactive-viz.html#why-use-interactivity",
    "title": "Interactive visualization",
    "section": "Why use interactivity?",
    "text": "Why use interactivity?\nPros\n\nUsers can click, hover, zoom, and pan to get more detailed information\nUsers can get quickly and deeply explore the data via linked data representations\nAllows guided exploration of results without needing to share data\n\nCons\n\nTakes longer to design\nAnalyst might spend longer exploring an interactive visualization than a series of static visualizations\nPoor design could result in information overload"
  },
  {
    "objectID": "04-interactive-viz.html#common-features-of-interactive-visualizations",
    "href": "04-interactive-viz.html#common-features-of-interactive-visualizations",
    "title": "Interactive visualization",
    "section": "Common features of interactive visualizations",
    "text": "Common features of interactive visualizations\nCommon features of interactive visualizations include (reference):\n\nChanging data representation: providing options to change the type of plot displayed (e.g., allowing users to visualize temperature patterns over a month vs. over years)\nFocusing and getting details: mousing over part of a visualization to see an exact data value, zooming and panning\nData transformation: e.g., changing color scale, switching to/from log scale\nData selection and filtering: highlighting and brushing regions of a plot to focus the selected points; reordering and filtering data show in tables\nFinding corresponding information in multiple views: linked views that update dynamically based on interaction in another plot (often by zooming, panning, or selecting certain points)"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-0-app-planning",
    "href": "04-interactive-viz.html#exercise-0-app-planning",
    "title": "Interactive visualization",
    "section": "Exercise 0: App planning",
    "text": "Exercise 0: App planning\nCatalog the app’s layout and interactivity features as part of the app planning phase.\n\nNavigator: Open up the neighborhood diversity app for reference. The Navigator should explore the interactive features of the app and help the Driver sketch out a schematic of the app.\nDriver: Sketch the layout and general features of the app as the Navigator navigates. Draw arrows to indicate what parts of the app update in response to user input.\n\n\n\n\n\n\n\nReflect: App design\n\n\n\n\n\nIs the interactivity in this app needed? Does the interactivity actually help you gain more insight (and perhaps more efficiently) than a series of static visualizations? What static visualizations might be more useful?"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-1-setup-and-getting-acquainted",
    "href": "04-interactive-viz.html#exercise-1-setup-and-getting-acquainted",
    "title": "Interactive visualization",
    "section": "Exercise 1: Setup and getting acquainted",
    "text": "Exercise 1: Setup and getting acquainted\nSetup part 1: Load required packages at the top of app.R: shiny, tidyverse, sf, and plotly.\nSetup part 2: Data download and folder setup\nNavigate to the “Data for interactive viz activity” folder on Moodle and save the two files with the folder setup below:\n\n📂 YOUR_CLASS_FOLDER\n\n📂 interactive_viz\n\n📂 neighborhood_diversity\n\napp.R\n📂 data\n\ndata_by_dist.rds\ndata_by_year.csv\n\n\n\n\n\nSetup part 3: Below your library() calls, add the following commands to read in the data:\n\ndata_by_dist &lt;- read_rds(\"Enter the correct relative path to data_by_dist.rds\")\ndata_by_year &lt;- read_csv(\"Enter the correct relative path to data_by_year.csv\")\n\nGetting acquainted with the app and underlying code: Open this PDF or have the code printout distributed at the start of class in front of you. Also have the app running in your browser.\n\nDraw lines on the printout/PDF of what visual parts of the app correspond to which parts of code.\nWhat names/labels in the User Interface (ui) part of the app seem to be shared with the server part of the app? (Draw lines between the ui and server parts of the code.)\n\n\n\n\n\n\n\nStop to Share\n\n\n\n\n\nAs you work on the “Getting acquainted” part of this exercise, share with your partner some struggles you have with code and some strategies that you have tried."
  },
  {
    "objectID": "04-interactive-viz.html#input-functions",
    "href": "04-interactive-viz.html#input-functions",
    "title": "Interactive visualization",
    "section": "*Input() functions",
    "text": "*Input() functions\n\nBackground\nThe *Input() functions collect inputs from the user. The various types are listed on the right-hand side of the first page of the cheatsheet. You will list all the *Input() functions you want to use with their accompanying arguments inside the fluidPage() function in the ui portion. Separate the *Input() functions with commas.\nIn all the *Input() functions, the first two arguments are the same:\n\ninputId is how you will refer to this input in the server portion later\nlabel is how this will actually be labeled in your UI (what text shows up in the app)\n\nEach function has some additional arguments depending what you want to do.\n\n\nExercise 2: Add *Input()s\nAdd the following two user inputs to your app:\n\nDropdown to select the city name\nSlider to choose the span parameter for the scatterplot smooth\n\nUse the Shiny cheatsheet to find the *Input() functions that correspond to the two inputs above. Add them to the appropriate place within the ui object. Use commas to separate the inputs. You will have to look at the documentation for the *Input() functions to know how to use arguments beyond inputId and label. To view this documentation, type ?function_name in the Console.\nTo get the collection of city names from the data_by_dist dataset, you can use the pull() and unique() functions. Save the city names in an object called metro_names—this code can go just beneath where you read in the data.\nOnce you finish, run your app. Make sure you can select and move things around as expected. You won’t see any plots yet–we’ll work on those in the next exercises."
  },
  {
    "objectID": "04-interactive-viz.html#output-functions",
    "href": "04-interactive-viz.html#output-functions",
    "title": "Interactive visualization",
    "section": "*Output() functions",
    "text": "*Output() functions\n\nBackground\n*Output() functions in the ui portion work with the render*() functions in the server portion to to add R output to the UI. The *Output() functions are listed in the bottom center part of the first page of the cheatsheet.\nAll the *Output() functions have the same first argument, outputId, which is used how you will refer to this output in the server portion later (like the inputId in the *Input() functions).\n\n\nExercise 3: Add *Output()s\nAdd 3 plotOutput()s to the ui that will eventually be:\n\nA scatterplot of diversity score (entropy) versus distance to city hall (distmiles) with a smoothing line (smoothness controlled by the span parameter on your slider input)\nA map of diversity scores across the counties in the selected city\nA bar chart of the overall race distribution in the selected city (i.e., the total number of people in each race category in the city)\n\nFor now, don’t worry that the layout of the plots exactly matches the original neighborhood diversity app. (You will update this in your homework.)\nRun the app with the output. Notice that nothing really changes. Think of the outputs you just placed as placeholders—the app knows there will be a plot in the UI, but the details of what the plots will look like and the R code to create them will be in the server portion. Let’s talk about that now!"
  },
  {
    "objectID": "04-interactive-viz.html#render-functions",
    "href": "04-interactive-viz.html#render-functions",
    "title": "Interactive visualization",
    "section": "render*() functions",
    "text": "render*() functions\nThe render*() functions go in the server function of the app. The render*() functions use R code (i.e., standard ggplot code) to communicate with (“listen to”) the user inputs to create the desired output.\nThe render*() function you use will depend on the desired output. The bottom center of the cheatsheet shows how *Output() and render*() functions connect.\nIn general, the server section of code will look something like this:\n\nserver &lt;- function(input, output) {\n    output$outputId_of_interest &lt;- render*({ # Note the curly braces that enclose the R code below\n        # R code that creates the output and calls various input$InputId's\n    })\n}\n\nExample: Suppose that inside ui, we used plotOutput(outputId = \"timeplot\"):\n\nIn the server function, we would use output$timeplot &lt;- renderPlot({...}).\n\nThe ... would be replaced by detailed R plotting code.\nTo reference the inputs we create in the ui, we use input$inputID_name. e.g., if we had an *Input() with inputId = \"years\", we would use input$years in the server function.\n\n\n\nExercise 4: Add renderPlot()\nWhile our main goals is to make 3 plots, you will just make one of them in this exercise.\nAdd a renderPlot() functions inside the server portion of the code to make the scatterplot of diversity score (entropy) versus distance to city hall (distmiles) with a smoothing line. Reference the inputs you’ve already created in previous exercises by using filter() and ggplot() to render the desired interactive plot.\nNote: the geom_??? used to create the smoothing line has a span parameter. (Check out the documentation for that geom by entering ?geom_??? in the Console.)\nRun the app and check that the scatterplot displays and reacts to the chosen city and span parameter.\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWhat challenges are you encountering as we go through this new material? What parts of your interactions with your partner have been helpful or less helpful for your learning today?"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-5-turn-plots-into-plotlys",
    "href": "04-interactive-viz.html#exercise-5-turn-plots-into-plotlys",
    "title": "Interactive visualization",
    "section": "Exercise 5: Turn plots into plotlys",
    "text": "Exercise 5: Turn plots into plotlys\nIn a web application, having plots be plotly objects is just nice by default because of the great mouseover, zoom, and pan features.\nInside app.R, change all instances of plotOutput to plotlyOutput and all instances of renderPlot to renderPlotly. Make sure to add calls to ggplotly() too."
  },
  {
    "objectID": "05-data-types-1.html",
    "href": "05-data-types-1.html",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nDetermine the class of a given object and identify concerns to be wary of when manipulating an object of that class (numerics, logicals, factors, dates, strings, data.frames)\nExplain what vector recycling is, when it is used, when it can be a problem, and how to avoid those problems\nExplain the difference between implicit and explicit coercion\nExtract date-time information using the lubridate package\nWrite R code to wrangle data from these different types\nRecognize several new R errors and warnings related to data types\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nwrangling_data_types\n\ncode\n\n05-data-types-1.qmd\n\ndata\n\nYou’ll download data from Moodle later today."
  },
  {
    "objectID": "05-data-types-1.html#numeric-and-integer-classes",
    "href": "05-data-types-1.html#numeric-and-integer-classes",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Numeric and integer classes",
    "text": "Numeric and integer classes\nNumbers that we see in R are generally of the numeric class, which are numbers with decimals. The c() function below is a way to create a vector of multiple numbers.\n\nnumbers &lt;- c(1, 2, 3)\nclass(numbers)\n\n[1] \"numeric\"\n\n\nR also has an integer class which will most often be formed when using the : operator to form regularly spaced sequences.\n\nintegers &lt;- 1:3\nclass(integers)\n\n[1] \"integer\"\n\n\nIt will be important to know how to check whether a number is a numeric or integer because we’ll be using the purrr package very shortly which checks types very strictly (e.g., 1 as an integer cannot be combined with 1 as a numeric)"
  },
  {
    "objectID": "05-data-types-1.html#vector-recycling",
    "href": "05-data-types-1.html#vector-recycling",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Vector recycling",
    "text": "Vector recycling\n\nhead(lakers %&gt;% select(date, opponent, team, points))\n\n      date opponent team points\n1 20081028      POR  OFF      0\n2 20081028      POR  LAL      0\n3 20081028      POR  LAL      0\n4 20081028      POR  LAL      0\n5 20081028      POR  LAL      0\n6 20081028      POR  LAL      2\n\n\nSuppose that we wanted to update just the first two points values (e.g., we learned of a typo).\n\npoint_update &lt;- c(2,3)\nlakers2 &lt;- lakers %&gt;%\n    mutate(points = points + point_update)\nhead(lakers$points)\n\n[1] 0 0 0 0 0 2\n\nhead(lakers2$points)\n\n[1] 2 3 2 3 2 5\n\n\nUh oh! It looks like the 2,3 point update vector got repeated multiple times. This is called vector recycling. If you are trying to combine or compare vectors of different lengths, R will repeat (recycle) the shorter one as many times as it takes to make them the same length. When the longer vector’s length isn’t a multiple of the smaller one, we’ll get a warning.\n\npoint_update &lt;- c(2,3,2)\nlakers2 &lt;- lakers %&gt;%\n    mutate(points = points + point_update)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `points = points + point_update`.\nCaused by warning in `points + point_update`:\n! longer object length is not a multiple of shorter object length\n\n\nIn this case, the safest way to do the points update is to make sure that point_update has the same length as points:\n\nlakers2 &lt;- lakers %&gt;%\n    mutate(\n        play_id = 1:nrow(lakers),\n        point_update = case_when(\n            play_id==1 ~ 2,\n            play_id==2 ~ 3,\n            .default = 0\n        ),\n        points = points + point_update\n    )\n\nhead(lakers2 %&gt;% select(date, opponent, team, points))\n\n      date opponent team points\n1 20081028      POR  OFF      2\n2 20081028      POR  LAL      3\n3 20081028      POR  LAL      0\n4 20081028      POR  LAL      0\n5 20081028      POR  LAL      0\n6 20081028      POR  LAL      2\n\n\nRecycling will very often come up when working with logical objects (Booleans):\n\nclass(diamonds)==\"data.frame\"\n\n[1] FALSE FALSE  TRUE\n\nclass(diamonds)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\"data.frame\" %in% class(diamonds)\n\n[1] TRUE\n\nany(class(diamonds)==\"data.frame\")\n\n[1] TRUE"
  },
  {
    "objectID": "05-data-types-1.html#explicit-coercion",
    "href": "05-data-types-1.html#explicit-coercion",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Explicit coercion",
    "text": "Explicit coercion\nIn R there is a family of coercion functions that force a variable to be represented as a particular type. We have as.numeric() and as.integer() for numbers.\nMost commonly we will use these when numbers have accidentally been read in as a character or a factor. (More on factors later.)\nIn the example below we have a set of 4 points values, but the last entry was mistakenly typed as a space in the spreadsheet (instead of as an empty cell). We can see when we display points that all of the values have quotes around them and that the class of the points object is a character vector. (More on working with character objects next time.)\n\npoints &lt;- c(2, 3, 0, \" \")\npoints\n\n[1] \"2\" \"3\" \"0\" \" \"\n\nclass(points)\n\n[1] \"character\"\n\n\nMost commonly we will have numeric data that happens to be read in as a character. After cleaning up the strings, we can use as.numeric to coerce the vector to a numeric vector. (More on strings and regular expressions later.) Example:\n\nx &lt;- c(\"2.3\", \"3.4\", \"4.5\", \"5.6.\")\nas.numeric(x)\n\nWarning: NAs introduced by coercion\n\n\n[1] 2.3 3.4 4.5  NA\n\nx &lt;- str_remove(x, \"\\\\.$\")\nas.numeric(x)\n\n[1] 2.3 3.4 4.5 5.6"
  },
  {
    "objectID": "05-data-types-1.html#other-topics",
    "href": "05-data-types-1.html#other-topics",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Other topics",
    "text": "Other topics\nThe Numbers chapter in R4DS covers a lot of useful functions and ideas related to wrangling numbers. It would be very usefl to read this chapter. A glossary of the\n\nn(), n_distinct()\nsum(is.na())\npmin(), pmax() vs min(), max()\nInteger division: %/%. Remainder: %%\nround(), floor(), ceiling()\ncut()\ncumsum(), dplyr::cummean(), cummin(), cummax()\ndplyr::min_rank()\nlead(), lag(): shift a vector by padding with NAs\nNumerical summaries: mean, median, min, max, quantile, sd, IQR"
  },
  {
    "objectID": "06-data-types-2.html",
    "href": "06-data-types-2.html",
    "title": "Wrangling: strings",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nManipulate and explore strings using the stringr package\nConstruct regular expressions to find patterns in strings\n\n\nTo shape how we hold class today, go to my PollEverywhere page for some survey questions.\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nwrangling_data_types\n\ncode\n\n05-data-types-1.qmd\n06-data-types-2.qmd"
  },
  {
    "objectID": "06-data-types-2.html#creating-strings",
    "href": "06-data-types-2.html#creating-strings",
    "title": "Wrangling: strings",
    "section": "Creating strings",
    "text": "Creating strings\nCreating strings by hand is useful for testing out regular expressions.\nTo create a string, type any text in either double quotes (\") or single quotes '. Using double or single quotes doesn’t matter unless your string itself has single or double quotes.\n\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\n\nWe can view these strings “naturally” (without the opening and closing quotes) with str_view():\n\nstr_view(string1)\n\n[1] │ This is a string\n\nstr_view(string2)\n\n[1] │ If I want to include a \"quote\" inside a string, I use single quotes\n\n\nExercise: Create the string It's Thursday. What happens if you put the string inside single quotes? Double quotes?\n\n# Your code\n\nBecause \" and ' are special characters in the creation of strings, R offers another way to put them inside a string. We can escape these special characters by putting a \\ in front of them:\n\nstring1 &lt;- \"This is a string with \\\"double quotes\\\"\"\nstring2 &lt;- \"This is a string with \\'single quotes\\'\"\nstr_view(string1)\n\n[1] │ This is a string with \"double quotes\"\n\nstr_view(string2)\n\n[1] │ This is a string with 'single quotes'\n\n\nGiven that \\ is a special character, how can we put the \\ character in strings? We have to escape it with \\\\.\nExercise: Create the string C:\\Users. What happens when you don’t escape the \\?\n\n# Your code\n\nOther special characters include:\n\n\\t (Creates a tab)\n\\n (Creates a newline)\n\nBoth can be useful in plots to more neatly arrange text.\n\nstring1 &lt;- \"Record temp:\\t102\"\nstring2 &lt;- \"Record temp:\\n102\"\n\nstr_view(string1)\n\n[1] │ Record temp:{\\t}102\n\nstr_view(string2)\n\n[1] │ Record temp:\n    │ 102\n\n\nExercise (Exploring function documentation): Can we get str_view() to show the tab instead of {\\t}? Enter ?str_view in the Console to pull up the documentation for this function. Look through the arguments to see how we might do this.\nReflection: In your Process and Reflection Log, record any strategies that you learned about reading function documentation.\n\nOften we will want to create new strings within data frames. We can use str_c() or str_glue():\n\nWith str_c() the strings to be combined are all separate arguments separated by commas.\nWith str_glue() the desired string is written as a template with variable names inside curly braces {}.\n\n\ndf &lt;- tibble(\n    first_name = c(\"Arya\", \"Olenna\", \"Tyrion\", \"Melisandre\"),\n    last_name = c(\"Stark\", \"Tyrell\", \"Lannister\", NA)\n)\ndf\n\n# A tibble: 4 × 2\n  first_name last_name\n  &lt;chr&gt;      &lt;chr&gt;    \n1 Arya       Stark    \n2 Olenna     Tyrell   \n3 Tyrion     Lannister\n4 Melisandre &lt;NA&gt;     \n\ndf %&gt;%\n    mutate(\n        full_name1 = str_c(first_name, \" \", last_name),\n        full_name2 = str_glue(\"{first_name} {last_name}\")\n    )\n\n# A tibble: 4 × 4\n  first_name last_name full_name1       full_name2      \n  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;            &lt;glue&gt;          \n1 Arya       Stark     Arya Stark       Arya Stark      \n2 Olenna     Tyrell    Olenna Tyrell    Olenna Tyrell   \n3 Tyrion     Lannister Tyrion Lannister Tyrion Lannister\n4 Melisandre &lt;NA&gt;      &lt;NA&gt;             Melisandre NA   \n\n\nExercise: In the following data frame, create a full date string in month-day-year format using both str_c() and str_glue().\n\ndf_dates &lt;- tibble(\n    year = c(2000, 2001, 2002),\n    month = c(\"Jan\", \"Feb\", \"Mar\"),\n    day = c(3, 4, 5)\n)"
  },
  {
    "objectID": "06-data-types-2.html#extracting-information-from-strings",
    "href": "06-data-types-2.html#extracting-information-from-strings",
    "title": "Wrangling: strings",
    "section": "Extracting information from strings",
    "text": "Extracting information from strings\nThe str_length() counts the number of characters in a string.\n\ncomments &lt;- tibble(\n    name = c(\"Alice\", \"Bob\"),\n    comment = c(\"The essay was well organized around the core message and had good transitions.\", \"Good job!\")\n)\n\ncomments %&gt;%\n    mutate(\n        comment_length = str_length(comment)\n    )\n\n# A tibble: 2 × 3\n  name  comment                                                   comment_length\n  &lt;chr&gt; &lt;chr&gt;                                                              &lt;int&gt;\n1 Alice The essay was well organized around the core message and…             78\n2 Bob   Good job!                                                              9\n\n\nThe str_sub() function gets a substring of a string. The 2nd and 3rd arguments indicate the beginning and ending position to extract.\n\nNegative positions indicate the position from the end of the word. (e.g., -3 indicates “3rd letter from the end”)\nSpecifying a position that goes beyond the word won’t result in an error. str_sub() will just go as far as possible.\n\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n\n[1] \"App\" \"Ban\" \"Pea\"\n\nstr_sub(x, -3, -1)\n\n[1] \"ple\" \"ana\" \"ear\"\n\nstr_sub(\"a\", 1, 5)\n\n[1] \"a\"\n\n\nExercise: Find the middle letter of each word in the data frame below. (Challenge: How would you handle words with an even number of letters?)\n\ndf &lt;- tibble(\n    word_id = 1:3,\n    word = c(\"replace\", \"match\", \"pattern\")\n)"
  },
  {
    "objectID": "06-data-types-2.html#finding-patterns-in-strings-with-regular-expressions",
    "href": "06-data-types-2.html#finding-patterns-in-strings-with-regular-expressions",
    "title": "Wrangling: strings",
    "section": "Finding patterns in strings with regular expressions",
    "text": "Finding patterns in strings with regular expressions\nSuppose that you’re exploring text data looking for places where people describe happiness. There are many ways to search. We could search for the word “happy” but that excludes “happiness” so we might search for “happi”.\nRegular expressions (regex) are a powerful language for describing patterns within strings.\n\ndata(fruit)\ndata(words)\ndata(sentences)\n\nWe can use str_view() with the pattern argument to see what parts of a string match the regex supplied in the pattern argument. (Matches are enclosed in &lt;&gt;.)\n\nstr_view(fruit, \"berry\")\n\n [6] │ bil&lt;berry&gt;\n [7] │ black&lt;berry&gt;\n[10] │ blue&lt;berry&gt;\n[11] │ boysen&lt;berry&gt;\n[19] │ cloud&lt;berry&gt;\n[21] │ cran&lt;berry&gt;\n[29] │ elder&lt;berry&gt;\n[32] │ goji &lt;berry&gt;\n[33] │ goose&lt;berry&gt;\n[38] │ huckle&lt;berry&gt;\n[50] │ mul&lt;berry&gt;\n[70] │ rasp&lt;berry&gt;\n[73] │ salal &lt;berry&gt;\n[76] │ straw&lt;berry&gt;\n\n\nEssentials of forming a regex\n\nLetters and numbers in a regex are matched exactly and are called literal characters.\nMost punctuation characters, like ., +, *, [, ], and ?, have special meanings and are called metacharacters.\nQuantifiers come after a regex and control how many times a pattern can match:\n\n?: match the preceding pattern 0 or 1 times\n+: match the preceding pattern at least once\n*: match the preceding pattern at least 0 times (any number of times)\n\n\nExercise: Before running the code below, predict what matches will be made. Run the code to check your guesses. Note that in all regex’s below the ?, +, * applies to the b only (not the a).\n\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;ab&gt;b\n\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\n\n\nWe can match any of a set of characters with [] (called a character class), e.g., [abcd] matches “a”, “b”, “c”, or “d”.\n\nWe can invert the match by starting with ^: [^abcd] matches anything except “a”, “b”, “c”, or “d”.\n\n\n\n# Match words that have vowel-x-vowel\nstr_view(words, \"[aeiou]x[aeiou]\")\n\n[284] │ &lt;exa&gt;ct\n[285] │ &lt;exa&gt;mple\n[288] │ &lt;exe&gt;rcise\n[289] │ &lt;exi&gt;st\n\n# Match words that have not_vowel-y-not_vowel\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n\n[836] │ &lt;sys&gt;tem\n[901] │ &lt;typ&gt;e\n\n\nExercise Using the words data, find words that have two vowels in a row followed by an “m”.\n\n# Your code\n\n\nThe alternation operator | can be read just like the logical operator | (“OR”) to pick between one or more alternative patterns. e.g., apple|banana searches for “apple” or “banana”.\n\n\nstr_view(fruit, \"apple|melon|nut\")\n\n [1] │ &lt;apple&gt;\n[13] │ canary &lt;melon&gt;\n[20] │ coco&lt;nut&gt;\n[52] │ &lt;nut&gt;\n[62] │ pine&lt;apple&gt;\n[72] │ rock &lt;melon&gt;\n[80] │ water&lt;melon&gt;\n\n\nExercise: Using the fruit data, find fruits that have a repeated vowel (“aa”, “ee”, “ii”, “oo”, or “uu”.)\n\n# Your code\n\n\nThe ^ operator indicates the beginning of a string, and the $ operator indicates the end of a string. e.g., ^a matches strings that start with “a”, and a$ matches words that end with “a”.\nParentheses group together parts of a regular expression that should be taken as a bundle. (Much like parentheses in arithmetic statements.)\n\ne.g., ab+ is a little confusing. Does it match “ab” one or more times? Or does it match “a” first, then just “b” one or more times? (The latter, as we saw in an earlier example.) We can be very explicit and use a(b)+.\n\n\nExercise: Using the words data, find (1) words that start with “y” and (2) words that don’t start with “y”.\n\n# Your code\n\n\nThe following are core stringr functions that use regular expressions:\n\nstr_view() - View the first occurrence in a string that matches the regex\nstr_count() - Count the number of times a regex matches within a string\nstr_detect() - Determine if (TRUE/FALSE) the regex is found within string\nstr_subset() - Return subset of strings that match the regex\nstr_extract(), str_extract_all() - Return portion of each string that matches the regex. str_extract() extracts the first instance of the match. str_extract_all() extracts all matches.\nstr_replace(), str_replace_all() - Replace portion of string that matches the regex with something else. str_replace() replaces the first instance of the match. str_replace_all() replaces all instances of the match.\nstr_remove(), str_remove_all() - Removes the portion of the string that matches the pattern. Equivalent to str_replace(x, \"THE REGEX PATTERN\", \"\")\n\nExercise: Each person at your table should explore a different one of the functions (other than str_view()). Pull up the documentation page using ?function_name. Explore the arguments and create a small example that demonstrates its usage. Share with your group members."
  },
  {
    "objectID": "06-functions-control-structs.html",
    "href": "06-functions-control-structs.html",
    "title": "Topic 6: Functions and control structures",
    "section": "",
    "text": "Learning goals\nAfter this lesson, you should be able to:\n\nRecognize when it would be useful to write a function\nIdentify the core components of a function definition and explain their role (the function() directive, arguments, argument defaults, function body, return value)\nDescribe the difference between argument matching by position and by name\nDescribe what the ... argument does and the rationale underlying the rules for named arguments in conjunction with ...\nWrite if-else, if-else if-else statements to conditionally execute code\nWrite your own function to carry out a repeated task\nProvide feedback on functions written by others\n\n\n\nNOTES\nInstead of introducing purrr, just do functions and basic control structures for this lesson\n\n\nPre-class preparation\nRead https://bookdown.org/rdpeng/rprogdatascience/functions.html or rather https://r4ds.had.co.nz/functions.html\nMoodle quiz - Ask students for input on “Gosh I just wish it was easier to do ___ in R”. This will lead into the “Finding existing functions” part of the activity.\n\n\nSetup\npurrr resources\n\nhttps://jennybc.github.io/purrr-tutorial/index.html\nhttps://www.rebeccabarter.com/blog/2019-08-19_purrr\n\n\nlibrary(purrr)\nlibrary(repurrrsive)\n\n\ndata(got_chars)\ngot &lt;- got_chars\n\n\n\nActivity ideas\nWriting functions from scratch: Function Challenge Relay: Divide the students into groups and set up stations with different R function challenges. Each station has a specific task that requires creating or using R functions. The groups rotate through the stations, completing the challenges together. For example, one station might require writing a function to calculate factorial, another to find the mean of a dataset, and so on.\nWrite a function that fits a linear model within subgroups of the data.\nFinding existing functions: Function Library Creation: Assign each group a specific topic or problem domain (e.g., mathematical functions, data manipulation, data visualization). Each group works together to research, design, and implement a set of R functions that address various aspects of their assigned topic. They can then share their function library with the class. Function Scavenger Hunt: Create a scavenger hunt where each group receives a list of R functions to find and examples of tasks to perform using those functions. The hunt can involve finding functions in R documentation, tutorials, or online resources. The group that completes the most tasks correctly wins.\nGroups can put together a nice resource for others (e.g., a cheat sheet). Something more user-friendly than a Google Doc.\nEditing functions writen by others: Function Debugging Party: Give each group a set of R functions with intentional errors or bugs. The groups work together to debug and correct the functions. This activity reinforces the importance of testing and troubleshooting code collaboratively. Function Code Review Workshop: Each group writes an R function and shares it with another group. The receiving group reviews the code, provides feedback, and suggests improvements. This exercise promotes collaborative code development and helps students learn from each other’s code.\n\n\nHomework\nHave students go from gap_nested -&gt; gap_simple and gap_split -&gt; gap_simple\nExtra: other combinations: ehh I don’t know if this is that useful\n\n\npurrr"
  },
  {
    "objectID": "07-data-types-3.html",
    "href": "07-data-types-3.html",
    "title": "Wrangling: factors",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nRecode and manage factors using the forcats package\n\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nwrangling_data_types\n\ncode\n\n05-data-types-1.qmd\n06-data-types-2.qmd\n07-data-types-3.qmd"
  },
  {
    "objectID": "07-data-types-3.html#creating-factors",
    "href": "07-data-types-3.html#creating-factors",
    "title": "Wrangling: factors",
    "section": "Creating factors",
    "text": "Creating factors\nIn R, factors are made up of two components: the actual values of the data and the possible levels within the factor. Creating a factor requires supplying both pieces of information.\n\nmonths &lt;- c(\"Mar\", \"Dec\", \"Jan\",  \"Apr\", \"Jul\")\n\nHowever, if we were to sort this vector, R would sort this vector alphabetically.\n\n# alphabetical sort\nsort(months)\n\n[1] \"Apr\" \"Dec\" \"Jan\" \"Jul\" \"Mar\"\n\n\nWe can fix this sorting by creating a factor version of months. The levels argument is a character vector that specifies the unique values that the factor can take. The order of the values in levels defines the sorting of the factor.\n\nmonths_fct &lt;- factor(months, levels = month.abb) # month.abb is a built-in variable\nmonths_fct\n\n[1] Mar Dec Jan Apr Jul\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nsort(months_fct)\n\n[1] Jan Mar Apr Jul Dec\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nWhat if we try to create a factor with values that aren’t in the levels? (e.g., a typo in a month name)\n\nmonths2 &lt;- c(\"Jna\", \"Mar\")\nfactor(months2, levels = month.abb)\n\n[1] &lt;NA&gt; Mar \nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nBecause the NA is introduced silently (without any error or warnings), this can be dangerous. It might be better to use the fct() function in the forcats package instead:\n\nfct(months2, levels = month.abb)\n\nError in `fct()`:\n! All values of `x` must appear in `levels` or `na`\nℹ Missing level: \"Jna\"\n\n\nExercise: Create a factor version of the following data with the levels in a sensible order.\n\nratings &lt;- c(\"High\", \"Medium\", \"Low\")\n\nIn the remainder of the exercises and examples, we’ll use a subset of the General Social Survey (GSS) dataset available in the forcats pacakges.\n\ndata(gss_cat)"
  },
  {
    "objectID": "07-data-types-3.html#reordering-factors",
    "href": "07-data-types-3.html#reordering-factors",
    "title": "Wrangling: factors",
    "section": "Reordering factors",
    "text": "Reordering factors\nReordering the levels of a factor can be useful in plotting when categories would benefit from being sorted in a particular way:\n\nrelig_summary &lt;- gss_cat %&gt;%\n    group_by(relig) %&gt;%\n    summarize(\n        tvhours = mean(tvhours, na.rm = TRUE),\n        n = n()\n    )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) + \n    geom_point() +\n    theme_classic()\n\n\n\n\nWe can use fct_reorder() in forcats.\n\nThe first argument is the factor that you want to reorder the levels of\nThe second argument determines how the factor is sorted (analogous to what you put inside arrange() when sorting the rows of a data frame.)\n\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n    geom_point() +\n    theme_classic()\n\n\n\n\nFor bar plots, we can use fct_infreq() to reorder levels from most to least common. This can be combined with fct_rev() to reverse the order (least to most common):\n\ngss_cat %&gt;%\n    ggplot(aes(x = marital)) +\n    geom_bar() +\n    theme_classic()\n\n\n\ngss_cat %&gt;%\n    mutate(marital = marital %&gt;% fct_infreq() %&gt;% fct_rev()) %&gt;%\n    ggplot(aes(x = marital)) +\n    geom_bar() +\n    theme_classic()"
  },
  {
    "objectID": "07-data-types-3.html#modifying-factor-levels",
    "href": "07-data-types-3.html#modifying-factor-levels",
    "title": "Wrangling: factors",
    "section": "Modifying factor levels",
    "text": "Modifying factor levels\nWe talked about reordering the levels of a factor–what about changing the values of the levels themselves?\nFor example, the names of the political parties in the GSS could use elaboration (“str” isn’t a great label for “strong”) and clean up:\n\ngss_cat %&gt;% count(partyid)\n\n# A tibble: 10 × 2\n   partyid                n\n   &lt;fct&gt;              &lt;int&gt;\n 1 No answer            154\n 2 Don't know             1\n 3 Other party          393\n 4 Strong republican   2314\n 5 Not str republican  3032\n 6 Ind,near rep        1791\n 7 Independent         4119\n 8 Ind,near dem        2499\n 9 Not str democrat    3690\n10 Strong democrat     3490\n\n\nWe can use fct_recode() on partyid with the new level names going on the left and the old levels on the right. Any levels that aren’t mentioned explicitly (i.e., “Don’t know” and “Other party”) will be left as is:\n\ngss_cat %&gt;%\n    mutate(\n        partyid = fct_recode(partyid,\n            \"Republican, strong\"    = \"Strong republican\",\n            \"Republican, weak\"      = \"Not str republican\",\n            \"Independent, near rep\" = \"Ind,near rep\",\n            \"Independent, near dem\" = \"Ind,near dem\",\n            \"Democrat, weak\"        = \"Not str democrat\",\n            \"Democrat, strong\"      = \"Strong democrat\"\n        )\n    ) %&gt;%\n    count(partyid)\n\n# A tibble: 10 × 2\n   partyid                   n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 No answer               154\n 2 Don't know                1\n 3 Other party             393\n 4 Republican, strong     2314\n 5 Republican, weak       3032\n 6 Independent, near rep  1791\n 7 Independent            4119\n 8 Independent, near dem  2499\n 9 Democrat, weak         3690\n10 Democrat, strong       3490\n\n\nTo combine groups, we can assign multiple old levels to the same new level (“Other” maps to “No answer”, “Don’t know”, and “Other party”):\n\ngss_cat %&gt;%\n    mutate(\n        partyid = fct_recode(partyid,\n            \"Republican, strong\"    = \"Strong republican\",\n            \"Republican, weak\"      = \"Not str republican\",\n            \"Independent, near rep\" = \"Ind,near rep\",\n            \"Independent, near dem\" = \"Ind,near dem\",\n            \"Democrat, weak\"        = \"Not str democrat\",\n            \"Democrat, strong\"      = \"Strong democrat\",\n            \"Other\"                 = \"No answer\",\n            \"Other\"                 = \"Don't know\",\n            \"Other\"                 = \"Other party\"\n        )\n    )\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Independe… Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Republica… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Independe… Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Democrat,… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Democrat,… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Republica… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Independe… Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Democrat,… Prot… Other       0\n10  2000 Married          47 White $25000 or more Republica… Prot… Sout…       3\n# ℹ 21,473 more rows\n\n\nWe can use fct_collapse() to collapse many levels:\n\ngss_cat %&gt;%\n    mutate(\n        partyid = fct_collapse(partyid,\n            \"Other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n            \"Republican\" = c(\"Strong republican\", \"Not str republican\"),\n            \"Independent\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n            \"Democrat\" = c(\"Not str democrat\", \"Strong democrat\")\n        )\n    ) %&gt;%\n    count(partyid)\n\n# A tibble: 4 × 2\n  partyid         n\n  &lt;fct&gt;       &lt;int&gt;\n1 Other         548\n2 Republican   5346\n3 Independent  8409\n4 Democrat     7180\n\n\nExercises: Using the gss_cat dataset, try the following:\n\nMake a plot that shows the relationship between marital status (marital) and age in a way that makes a trend clear.\nMake a plot that shows the relationship between religion followed (relig) and income rincome. Combine income categories for better readability."
  },
  {
    "objectID": "activities.html",
    "href": "activities.html",
    "title": "Activities",
    "section": "",
    "text": "In-class activities"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework",
    "section": "",
    "text": "General instructions for homework:\n\nProcess section:\n\nOn getting help\n\nThings I Googled or asked on ChatGPT: There is no shame in having items here! But making note of this is important for noticing what you’re not “fluent” in yet. (e.g., when learning a new language, it would be helpful to write down words that you frequently have to look up to translate)\nThings I consulted with peers about\nOther resources that I consulted\n\nWhat was easy, medium, hard? Why?\n\n\nCommon elements of weekly homework:\n\nFirst part will always be to work on the most recent Tidy Tuesday."
  },
  {
    "objectID": "homework0.html",
    "href": "homework0.html",
    "title": "Homework 0",
    "section": "",
    "text": "A note from your instructor\n\n\n\nWhen I started college, the main thinking I did about my capital-F Future (that nebulous thing way out in the distance) was about what I would be doing after college. It made me very anxious.\nThrough the many years since my college experience, I have come to see that what allows me to be more at peace with my capital-F Future now is a deeper understanding of who I am and what my values are.\nI want to give you a chance to do this kind of thinking now with this “assignment”.\n\n\nI invite you to write an essay (tentatively) titled “My past, present and future and the values they express”. (Change the title if you wish!)\nThis essay does not need to be submitted and is not due at any point. If you ever wish to talk to me about what you wrote, the process of writing it, or what you’ve thought about after writing it, I’d love to do that over a walk or a cup of hot chocolate.\nI do hope that by writing it you are able to move forward with your college experience this semester with more peace and clarity. For that reason alone, I suggest that you write this essay by the end of the first week of class (Sunday, September 10).\nIt might be helpful to do/think about the following as you write:\n\nVisit this Values Exercise page to read a very short bit about core values and their role in a fulfilling life. Click the “Start the Exercise” button to complete a ~15 minute exercise to identify your core values.\nWhat events brought you to Macalester, and what core values do you think led you to choose Mac?\nWhere do you see yourself in 10 years? How do you see yourself living? What would it take to get to that point? To think through that process in steps, think about:\n\n10-year vision (what’s going on in 2033 and why?)\n5-year vision (what’s going on in 2028 and why?)\n2-year vision (what’s going on in 2025 and why?)\n1-year vision (what’s going on in 2024 and why?)\n6-month vision (what’s going on in Spring 2024 and why?)\nThinking about the “why” for these visions can help affirm and clarify the core values you ended up with from the Values Exercise above. For example, if part of your 5-year vision wasn’t happening, how would you feel and why?\n\n\nIf it helps at all to look at someone else’s vision as you craft your own, I tried to write my own 10-year vision earlier this summer."
  },
  {
    "objectID": "homework1.html",
    "href": "homework1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Required parts\nFinish the plot that we started in our Advanced Data Visualization in ggplot2 class activity up to the minimum requirements.\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework2.html",
    "href": "homework2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Required parts\n\nFinish the Open-ended Exercise in our Advanced Map Visualization class activity.\n\nSubmission details: Click the “Render” button to create an HTML report from your Quarto file. Open the HTML in your web browser and save the webpage as a PDF (Ctrl-P/Command P, choose “Save as PDF” as the Destination). Submit this PDF on Moodle AND the .qmd file by midnight on Wednesday, 9/20.\n\nComplete Milestone 1 of the course project. (Brainstorming ideas and data sources). Put this information in a # Project section that you add to the end of your 03-adv-maps.qmd.\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework3.html",
    "href": "homework3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Required parts\n\nFinish the Shiny app from the interactive viz class activity up to the minimum requirements.\n\nSubmission details: Submit the app.R file on Moodle by midnight on Wednesday, 9/27.\n\nWork towards Milestone 2 of the course project. (Nothing to turn in for Homework 3, but you should be making progress.)\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework4.html",
    "href": "homework4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Required parts\nDue Wednesday, October 4 by midnight on Moodle.\nComplete Milestone 2 of the course project.\n\nEach team member will submit their own .Rmd file and knitted HTML containing their own “rough draft” visualization to answer the team’s initial research question.\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "",
    "text": "This is the course website for STAT/COMP 212: Intermediate Data Science at Macalester College for the Fall 2023 semester taught by Professor Leslie Myint. Materials were developed by Leslie Myint and Brianna Heggeseth."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "10/3",
    "text": "10/3\n\nProject Milestone 2 can be turned in this Wednesday 10/4 or next Wednesday 10/11\nReflection 1 is due next Wednesday 10/11. (I’m still finishing writing out the prompts–I’ll send a Moodle message later today when it’s ready.)\nCheck out our Schedule.\n\nOn Thursday we’ll talk about writing functions.\nNext week we’ll talk about loops and iteration.\nMake note of Project progress presentations on 10/24 and 11/16."
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/28",
    "text": "9/28\n\nI thought we might be able to cover wrangling factors today, but we’ll save that for next Tuesday.\nLook at the updated Schedule page. The readings there are excellent references and can be read before or after class on Tuesday."
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/26",
    "text": "9/26\n\nIf you haven’t already found an initial dataset, peruse the Tidy Tuesday repository for ideas.\n\nHomework 4 (due next Wednesday 10/4) is to complete Project Milestone 2.\n\nThursday topics: wrangling strings (with regular expressions) and factors\nIn place of a standard Homework 5, we will have the first of 3 substantive reflections."
  },
  {
    "objectID": "index.html#section-3",
    "href": "index.html#section-3",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/19",
    "text": "9/19\n\nOn Thursday:\n\nWe will spend the first 30 moving our course projects moving forward.\nIn the last hour of class, facilitators will come in to run an activity for the Classroom Community and Connectedness Survey. (I will be leaving.) A reminder of why this activity is important to me from our syllabus:\n“A sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).”"
  },
  {
    "objectID": "index.html#section-4",
    "href": "index.html#section-4",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/14",
    "text": "9/14\n\nBefore next Tuesday’s class\n\nCheck the Schedule page. There is a short podcast segment (~7 min) to listen to and one guiding question to answer. This podcast segment shares a bit of wisdom about when it is/isn’t useful to make fancy visualizations.\nInstall the shiny and plotly packages. Post on the #questions channel on Slack if you run into problems. (Share your commands and error messages.)\n\nNext Thursday we will be having facilitators come in for the last hour of class for the Classroom Community and Connectedness Survey. (I will be leaving.)\n\nWe will use the first 30 to get our course projects moving forward."
  },
  {
    "objectID": "index.html#section-5",
    "href": "index.html#section-5",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/12",
    "text": "9/12\n\nHomework 1 due Wednesday at midnight (Finishing up the temperature + precipitation plots from last Tuesday)\n\nUpdated submission instructions can be found here. (Also in the most recent Moodle announcement.)\n\nHomework 2 due next Wednesday, 9/20 has two parts:\n\nFinish Open-ended Exercise from today’s Advanced Map Visualization activity.\nComplete Milestone 1 of the course project\n\nThere is a final version of our syllabus that incorporates the learning goals and grading option that we discussed on our first day."
  },
  {
    "objectID": "index.html#section-6",
    "href": "index.html#section-6",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/7",
    "text": "9/7\n\nI’ll be adding a new version of the syllabus to our course website that incorporates our final choice for grading system and the learning goals that you contributed.\nComplete the pre-course survey by 3pm today to shape when I hold drop-in hours (office hours).\nLook at the updated Schedule page. We have Guiding Questions for next Tuesday’s class: advanced map visualization.\n\nNote that Guiding Questions never have to be turned in. Do answer them to the best of your ability before class. We’ll spend time at the start of class checking in on these."
  },
  {
    "objectID": "index.html#section-7",
    "href": "index.html#section-7",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/5",
    "text": "9/5\nTo do before class on Thursday:\n\nSet up R and RStudio using these instructions.\nJoin our Slack workspace.\n\nUpdate your Slack profile with preferred name, pronouns, name pronunciation. (To find your profile, click on your name under Direct Messages on the left menu, and click “Edit Profile”.)\nIntroduce yourself in the #general channel.\n\nComplete the pre-course survey.\nLook at the Guiding Questions for Thursday’s class on advanced ggplot2.\nTake a look at Homework 0.\n\nThis is a personal essay that doesn’t need to be turned in.\nTopic: Your 10-year vision\nMy hope is that writing this allows gives you more clarity on how to align what you do this semester (and beyond) with who/what/how you want to be.\n\nFinish writing your 12 favorite problems and post them in the #12-favorite-problems channel on Slack.\n\nWhen you connect with peers from Thursday onward, you’ll be using your 12FPs to get to know each other a bit first before working on activities together."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "The goal of the project is to build something awesome that you can showcase on your digital portfolio (your personal website)."
  },
  {
    "objectID": "project.html#milestone-1",
    "href": "project.html#milestone-1",
    "title": "Project",
    "section": "Milestone 1",
    "text": "Milestone 1\nIdentify a data context that interests you. (Your 12 favorite problems might serve as a good source of inspiration.) Identify 3 different data sources that relate to that context. Think beyond a spreadsheet; the most interesting projects may involve collecting and aggregating data from multiple sources and formats. We might not have covered all of the tools needed to acquire that data at this point, so check in with the instructor about the sources that you’ve found to make sure that they’re workable.\n\nExample non-spreadsheet data sources: search results on a webpage, text of an article, Tweets, other social media posts.\n\nBrainstorm 3 questions about your data context and sources that pique your curiosity.\nDue date: Wednesday, 9/20 as part of HW2."
  },
  {
    "objectID": "project.html#milestone-2",
    "href": "project.html#milestone-2",
    "title": "Project",
    "section": "Milestone 2",
    "text": "Milestone 2\n\nForm project teams.\nFinalize one initial data source and questions related to that source.\nEach team member should create 1 “ugly” (not fully polished) visualization to demonstrate viability of the research questions. (Think of this as visualization “prototyping”.)\n\nDue date: Wednesday, 10/11 as part of HW4. (You can submit early on 10/4 if you’d like.)"
  },
  {
    "objectID": "project.html#milestone-3",
    "href": "project.html#milestone-3",
    "title": "Project",
    "section": "Milestone 3",
    "text": "Milestone 3\nPerform the data acquisition, wrangling, visualization, and modeling needed to address one of your research questions. Note that your question might not be amenable to modeling (or to modeling that you’ve learned about so far). For that reason, modeling is not required, but visualization is.\nDeliverable: Project progress presentation #1–to be presented in class on Tuesday 10/24.\n\nHow long? Prepare a 5-7 minute presentation.\nWhat should be in your presentation?\n\nAn introduction to your project domain/focus: What questions are you hoping to answer? What question are you focusing on right now? Why is this important to you?\nAn introduction to your data sources\nWho is impacted (whether positive or negatively) by your analysis? How are you addressing this?\nPresent a few polished visualizations and interpretations that address your current research question\n\nWhy am I asking you to do this?\n\nOrganizing your work for a short presentation is a good way to stay on track and guarantee some useful intermediate work\nBased on the Classroom Community and Connectedness survey results, there was a desire for more authentic collaboration. I feel that this type of class activity is fertile ground for true collaboration.\n\nWhat feedback will you receive?\n\nBased on the context you present, the instructor and your classmates will give feedback on any suggestions for ethical considerations in your analysis.\nWe will also give feedback on the clarity of your visualizations and your interpretations of them."
  },
  {
    "objectID": "project.html#milestone-4",
    "href": "project.html#milestone-4",
    "title": "Project",
    "section": "Milestone 4",
    "text": "Milestone 4\n(NOT FINALIZED YET)\nAdjust data sources and research questions as needed based on the results of explorations so far. Perform the data acquisition, wrangling, visualization, and modeling needed to address another one of your research questions.\nDeliverable: Project progress presentation #2–to be presented in class on Thursday 11/16.\n\nHow long? Prepare a 7 minute presentation.\nWhat should be in your presentation?\n\n\n\nWhy am I asking you to do this?\n\n\n\nWhat feedback will you receive?"
  },
  {
    "objectID": "project.html#milestone-5",
    "href": "project.html#milestone-5",
    "title": "Project",
    "section": "Milestone 5",
    "text": "Milestone 5\n(NOT FINALIZED YET)\nAdjust data sources and research questions as needed based on the results of explorations so far. Perform the data acquisition, wrangling, visualization, and modeling needed to address another one of your research questions. Submit “Final Draft”.\nDue date: TBD"
  },
  {
    "objectID": "reflection1.html",
    "href": "reflection1.html",
    "title": "Reflection 1",
    "section": "",
    "text": "Purpose\nThe goal of this reflection is to check in on your learning as related to the learning goals that we have addressed so far. Most importantly, it is a space for honest conversation between you and me.\n\n\n\nTask\nMake your own copy of this Google Doc, and follow the reflection prompts in that document."
  },
  {
    "objectID": "reflection1.html#advanced-data-visualization-in-ggplot2",
    "href": "reflection1.html#advanced-data-visualization-in-ggplot2",
    "title": "Reflection 1",
    "section": "Advanced data visualization in ggplot2",
    "text": "Advanced data visualization in ggplot2\nLearning goal: Create a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nExercise: Look at the graph below from the NYT article A Summer of Strikes.\n\n\n\n\n\n\nDraft a codebook of what variables would be needed to create the graph. Example codebook entry:\n\nsector: private sector or public sector job\n\nWrite ggplot2 code to “recreate” as much of this plot as possible. (You don’t have the data, but pretend that you had a dataset with exactly the variables in the codebook you created in step 1.)\n\nReflection: Using the 3 sources of feedback and reflection described above, reflect on your progress towards this learning goal. What patterns do you notice in your reflections and feedback? What is one part about this goal that you’re doing well? What is one part about this goal that you’d like to improve on? What can you do to continue making progress? What can the instructor do?"
  },
  {
    "objectID": "reflection1.html#map-visualization",
    "href": "reflection1.html#map-visualization",
    "title": "Reflection 1",
    "section": "Map visualization",
    "text": "Map visualization\nLearning goal: Wrangle and visualize spatial data\nExercise: Consider the making of maps with spatial datasets of the sf class. In what ways does making a plot with geom_sf parallel the making of “ordinary” plots in ggplot?\nReflection: Using the 3 sources of feedback and reflection described above, reflect on your progress towards this learning goal. What patterns do you notice in your reflections and feedback? What is one part about this goal that you’re doing well? What is one part about this goal that you’d like to improve on? What can you do to continue making progress? What can the instructor do?"
  },
  {
    "objectID": "reflection1.html#creating-interactive-apps",
    "href": "reflection1.html#creating-interactive-apps",
    "title": "Reflection 1",
    "section": "Creating interactive apps",
    "text": "Creating interactive apps\nLearning goal: Create interactive web applications and visualizations that adapt to user input\nExercise: Write the code for an app that allows the user to type in a number (call it num) and that displays the first num rows of a dataset called example_data.\nReflection: Using the 3 sources of feedback and reflection described above, reflect on your progress towards this learning goal. What patterns do you notice in your reflections and feedback? What is one part about this goal that you’re doing well? What is one part about this goal that you’d like to improve on? What can you do to continue making progress? What can the instructor do?"
  },
  {
    "objectID": "reflection1.html#data-wrangling",
    "href": "reflection1.html#data-wrangling",
    "title": "Reflection 1",
    "section": "Data wrangling",
    "text": "Data wrangling\nLearning goal: Wrangle arbitrarily messy data using functional programming tools in R\nExercise: Look back at our data wrangling activities (numbers, logicals, and dates, strings, and factors). For each type of data (5 total), write down 1 idea/tip/strategy that you want to keep in mind when wrangling that type of data.\nReflection: Using the 3 sources of feedback and reflection described above, reflect on your progress towards this learning goal. What patterns do you notice in your reflections and feedback? What is one part about this goal that you’re doing well? What is one part about this goal that you’d like to improve on? What can you do to continue making progress? What can the instructor do?"
  },
  {
    "objectID": "reflection1.html#reflection-skills",
    "href": "reflection1.html#reflection-skills",
    "title": "Reflection 1",
    "section": "Reflection skills",
    "text": "Reflection skills\nGoals:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(Class-contributed goal) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\n\nReflection: For this reflection, focus on what you’ve written in your Process and Reflection Log and your general impressions of how learning is going in class. What patterns do you notice in when you tend to reflect and what you tend to reflect on? What do you feel is going well regarding reflection? What would you like to improve on? What can you do to continue making progress? What can the instructor do?"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Readings in the schedule below refer to the following textbooks (freely available online):\n\nR for Data Science (2e) by Wickham, Cetinkaya-Rundel, and Grolemund (Abbreviated as R4DS)\nR Programming for Data Science (Abbreviated as RPDS)\nModern Data Science with R (3e) by Baumer, Kaplan, and Horton (Abbreviated as MDSR)\n\nGuiding questions for the readings are available at the bottom of this page.\n\n\n\n  \n    Week\n    Tuesday\n    Thursday\n    Announcements\n  \n\n\n\n  \n    1\n    \n    \n      9/5: Welcome! Meeting each other and designing our learning community \n      Before class: Review the syllabus and think about the questions posed in the green \"Reflect\" blocks.\n    \n    \n      9/7: Advanced visualization in ggplot \n      Before class: Review the construction of plots from STAT 112 and STAT 155. Answer the Guiding Questions at the bottom of this page. \n    \n    \n    \n      Work on HW0 (your 10-year vision, doesn't need to be turned in).Look ahead to HW1\n    \n  \n  \n  \n  \n  \n    2\n    \n      9/12: Advanced map visualization \n      Before class: Watch this video on Coordinate Reference Systems, and answer the Guiding Questions at the bottom of this page.\n    \n    \n    \n      9/14: Advanced map visualization (continued) \n    \n    \n    Turn in HW1 by midnight on Wed 9/13. Look ahead to HW2 due Wednesday 9/20 at midnight.\n  \n  \n  \n  \n  \n    3\n    \n      9/19: Interactive visualization \n      Before class: Listen to this podcast from Chapter 7 (timestamp 18:09) through Chapter 8 (ending at timestamp 25:27). Answer the Guiding Question at the bottom of this page. Install the \"shiny\" and \"plotly\" R packages.\n    \n    \n    \n      9/21: Classroom Community and Connectedness (CC&C) Survey \n      For the first 30 minutes, we will move our course projects forward. In the last hour of class, CC&C facilitators will come in to run an activity on how community-building is going in our course.\n    \n    \n    Turn in HW2 by midnight on Wednesday 9/20. Look ahead to HW3.\n  \n  \n  \n  \n  \n    4\n    \n      9/26: Data wrangling: numbers, logicals, and dates\n      Helpful readings (read before or after class): (All from R4DS) Chapter 13 (Logicals), Chapter 14 (Numbers), and Chapter 18 (Dates/Times)\n    \n    \n    \n      9/28: Data wrangling: strings \n      Helpful readings (read before or after class): (All from R4DS) Chapter 15 (Strings) and Chapter 16 (Regular Expressions)\n    \n    \n    Turn in HW3. Look ahead to HW4 (Project Miletone 2).\n  \n  \n  \n  \n  \n    5\n    \n      10/3: Data wrangling: factors \n      Helpful readings (read before or after class): Chapter 17 (Factors) (R4DS).\n    \n    \n    \n      10/5: Writing functions \n      Helpful readings (read before or after class): R4DS Chapter 26 (Functions) and RPDS Section 13.1 (if-else). \n    \n    \n    Turn in Project Milestone 2 by either Wed 10/4 or Wed 10/11 at midnight. Start looking at Reflection 1.\n  \n  \n  \n  \n  \n    6\n    \n      10/10: Loops and iteration \n      Helpful readings (read before or after class): Chapter 27 (Iteration) and this tutorial. \n    \n    \n    \n      10/12: Loops and iteration \n      Helpful readings (read before or after class): Chapter 22 (Databases).\n    \n    \n    Turn in HW4 (Project Milestone 2) by Wed 10/11 if you haven't already. Turn in Reflection 1 by Wed 10/11.\n  \n  \n  \n  \n  \n    7\n    \n      10/17: Data acquisition: APIs \n      Helpful readings (read before or after class): Getting started with httr \n    \n    \n    \n      10/19: Data acquisition: Scraping \n      Helpful readings (read before or after class): rvest vignette \n    \n    \n    \n  \n  \n  \n  \n  \n    8\n    \n      10/24: Project feedback & styling your personal site with HTML and CSS \n      Project progress presentation #1: Your team will present a 5-7 minute progress report and plan for next steps \n      After project presentations, we will learn a bit more about HTML and CSS so that you can style your personal websites.\n    \n    \n    \n      10/26: No class - Fall Break 🍁\n    \n    \n    \n  \n  \n  \n  \n  \n    9\n    \n      10/31: Data acquisition: databases \n      Helpful readings (read before or after class): R4DS Chapter 22 (Databases).\n    \n    \n    \n      11/2: Causal inference and machine learning in data science\n    \n    \n    \n  \n  \n  \n  \n  \n    10\n    \n      11/7: Missing data: wrangling and missingness mechanisms \n      Helpful readings (read before or after class): R4DS Chapter 22 (Databases).\n    \n    \n    \n      11/9: Missing data: imputation\n    \n    \n    \n  \n  \n  \n  \n  \n    11\n    \n      11/14: Likely Python, GitHub, and topics of your choosing from this poitn onward \n    \n    \n    \n      11/16: Project presentations \n      Project progress presentation #2: Your team will give a 10 minute presentation with intermediate results for 2 research questions."
  },
  {
    "objectID": "schedule.html#advanced-visualization-in-ggplot",
    "href": "schedule.html#advanced-visualization-in-ggplot",
    "title": "Schedule",
    "section": "9/7: Advanced visualization in ggplot",
    "text": "9/7: Advanced visualization in ggplot\nTo review plot creation skills from STAT/COMP 112 and STAT 155, use the diamonds dataset in the ggplot2 package to recreate the following visualizations:\n\nlibrary(ggplot2)\ndata(diamonds)"
  },
  {
    "objectID": "schedule.html#advanced-map-visualization",
    "href": "schedule.html#advanced-map-visualization",
    "title": "Schedule",
    "section": "9/12: Advanced map visualization",
    "text": "9/12: Advanced map visualization\nAfter/while watching this video on Coordinate Reference Systems (CRS), answer the following questions:\n\nWhat is the shape of the Earth?\nWhy is GDA94 a great datum name?\nWhat are the two components of a CRS/GCS?\nWhy do we use many different local CRSs rather than just one CRS for the whole earth?\nWhy is it insufficient to identify a location by its latitude and longitude?\nWhy do we need to be mindful about CRSs when working with different spatial datasets?"
  },
  {
    "objectID": "schedule.html#interactive-visualization",
    "href": "schedule.html#interactive-visualization",
    "title": "Schedule",
    "section": "9/19: Interactive visualization",
    "text": "9/19: Interactive visualization\nAfter listening to this podcast from Chapter 7 (timestamp 18:09) through Chapter 8 (ending at timestamp 25:27), reflect on the following question:\n\nWhat was new, unexpected, or interesting in the discussion about animations, interactivity, and dashboards?"
  },
  {
    "objectID": "slides/02-adv-ggplot.html#welcome-back",
    "href": "slides/02-adv-ggplot.html#welcome-back",
    "title": "Day 2",
    "section": "Welcome back!",
    "text": "Welcome back!\nAs we prepare to gather as a class, think about the following:\n\nWhat themes emerge in your 12 favorite problems? (You’ll be sharing with partner(s) today.)\n\nRandom\n\nHow do you pronounce the name Sean Bean? 😆\n\nQuote of the day\n\nYou don’t rise to the level of your goals. You fall to the level of your systems.\n\nJames Clear, Atomic Habits"
  },
  {
    "objectID": "slides/03-adv-maps.html#as-we-gather",
    "href": "slides/03-adv-maps.html#as-we-gather",
    "title": "Advanced Spatial Visualizations",
    "section": "As we gather…",
    "text": "As we gather…\nCheck in with those around you–how is the semester going so far?\nOpen up your Process and Reflection Log (Google Doc)."
  },
  {
    "objectID": "slides/03-adv-maps.html#as-we-gather-1",
    "href": "slides/03-adv-maps.html#as-we-gather-1",
    "title": "Advanced Spatial Visualizations",
    "section": "As we gather…",
    "text": "As we gather…\nSit next to someone new. Share a favorite problem that helps you feel curious this week. In talking with your partner, what connections do you see to your own FPs?\nQuote of the day:\n\nThe more stuff you love the happier you will be.\n― Ross Gay, The Book of Delights\n\nOpen up your Process and Reflection Log (Google Doc).\n\nReshare it with me so that I can be a Commenter, and check the “Notify people” box.\nLeave it open. We are going to stop and reflect a few times today."
  },
  {
    "objectID": "slides/04-interactive-viz.html#as-we-gather",
    "href": "slides/04-interactive-viz.html#as-we-gather",
    "title": "Interactive visualization",
    "section": "As we gather…",
    "text": "As we gather…\nThink about what makes learning new code challenging for you and what strategies tend to work well or less well. You will work with someone random (and possibly new)–how can you best support your own and their learning?\nQuote of the day:\n\nIn fact, in addition to the fact that we all die, the most salient or unifying feature of we the living is that we cannot survive without help.\n― Ross Gay, Inciting Joy\n\nOpen up your Process and Reflection Log (Google Doc).\n\nLeave it open. We are going to stop and reflect a few times today."
  },
  {
    "objectID": "slides/04-interactive-viz.html#reflecting-on-our-shiny-activity",
    "href": "slides/04-interactive-viz.html#reflecting-on-our-shiny-activity",
    "title": "Interactive visualization",
    "section": "Reflecting on our Shiny activity",
    "text": "Reflecting on our Shiny activity\nComment/uncomment the selected lines—super useful for debugging!!\n\nMac: Command-Shift-C\nWindows: Ctrl-Shift-C\n\nWrite a few observations in your Process and Reflection Log (Google Doc):\n\nWhat was challenging about learning Shiny? (When) did things start to click?\nWe’ve worked with a few different partners now–in general what has been helpful/less helpful about working with others? What would you like to change in the future?"
  },
  {
    "objectID": "slides/05-data-types-1.html#as-we-gather",
    "href": "slides/05-data-types-1.html#as-we-gather",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "As we gather…",
    "text": "As we gather…\nNavigate to our course page and activity: “Wrangling: numerics, logicals, dates”. Open the slides linked under the Learning Goals\nImage of the day:\n\nElderly woman, drinking in the momentOpen up your Process and Reflection Log (Google Doc)."
  },
  {
    "objectID": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief",
    "href": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Classroom Community and Connectedness debrief",
    "text": "Classroom Community and Connectedness debrief\nSection 1\n\nWhile working in groups on activities was seen as a strength, it was also something that has challenges\n\nMeeting and getting to know new people is hard–especially in a classroom environment\n\nThings that I can do\n\nChange groups regularly\nCreate spaces for more authentic and collaborative group work\nOut-of class opportunities for hanging out (with food!?)\n\nThings that you can do\n\nA number of you mentioned that you yourselves wanted to better at fostering community\n\n\nNote: reflection regarding group work is one of my top learning goals not because I want to judge/evaluate you on it but because I value it. Across your 3 substantive reflections, I just want to give feedback. I won’t give mandates that you have to follow “or else”."
  },
  {
    "objectID": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief-1",
    "href": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief-1",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Classroom Community and Connectedness debrief",
    "text": "Classroom Community and Connectedness debrief\nSection 2\n\nWhile working in groups on activities was seen as a strength, it was also something that has challenges\n\n“Clicking” with others is not always easy\n\nThings that I can do\n\nBe mindful of class dynamics and energy\nCreate spaces for more authentic and collaborative group work\nOut-of class opportunities for hanging out (with food!?)\n\nThings that you can do\n\nA number of you mentioned trying to be more compassionate and collaborative\n\n\nNote: reflection regarding group work is one of my top learning goals not because I want to judge/evaluate you on it but because I value it. Across your 3 substantive reflections, I just want to give feedback. I won’t give mandates that you have to follow “or else”."
  },
  {
    "objectID": "slides/05-data-types-1.html#project-team-formation-activity",
    "href": "slides/05-data-types-1.html#project-team-formation-activity",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Project team formation activity",
    "text": "Project team formation activity\nOpen up this Google Jamboard.\n\nOn a sticky note (left menu), write down the general domain of your ideal project (e.g., environmental/climate issues) and your name.\nOnce everyone is done, work together to group the sticky notes into clusters such that an even number is in each group.\nWithin these groups, re-introduce yourselves and share more specific details about your desired project (e.g., specific research ?s and possible data sources).\nForm teams (pairs) for your project and decide on a contact/communication strategy outside of class."
  },
  {
    "objectID": "slides/05-data-types-1.html#about-project-teams-and-pods",
    "href": "slides/05-data-types-1.html#about-project-teams-and-pods",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "About project teams and “pods”",
    "text": "About project teams and “pods”\nWe’ll try out sitting in project pairs to better facilitate community and connection. We’ll do a little bit of project work each class period.\nOn feedback days, pairs will sit with other pairs with similar project domains and different domains. Having this variety of feedback will be important for the quality of your project."
  },
  {
    "objectID": "slides/05-data-types-1.html#thursday-project-work",
    "href": "slides/05-data-types-1.html#thursday-project-work",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Thursday: project work",
    "text": "Thursday: project work\nMilestone 2 is about finding an initial dataset and each team member creating one “rough draft” visualization to answer one of your research questions.\nI highly recommend using the Tidy Tuesday repository to locate an initial dataset if you don’t already have one. (The dataset doesn’t have to be a perfect match for your questions.)"
  },
  {
    "objectID": "slides/day1.html#plan-for-today",
    "href": "slides/day1.html#plan-for-today",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Plan for today",
    "text": "Plan for today\n\nWhat is this course about?\nGet to know your classmates\nShaping our syllabus together\nCreate your personal website!\n\nWebsite content building + connecting with classmates"
  },
  {
    "objectID": "slides/day1.html#what-is-this-course-about",
    "href": "slides/day1.html#what-is-this-course-about",
    "title": "Welcome to Intermediate Data Science!",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nExpanding your abilities for self-reflection in service of:\n\nYour lifelong independent learning\nOur course community\n\nExpanding your data science toolbox:\n\nVisualization\nWrangling\nData acquisition\nData storytelling\n\n\nI’ve intentionally put reflection first and data science skills second not necessarily in order of importance but because cultivating data science skills will come automatically—reflection and community-building won’t."
  },
  {
    "objectID": "slides/day1.html#get-to-know-your-classmates",
    "href": "slides/day1.html#get-to-know-your-classmates",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Get to know your classmates",
    "text": "Get to know your classmates\nIn groups, introduce yourselves with the following prompts: (~2 minutes/person)\n\nName, preferred pronouns\nMacalester connections (e.g., majors/minors/concentrations, clubs, teams, events regularly attended)\nHow are you feeling about starting the academic year?\nWhat is one thing you wish came up more in conversation?\nIf you could use data to investigate anything, what would it be?\n\nWhen we come back together, you will introduce someone else from your group briefly with:\n\nTheir name and preferred pronouns\n1 memorable thing you learned about them from your conversation"
  },
  {
    "objectID": "slides/day1.html#syllabus-shaping-learning-goals",
    "href": "slides/day1.html#syllabus-shaping-learning-goals",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Syllabus shaping: learning goals",
    "text": "Syllabus shaping: learning goals\nNavigate to the Course learning goals section of our syllabus.\nPart 1: Reflect (~3 min)\nWrite a few sentences responding to the following questions:\n\nWhat are your goals in taking this class?\nDo you see your goals reflected in the course learning goals? If not, how would you like to see the course goals amended to see your goals reflected in them?\n\nPart 2: Share (~5 min)\nAt your tables, take turns sharing your responses to the above questions. As a group, summarize your discussion in this Google Doc. Elect 1 person to present this summary when we come together as a class to share."
  },
  {
    "objectID": "slides/day1.html#my-qualms-with-grades",
    "href": "slides/day1.html#my-qualms-with-grades",
    "title": "Welcome to Intermediate Data Science!",
    "section": "My qualms with grades",
    "text": "My qualms with grades\nGrades (final and intermediate letter grades/points) make me uncomfortable because they:\n\nTend to distract from learning (due to a greater focus on the grade than on qualitative feedback)\nCreate anxiety that hinders risk-taking and exploration\nCreate a power dynamic between me and you that I am uncomfortable with. (I feel like a gatekeeper.)\n\nIf I had my way, I would never assign letter grades and only give qualitative comments all semester. Unfortunately, I am required to submit a letter grade at the end of the course.\n\nI need your input: which of the following two grading systems should we use for the semester?"
  },
  {
    "objectID": "slides/day1.html#option-1",
    "href": "slides/day1.html#option-1",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Option 1",
    "text": "Option 1\nSummary: evaluation of learning is done by instructor\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nPass all homework assignments\nPass all but 1 homework assignment\nPass all but 2 homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects"
  },
  {
    "objectID": "slides/day1.html#option-2",
    "href": "slides/day1.html#option-2",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Option 2",
    "text": "Option 2\nSummary: evaluation of learning is done by students in conversation with instructor\nMain difference: The standards below are the basis for your self-evaluation. I will join in on the conversation after reviewing your work and your self-evaluation. We will assign grades through conversation.\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects"
  },
  {
    "objectID": "slides/day1.html#syllabus-shaping-grading-system",
    "href": "slides/day1.html#syllabus-shaping-grading-system",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Syllabus shaping: grading system",
    "text": "Syllabus shaping: grading system\nNavigate to the Grading and feedback section of our syllabus to refer to details of the two grading options as needed.\nPart 1: Reflect (~5 min)\nWrite a few sentences responding to the following questions:\n\nWhich of the two options would be better for motivating you to learn as much as possible, and why? For reducing stress?\nWith regards to motivation and stress, are there any other parts of the course (not directly related to the grading system) that you think would benefit from changing?\n\nPart 2: Share (~10-15 min)\nAt your tables, take turns sharing your responses to the above questions. As a group, summarize your discussion in this Google Doc. Elect 1 person to present this summary when we come together as a class to share."
  },
  {
    "objectID": "slides/day1.html#start-your-personal-website-quarto",
    "href": "slides/day1.html#start-your-personal-website-quarto",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Start your personal website: Quarto",
    "text": "Start your personal website: Quarto\nFile &gt; New Project &gt; New Directory &gt; Quarto Website\n\nName the directory personal_website.\nPut this directory in a place you’ll access beyond this course (and beyond Mac)\n\nSome files will get created in the directory, and your newly created website will open in your browser."
  },
  {
    "objectID": "slides/day1.html#your-quarto-site-what-are-these-files",
    "href": "slides/day1.html#your-quarto-site-what-are-these-files",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Your Quarto site: what are these files?",
    "text": "Your Quarto site: what are these files?\nQuarto markdown files: The formatting in these files is almost identical to RMarkdown files (e.g., * for italics, ** for bold, # for headers).\n\nindex.qmd: This generates the content on the Home page.\nabout.qmd: This generates the content on the About page.\n\nOther files:\n\n_quarto.yml: Controls metadata about the website and how it should be built\nstyles.css: Controls the visual appearance of the site (e.g., color themes, fonts, spacing)\n\nWARNING: The more you know about CSS, the more addicting it is! It is very easy to unintentionally spend hours playing with colors and site appearance. 😆"
  },
  {
    "objectID": "slides/day1.html#todays-goal-the-about-page",
    "href": "slides/day1.html#todays-goal-the-about-page",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Today’s goal: the “About” page",
    "text": "Today’s goal: the “About” page\nOne of the first questions that comes up in every job interview is a question about yourself: “Tell me about yourself. How did you get to this point? What type of work do you want to do?”\nCrafting your homepage and About page can help you prepare for this question and have benefits even before the interview.\nLet’s take a look at an approach for crafting a thoughtful about page."
  },
  {
    "objectID": "slides/day1.html#some-context",
    "href": "slides/day1.html#some-context",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Some context",
    "text": "Some context\nRichard Feynman was a Nobel prize-winning physicist whose contributions fundamentally reshaped our understanding of the physical world.\nA major part of his success was a method for viewing the world: a mindset of viewing the world through the lens of several open-ended questions. Feynman called these his “favorite problems.” He said of these problems:\n\nYou have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did [they] do it? [They] must be a genius!”\nQuote source: Forte Labs"
  },
  {
    "objectID": "slides/day1.html#the-12-favorite-problems-framework",
    "href": "slides/day1.html#the-12-favorite-problems-framework",
    "title": "Welcome to Intermediate Data Science!",
    "section": "The 12 Favorite Problems framework",
    "text": "The 12 Favorite Problems framework\nEveryone can generate a list of their own 12 favorite problems - a set of meaningful open-ended questions that allow you to learn, explore, and act with intention on your biggest interests in life. Their benefits:\n\n\nDedicate your time and attention to ideas that truly spark your curiosity\nSee how a piece of information might be useful and why it’s worth keeping\nSee insightful patterns across multiple subjects that seem unrelated, but might share a common thread\nFocus the impact of your work on problems where you can make a real difference\nPrime your subconscious to notice helpful solutions to your biggest challenges in the world around you\nAttract like-minded people who have the same interests and goals as you\n\nSource: Forte Labs"
  },
  {
    "objectID": "slides/day1.html#brainstorming-our-12-favorite-problems-fps",
    "href": "slides/day1.html#brainstorming-our-12-favorite-problems-fps",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Brainstorming our 12 favorite problems (FPs)",
    "text": "Brainstorming our 12 favorite problems (FPs)\nNavigate to this article by Tiago Forte, and scroll down to the first step “Get started with these prompts.”\nWe’ll take 15-20 minutes to brainstorm our 12 FPs in the about.qmd file of your new website project.\nTiago Forte provides examples of his 12 FPs in his post. Feel free to also look at my own for more examples. (I’m working on updating my 12 FPs today alongside you!)\nWhat does this have to do with data science?? The 12 FP framework is a way of filtering the deluge of information thrown at us to the precious subset that matter most to our deepest questions. In other words, using data of all forms most effectively in our day-to-day lives. I truly believe that adopting this approach will help you become the kinds of data scientists who will be invaluable wherever you go."
  },
  {
    "objectID": "slides/day1.html#sharing-our-12-fps",
    "href": "slides/day1.html#sharing-our-12-fps",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Sharing our 12 FPs",
    "text": "Sharing our 12 FPs\nIn groups, each person will have ~2 minutes to share their top 2 FPs and get some feedback from the group. The group should give feedback to help make the FPs more specific, counterintuitive, and interdiscipinary:\n\nSpecific:\n\nOriginal: “How can I be a better leader?” is a little broad.\nPossible improvement: “How can I be a better leader as an introvert?”\n\nCounterintuitive:\n\nOriginal: “How can I improve the standard of living in the global south?”\nPossible improvement: “How can I improve the standard of living in the global south without further contributing to the climate change that threatens those regions the most?”\n\nInterdisciplinary:\n\nOriginal: How can I improve education?”\nPossible improvement: “How can I improve education by borrowing ideas from video games?”\n\n\n(Examples from Forte Labs)"
  },
  {
    "objectID": "slides/day1.html#free-time",
    "href": "slides/day1.html#free-time",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Free time",
    "text": "Free time\nThe remainder of the class period is free time. Some suggestions for spending the time:\n\nGet up and sit with new people. Share your 12 FPs with each other and get further feedback.\nKeep working on your website. Google to learn more about CSS and play with the appearance of your page in the styles.css file.\nClarify anything about the course with me."
  },
  {
    "objectID": "slides/day1.html#announcements",
    "href": "slides/day1.html#announcements",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Announcements",
    "text": "Announcements\nTo do before class on Thursday:\n\nSet up R and RStudio using these instructions.\nJoin our Slack workspace.\n\nUpdate your Slack profile with preferred name, pronouns, name pronunciation. (To find your profile, click on your name under Direct Messages on the left menu, and click “Edit Profile”.)\nIntroduce yourself in the #general channel.\n\nComplete the pre-course survey.\nLook at the Guiding Questions for Thursday’s class on advanced ggplot2.\nTake a look at Homework 0.\n\nThis is a personal essay that doesn’t need to be turned in.\nTopic: Your 10-year vision\nMy hope is that writing this allows gives you more clarity on how to align what you do this semester (and beyond) with who/what/how you want to be.\n\nFinish writing your 12 favorite problems and post them in the #12-favorite-problems channel on Slack.\n\nWhen you connect with peers from Thursday onward, you’ll be using your 12FPs to get to know each other a bit first before working on activities together."
  },
  {
    "objectID": "syllabus_final.html",
    "href": "syllabus_final.html",
    "title": "Final Syllabus",
    "section": "",
    "text": "Nature doesn’t reveal its secrets easily. - Thomas Kempa\n\nNor do data.\nBut that is exactly what can make data science so thrilling!\nThis course is about empowering you with the wisdom to ask the best questions of data–ones that are meaningful, adaptive, and equity-minded–and the technical savvy to answer them.\nBecause your careers (whether in data science or not), will all involve further learning and working with others, my other primary goal is for you to cultivate self-reflection skills with regards to your own learning and your collaboration with others. In this way, I hope that you feel confident learning new skills on your own in the future and contributing to a welcoming work community.\n\n\n\n\n\n\nCourse catalog description\n\n\n\n\n\nThis second course in the data science curriculum emphasizes advanced data wrangling and manipulation, interactive visualization, writing functions, working with data in databases, version control, and data ethics. Through open-ended and interdisciplinary projects, students practice the constant feedback loop of asking questions of the data, manipulating the data to help answer the question, and then returning to more questions. Prerequisite(s): COMP 112 and COMP 123 and STAT 155; STAT 253 recommended but not required.\n\n\n\n\n\nBy the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(+) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases (*)\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python (*)\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\n\n(+) Collect data ethically in a way that doesn’t undermine communities and people\n\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nYour feedback\n\n\n\nBased on our first day of class discussions, I’ve indicated with a (+) clarifications/details that you added to our existing learning goals and put a (*) next to existing goals that were underscored as desired ones."
  },
  {
    "objectID": "syllabus_final.html#course-learning-goals",
    "href": "syllabus_final.html#course-learning-goals",
    "title": "Final Syllabus",
    "section": "",
    "text": "By the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(+) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases (*)\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python (*)\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\n\n(+) Collect data ethically in a way that doesn’t undermine communities and people\n\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nYour feedback\n\n\n\nBased on our first day of class discussions, I’ve indicated with a (+) clarifications/details that you added to our existing learning goals and put a (*) next to existing goals that were underscored as desired ones."
  },
  {
    "objectID": "syllabus_final.html#how-to-contact-me",
    "href": "syllabus_final.html#how-to-contact-me",
    "title": "Final Syllabus",
    "section": "How to contact me",
    "text": "How to contact me\n\n\n\n\n\n\nCall me “Leslie”\n\n\n\nStudents sometimes wonder what to call their professors. I prefer to be called Leslie (lez-lee), but if you prefer to be more formal, I am also ok with Professor Myint (pronounced “mee-int”). My preferred gender pronouns are she/her/hers.\nPlease help me make sure that I call you by your preferred name and pronouns too!\n\n\nI love getting to talk to students outside of class time—whether about class-related topics or anything else. Come chat with me!\nI’ll be setting times for drop-in hours based on feedback from the pre-course survey. I’ll update my drop-in hours on our course homepage and Moodle when they’re finalized.\nI’m also happy to meet one-on-one if my normal drop-in hours don’t work. You can schedule a time to meet with me via Calendly.\nI’ll also often be in the Leonard Center weight room from about 4:30-5:10 some weekdays. Feel free to say hello!"
  },
  {
    "objectID": "syllabus_final.html#discussion-board-slack",
    "href": "syllabus_final.html#discussion-board-slack",
    "title": "Final Syllabus",
    "section": "Discussion board (Slack)",
    "text": "Discussion board (Slack)\nSlack is a commonly used communication tool in industry and is useful to be familiar with, so we’ll be using it as our discussion board.\n\nIf you’re new to Slack, this video provides a quick overview.\nFirst join our STAT/COMP 212: Fall 2023 workspace here.\nAfter joining, you can access our workspace here. (You might want to bookmark this if you have Slack open in your web broswer.)"
  },
  {
    "objectID": "syllabus_final.html#community-is-key",
    "href": "syllabus_final.html#community-is-key",
    "title": "Final Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nOur class is participating in the Classroom Community & Connectedness Project this semester. On Thursday, September 21 our class sessions will be a facilitated class activity (peers and facilitators only; I will not be present) to collectively reflect on strengthening our classroom community, with the intent of improving the learning environment for all of us.\nYour participation is voluntary, but very much appreciated. The project is co-sponsored by Macalester’s Serie Center for Scholarship and Teaching and our Office of Institutional Research & Assessment."
  },
  {
    "objectID": "syllabus_final.html#reflection-is-paramount",
    "href": "syllabus_final.html#reflection-is-paramount",
    "title": "Final Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that as technology evolves, some part of it will become out of date during your careers. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content–it’s fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection as a goal for our course in both content learning and collaborative activities. (Note that these reflection goals are the first two course learning goals.)"
  },
  {
    "objectID": "syllabus_final.html#mistakes-are-essential",
    "href": "syllabus_final.html#mistakes-are-essential",
    "title": "Final Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field. - Niels Bohr, Nobel Prize-winning physicist\n\nI don’t feel comfortable working with a new R package until I’ve seen the same errors over and over again. Seeing new errors helps me understand the constraints of the code and the assumptions that I was making about my data.\nWe’re going to be seeking out mistakes like my cats hunt for leftover food scraps.\n\n\n\nMy cat Potato attempting to eat my daughter’s dinner"
  },
  {
    "objectID": "syllabus_final.html#communication-is-a-superpower",
    "href": "syllabus_final.html#communication-is-a-superpower",
    "title": "Final Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas–whether through writing, visuals, or oral presentation–I want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What’s more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n— David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus_final.html#outside-of-class",
    "href": "syllabus_final.html#outside-of-class",
    "title": "Final Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class reading: Most class periods will have a required reading to review ideas from previous courses or to familiarize yourself with new concepts before seeing them again in class. My goal for these readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. I will provide Guiding Questions for each reading to focus your attention.\n\n\n\n\n\n\nSuggestion\n\n\n\nScan the Guiding Questions before reading to preview the main ideas. Fill in answers to these questions as you read. Ask (and answer!) questions in the #questions channel in our Slack workspace.\n\n\nPodcast discussions: About every other week, we will discuss a podcast for the first ~20 minutes of class. These podcasts are meant to expose you aspects of data science in industry. Record anything that you’re curious about, and come prepared to discuss.\n\n\n\n\n\n\nYour own media contributions\n\n\n\nThroughout the semester, if you come across any media that is relevant to the course, feel free to suggest it as a discussion piece by emailing the instructor or posting it in the #general channel in our Slack workspace.\n\n\n\n\n\n\n\n\nOther suggestions for out-of-class time\n\n\n\n\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the weekly homework.\nCome to instructor drop-in hours to chat about the course or anything else 😃"
  },
  {
    "objectID": "syllabus_final.html#during-class",
    "href": "syllabus_final.html#during-class",
    "title": "Final Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.) I’ll always leave a few minutes at the end of class for synthesis. Use this time to update your reflections and summarize the key takeaways from class."
  },
  {
    "objectID": "syllabus_final.html#instructors-philosophy",
    "href": "syllabus_final.html#instructors-philosophy",
    "title": "Final Syllabus",
    "section": "Instructor’s philosophy",
    "text": "Instructor’s philosophy\nFor a long time, I have been uncomfortable with the outsized role that letter grades play in education. The article Teaching More by Grading Less (Or Differently) by Schinske and Tanner (source) shaped many of my viewpoints and may be an interesting read for you.\nIn short, grades tend to distract from learning (due to a greater focus on the grade than on qualitative feedback), create anxiety that hinders risk-taking and exploration, and create a power dynamic between the instructor and students that I am uncomfortable with.\nIf I had my way, I would never assign letter grades and only give qualitative comments all semester. Unfortunately, I am required to submit a letter grade at the end of the course.\n\nThere were two grading options presented in the preliminary syllabus. The consensus of both course sections was Option 2, which is detailed below."
  },
  {
    "objectID": "syllabus_final.html#grading-system",
    "href": "syllabus_final.html#grading-system",
    "title": "Final Syllabus",
    "section": "Grading system",
    "text": "Grading system\n\nOverview\nIn the grading system chosen, evaluation (assigning of letter grades) occurs as a conversation between you and me–a conversation that you start. Using the qualities of A, B, and C letter grades (section below), you will self-assess your work using more detailed evaluation guidelines provided in reflection prompts and comments on your work. As part of this assessment you will propose your letter grade. I will also do this evaluation on my own and read your self-assessment afterwards. We will use all of this information to have a conversation about your progress. If we agree on the letter grade, that will be the grade you receive. If we disagree, we will use our conversation to come to a consensus. As part of consensus-building, we may discuss reframing both of our perspectives or additional work/revisions.\nI recognize that no single grading system can be ideal for everyone, but I do hope that the reflection, honesty, and conversation that are central to this system support your learning. Please reach out to me if something could be going better for you. I am always willing to talk. It’s your education–I want you to have a voice in it.\n\n\nWhat kind of work characterizes A, B, and C grades?\nThe table below describes the qualities of A, B, and C grades in terms of the 3 core course components: reflections, homework, and the final project.\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\nDetails about the course components are given below:\n\nSelf-reflection:\n\nWe will look at the growth in your reflection process over the course of 3 substantive reflections. These will roughly come a month into the course, mid-course, and the end of the semester.\n\nMy expectation is that your mid-course and end-of-course reflections show that your are using feedback from previous reflections.\n\nWe will look at the consistency in your reflection process by monitoring your Process and Reflection Google Doc.\n\nMy expectation is that you are filling this in regularly throughout class activities and through work outside of class.\n\n\nHomework: We will have weekly homework in which you will complete activities that we start in class. The requirements for passing the assignment will be clearly stated in the homework directions.\n\nIf you do not pass an assignment and wish to revise your work, you may resubmit the assignment the following week. This revision needs to be submitted by 2 weeks after the original homework due date. (See my policy on late work.)\n\nFinal project: For this semester-long project, you will receive regular feedback on the quality of the different project aspects and will have the opportunity to improve the quality of the different aspects as you continue working.\n\n\n\nHow will course components be evaluated?\nIn each of the 3 substantive reflections (month, mid-semester, end-of-semester), you will evaluate yourselves using self-assessment prompts and qualitative feedback from me on your reflections, homework, and project work.\nFor each of the 3 substantive reflections, you will receive a prompt that guides you through how to look at your work, my comments, solutions, and prior reflections to craft your self-assessment on your reflection process, homework, and project work. I will use the same prompts/process to assess your work before we come together for conversation.\nNote: Your self-assessments need to be based on demonstrated evidence in the work that you submit. For example, if you have struggled with the data wrangling homework assignments and say in your self-evaluation that your understanding is now strong after reviewing feedback, this is not sufficient evidence. You would need to demonstrate your stronger understanding of data wrangling by submitting a revision of the data wrangling homework. (See policy on late work.)"
  },
  {
    "objectID": "syllabus_final.html#late-work",
    "href": "syllabus_final.html#late-work",
    "title": "Final Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will be due weekly on Wednesdays at midnight. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. Limited extensions will always be granted:\n\nMy ideal extension: Turn in the homework by the following Monday morning at 9am. (A 4 day, 9 hour extension)\n\nWhy is this ideal for me? I want to return feedback on homework to everyone before the following Tuesday’s class because we will be briefly reviewing homework feedback in small groups.\n\nFirm limit on extensions: You must turn in the homework by 2 weeks after the due date (Wednesdays at 9am).\n\nWhy is this my firm limit? I post solutions to the homework at this point.\nWhat if it’s past the 2-week limit and you still want to turn in the homework in some form? If this is the case, you need to create your own equivalent homework. This involves mapping the original homework’s exercises to a new dataset and completing those exercises. Note that I can’t make any guarantees about when I can get you feedback on this late submission. (Only guarantee = by the end of the semester)"
  },
  {
    "objectID": "syllabus_final.html#academic-integrity",
    "href": "syllabus_final.html#academic-integrity",
    "title": "Final Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus_final.html#artificial-intelligence-ai-use",
    "href": "syllabus_final.html#artificial-intelligence-ai-use",
    "title": "Final Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nLearning to use AI tools is an emerging skill that we will explore together in this course. I expect you to use AI (ChatGPT, Google Bard)—in fact, some assignments may require it.\nHowever, you should be aware of the limits of AI:\n\nAI is a tool, but one that you need to acknowledge using. Any ideas, language, or code that is produced by AI must be cited, just like any other resource. [sample suggestion: Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you used to get the results.] Failure to do so is in violation of the academic integrity policy at Macalester College.\nDon’t trust anything AI says. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you understand.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nHow to cite usage of AI: Please copy and paste all prompts and output into an Appendix section accompanying each problem of an assignment.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "syllabus_prelim.html",
    "href": "syllabus_prelim.html",
    "title": "Preliminary Syllabus",
    "section": "",
    "text": "Nature doesn’t reveal its secrets easily. - Thomas Kempa\n\nNor do data.\nBut that is exactly what can make data science so thrilling!\nThis course is about empowering you with the wisdom to ask the best questions of data–ones that are meaningful, adaptive, and equity-minded–and the technical savvy to answer them.\nBecause your careers (whether in data science or not), will all involve further learning and working with others, my other primary goal is for you to cultivate self-reflection skills with regards to your own learning and your collaboration with others. In this way, I hope that you feel confident learning new skills on your own in the future and contributing to a welcoming work community.\n\n\n\n\n\n\nCourse catalog description\n\n\n\n\n\nThis second course in the data science curriculum emphasizes advanced data wrangling and manipulation, interactive visualization, writing functions, working with data in databases, version control, and data ethics. Through open-ended and interdisciplinary projects, students practice the constant feedback loop of asking questions of the data, manipulating the data to help answer the question, and then returning to more questions. Prerequisite(s): COMP 112 and COMP 123 and STAT 155; STAT 253 recommended but not required.\n\n\n\n\n\nBy the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nReflect\n\n\n\n\nWhich of the learning goals above do you disagree with or want more clarity on?\nDo you have any goals that you’d like to include on this list?"
  },
  {
    "objectID": "syllabus_prelim.html#course-learning-goals",
    "href": "syllabus_prelim.html#course-learning-goals",
    "title": "Preliminary Syllabus",
    "section": "",
    "text": "By the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nReflect\n\n\n\n\nWhich of the learning goals above do you disagree with or want more clarity on?\nDo you have any goals that you’d like to include on this list?"
  },
  {
    "objectID": "syllabus_prelim.html#how-to-contact-me",
    "href": "syllabus_prelim.html#how-to-contact-me",
    "title": "Preliminary Syllabus",
    "section": "How to contact me",
    "text": "How to contact me\n\n\n\n\n\n\nCall me “Leslie”\n\n\n\nStudents sometimes wonder what to call their professors. I prefer to be called Leslie (lez-lee), but if you prefer to be more formal, I am also ok with Professor Myint (pronounced “mee-int”). My preferred gender pronouns are she/her/hers.\nPlease help me make sure that I call you by your preferred name and pronouns too!\n\n\nI love getting to talk to students outside of class time—whether about class-related topics or anything else. Come chat with me!\nI’ll be setting times for drop-in hours based on feedback from the pre-course survey. I’ll update my drop-in hours on our course homepage and Moodle when they’re finalized.\nI’m also happy to meet one-on-one if my normal drop-in hours don’t work. You can schedule a time to meet with me via Calendly.\nI’ll also often be in the Leonard Center weight room from about 4:30-5:10 some weekdays. Feel free to say hello!"
  },
  {
    "objectID": "syllabus_prelim.html#discussion-board-slack",
    "href": "syllabus_prelim.html#discussion-board-slack",
    "title": "Preliminary Syllabus",
    "section": "Discussion board (Slack)",
    "text": "Discussion board (Slack)\nSlack is a commonly used communication tool in industry and is useful to be familiar with, so we’ll be using it as our discussion board.\n\nIf you’re new to Slack, this video provides a quick overview.\nFirst join our STAT/COMP 212: Fall 2023 workspace here.\nAfter joining, you can access our workspace here. (You might want to bookmark this if you have Slack open in your web broswer.)"
  },
  {
    "objectID": "syllabus_prelim.html#community-is-key",
    "href": "syllabus_prelim.html#community-is-key",
    "title": "Preliminary Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nOur class is participating in the Classroom Community & Connectedness Project this semester. On Thursday, September 21 our class sessions will be a facilitated class activity (peers and facilitators only; I will not be present) to collectively reflect on strengthening our classroom community, with the intent of improving the learning environment for all of us.\nYour participation is voluntary, but very much appreciated. The project is co-sponsored by Macalester’s Serie Center for Scholarship and Teaching and our Office of Institutional Research & Assessment."
  },
  {
    "objectID": "syllabus_prelim.html#reflection-is-paramount",
    "href": "syllabus_prelim.html#reflection-is-paramount",
    "title": "Preliminary Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that as technology evolves, some part of it will become out of date during your careers. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content–it’s fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection as a goal for our course in both content learning and collaborative activities. (Note that these reflection goals are the first two course learning goals.)"
  },
  {
    "objectID": "syllabus_prelim.html#mistakes-are-essential",
    "href": "syllabus_prelim.html#mistakes-are-essential",
    "title": "Preliminary Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field. - Niels Bohr, Nobel Prize-winning physicist\n\nI don’t feel comfortable working with a new R package until I’ve seen the same errors over and over again. Seeing new errors helps me understand the constraints of the code and the assumptions that I was making about my data.\nWe’re going to be seeking out mistakes like my cats hunt for leftover food scraps.\n\n\n\nMy cat Potato attempting to eat my daughter’s dinner"
  },
  {
    "objectID": "syllabus_prelim.html#communication-is-a-superpower",
    "href": "syllabus_prelim.html#communication-is-a-superpower",
    "title": "Preliminary Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas–whether through writing, visuals, or oral presentation–I want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What’s more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n— David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus_prelim.html#outside-of-class",
    "href": "syllabus_prelim.html#outside-of-class",
    "title": "Preliminary Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class reading: Most class periods will have a required reading to review ideas from previous courses or to familiarize yourself with new concepts before seeing them again in class. My goal for these readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. I will provide Guiding Questions for each reading to focus your attention.\n\n\n\n\n\n\nSuggestion\n\n\n\nScan the Guiding Questions before reading to preview the main ideas. Fill in answers to these questions as you read. Ask (and answer!) questions in the #questions channel in our Slack workspace.\n\n\nPodcast discussions: About every other week, we will discuss a podcast for the first ~20 minutes of class. These podcasts are meant to expose you aspects of data science in industry. Record anything that you’re curious about, and come prepared to discuss.\n\n\n\n\n\n\nYour own media contributions\n\n\n\nThroughout the semester, if you come across any media that is relevant to the course, feel free to suggest it as a discussion piece by emailing the instructor or posting it in the #general channel in our Slack workspace.\n\n\n\n\n\n\n\n\nOther suggestions for out-of-class time\n\n\n\n\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the weekly homework.\nCome to instructor drop-in hours to chat about the course or anything else 😃"
  },
  {
    "objectID": "syllabus_prelim.html#during-class",
    "href": "syllabus_prelim.html#during-class",
    "title": "Preliminary Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.) I’ll always leave a few minutes at the end of class for synthesis. Use this time to update your reflections and summarize the key takeaways from class."
  },
  {
    "objectID": "syllabus_prelim.html#option-1-evaluation-of-learning-is-done-by-instructor",
    "href": "syllabus_prelim.html#option-1-evaluation-of-learning-is-done-by-instructor",
    "title": "Preliminary Syllabus",
    "section": "Option 1: evaluation of learning is done by instructor",
    "text": "Option 1: evaluation of learning is done by instructor\nThe table below describes the qualities of A, B, and C grades in terms of the 3 core course components: reflections, homework, and the final project.\nIn order to earn a given letter grade, ALL of the requirements in the column must be met. (e.g., In order to earn an A, everything in the first column must be true.)\nThere is a possibility that by the end of the semester, work for the different course components falls under different letter grades. (e.g., A-level for reflections and homework, but B-level for project).\n\nIf this happens, towards the end of the semester I will ask you to submit a written justification for the grade that you think you deserve. We will have a conference in which we discuss your justification.\nIf we agree, your proposed grade will be your final grade.\nIf we disagree, we will discuss what needs to be done next to come to an agreement. (This may involve being doing extra work or revisions.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nPass all homework assignments\nPass all but 1 homework assignment\nPass all but 2 homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\nDetails about the course components are given below:\n\nSelf-reflection:\n\nI will look at the growth in your reflection process over the course of 3 substantive reflections. These will roughly come a month into the course, mid-course, and the end of the semester.\n\nMy expectation is that your mid-course and end-of-course reflections show that your are using feedback from previous reflections.\n\nI will look at the consistency in your reflection process by monitoring your Process and Reflection Google Doc.\n\nMy expectation is that you are filling this in regularly throughout class activities and through work outside of class.\n\n\nHomework: We will have weekly homework in which you will complete activities that we start in class. The requirements for passing the assignment will be clearly stated in the homework directions.\n\nIf you do not pass an assignment and wish to revise your work, you may resubmit the assignment the following week. This revision needs to be submitted by 2 weeks after the original homework due date. (See my policy on late work.)\n\nFinal project: For this semester-long project, you will receive regular feedback on the quality of the different project aspects and will have the opportunity to improve the quality of the different aspects as you continue working."
  },
  {
    "objectID": "syllabus_prelim.html#option-2-evaluation-of-learning-is-done-by-students-in-conversation-with-instructor",
    "href": "syllabus_prelim.html#option-2-evaluation-of-learning-is-done-by-students-in-conversation-with-instructor",
    "title": "Preliminary Syllabus",
    "section": "Option 2: evaluation of learning is done by students in conversation with instructor",
    "text": "Option 2: evaluation of learning is done by students in conversation with instructor\nWhat constitutes A, B, and C-level work is essentially identical in Options 1 and 2 (see table below). That is, my standards for high quality work are the same between the two.\nWhat’s different is how (who) participates in the evaluation process. In Option 1, I am making the final judgment on the quality of your work for all course components. In Option 2, you will start the assessment of quality by evaluating yourselves using qualitative feedback on all of your work.\nIn Option 2, the qualitative comments that you receive on all your work (reflections, homework, project) will form the basis of your self-evaluation. That is, you will review all comments from me and use this to gauge the degree to which you are meeting the course learning goals. (On homework, you will not receive a pass/not passing designation—you’ll just receive comments.) You will write self-evaluations ~1 month into the semester, in the middle of the semester (before midterm grades are due), and a final one at the end of the semester. In all of these self-evaluations, you will propose the grade that you think deserve. I will also evaluate your work, and if we disagree on the grade, we will meet to discuss what needs to be done next to come to an agreement. (This may involve being doing extra work or revisions.)\nNote: Your self-evaluations need to be based on demonstrated evidence in the work that you submit. For example, if you have struggled with the data wrangling homework assignments and say in your self-evaluation that your understanding is now strong after reviewing feedback, this is not sufficient evidence. You would need to demonstrate your stronger understanding of data wrangling by submitting a revision of the data wrangling homework. (See policy on late work.)\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\n\n\n\n\n\n\nComparing Options 1 and 2\n\n\n\nBoth options satisfy my goal to have high standards for your learning that are achievable through thoughtful revision. No matter what option we use, you’ll have a personal Google Sheet for tracking your progress over time.\nMy other goals for our grading system are for it to motivate you to learn as much as possible and to reduce stress. For these goals, your input during our Day 1 discussion will be very valuable."
  },
  {
    "objectID": "syllabus_prelim.html#late-work",
    "href": "syllabus_prelim.html#late-work",
    "title": "Preliminary Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will be due weekly on Wednesdays at midnight. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. Limited extensions will always be granted:\n\nMy ideal extension: Turn in the homework by the following Monday morning at 9am. (A 4 day, 9 hour extension)\n\nWhy is this ideal for me? I want to return feedback on homework to everyone before the following Tuesday’s class because we will be briefly reviewing homework feedback in small groups.\n\nFirm limit on extensions: You must turn in the homework by 2 weeks after the due date (Wednesdays at 9am).\n\nWhy is this my firm limit? I post solutions to the homework at this point.\nWhat if it’s past the 2-week limit and you still want to turn in the homework in some form? If this is the case, you need to create your own equivalent homework. This involves mapping the original homework’s exercises to a new dataset and completing those exercises. Note that I can’t make any guarantees about when I can get you feedback on this late submission. (Only guarantee = by the end of the semester)"
  },
  {
    "objectID": "syllabus_prelim.html#academic-integrity",
    "href": "syllabus_prelim.html#academic-integrity",
    "title": "Preliminary Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus_prelim.html#artificial-intelligence-ai-use",
    "href": "syllabus_prelim.html#artificial-intelligence-ai-use",
    "title": "Preliminary Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nLearning to use AI tools is an emerging skill that we will explore together in this course. I expect you to use AI (ChatGPT, Google Bard)—in fact, some assignments may require it.\nHowever, you should be aware of the limits of AI:\n\nAI is a tool, but one that you need to acknowledge using. Any ideas, language, or code that is produced by AI must be cited, just like any other resource. [sample suggestion: Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you used to get the results.] Failure to do so is in violation of the academic integrity policy at Macalester College.\nDon’t trust anything AI says. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you understand.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nHow to cite usage of AI: Please copy and paste all prompts and output into an Appendix section accompanying each problem of an assignment.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "tech_setup.html",
    "href": "tech_setup.html",
    "title": "Tech Setup",
    "section": "",
    "text": "Ideally before class on Tuesday, September 5 and definitely before class on Thursday, September 7, you should follow these instructions to set up the software that we’ll be using throughout the semester. Even if you’ve already downloaded both R and RStudio, you’ll want to re-download to make sure that you have the most current versions.\n\nRequired: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\nRequired: (Re)Download R and RStudio\n\nFIRST: Download R here.\n\nIn the top section, tou will see three links “Download R for …”\nChoose the link that corresponds to your computer.\nAs of September 1, 2023, the latest version of R is 4.3.1 (“Beagle Scouts”).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\nAs of September 1, 2023, the latest version of RStudio is 2023.06.2+561.\n\nTHIRD: Check that when you go to File &gt; New Project &gt; New Directory, you see “Quarto Website” as an option.\n\n\nSuggested: Watch this video describing key configuration options for RStudio.\n\nRequired: Install required packages.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\"))\n\n\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(tidyverse) and hit Enter.\nIf you see an error message, then there was a problem installing the package. Post the full error message in the #questions channel in our Slack workspace and\nQuit RStudio. You’re done setting up!\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio."
  },
  {
    "objectID": "workflow_files_rstudio.html",
    "href": "workflow_files_rstudio.html",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\n\n\nWhen working on any data science project, I recommend setting up the directory (folder) structure below. Sub-bullets indicate folders that are inside other folders.\n\nDocuments (This should be some place you can find easily through your Finder (Mac) or File Explorer (Windows).)\n\ndescriptive_project_name\n\ncode\n\nraw: For messy code that you’re actively working on\nclean: For code that you have cleaned up, documented, organized, and tested to run as expected\n\ndata\n\nraw: Original data that hasn’t been cleaned\nclean: Any non-original data that has been processed in some way\n\nresults\n\nfigures: Plots that will be used in communicating your project should go here. (Using screenshots of output in RStudio is not a good practice.)\ntables: Any sort of plain text file results (e.g., CSVs)\n\n\n\n\nFrom this point onward, we will use a simplified version of this directory structure for all of our class activities.\n\n\nCreate a folder for this course in a place you can find easily through your Finder (Mac) or File Explorer (Windows). The name of this folder should not have spaces (use underscores _ instead). Suggestion: STAT212 or COMP212\nOrganize your files from class using the following directory structure:\n\nSTAT212 (or COMP212)\n\nadvanced_ggplot (For our Advanced visualization in ggplot2 activity)\n\ncode\n\n02-adv-ggplot.qmd\n\ndata\n\nadvanced_maps (For our Advanced map visualization activity)\n\ncode\n\n03-adv-maps.qmd\n\ndata\n\napportionment.csv\nshp_loc_pop_centers (From shp_loc_pop_centers.zip)\nshp_water_lakes_rivers (From shp_water_lakes_rivers.zip)\nus_states_hexgrid.geojson\n\n\n\n\n\n\n\nIn a code file, when you read in data from a source on your computer, you need to specify the file path correctly. The file path is a text string that tells you how to get from your code file to the data. There are two types of paths: absolute and relative.\nAbsolute file paths start at the “root” directory in a computer system. Examples:\n\nMac: /Users/lesliemyint/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nOn a Mac the tilde ~ in a file path refers to the “Home” directory, which is /Users/lesliemyint. In this case, the path becomes ~/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nWindows: C:/Users/lesliemyint/Documents/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nNote: Windows uses both / (forward slash) and \\ (backward slash) to separate folders in a file path.\n\n\n\nRelative file paths start wherever you are right now (the working directory (WD)). The WD when you’re working in a code file may be different from the working directory in the Console.\nDirectory setup 1: Data is in same folder as code file\n\nsome_folder\n\nyour_code_file.qmd\ndata.csv\n\n\nThere are two options for the relative path:\n\n./data.csv (The ./ refers to the current working directory.)\ndata.csv\n\nDirectory setup 2: Data is within a subfolder called data\n\nsome_folder\n\nyour_code_file.qmd\ndata\n\ndata.csv\n\n\n\nThe relative path would be data/data.csv. (Note: ./data/data.csv would also work.)\nDirectory setup 3: Need to go to a “parent” folder first to get to the data\n\nsome_folder\n\ndata.csv\ncode\n\nyour_code_file.qmd\n\n\n\nTo go “up” a folder in a relative path we use ../.\nThe relative path here would be ../data.csv.\n\n\n\nIn 03-adv-maps.qmd, navigate to the code chunk where you read in us_states_hexgrid.geojson, apportionment.csv, shp_loc_pop_centers, and shp_water_lakes_rivers.\nUpdate the file paths to correctly find the data in the new directory structure."
  },
  {
    "objectID": "workflow_files_rstudio.html#change-the-default-file-download-location-for-your-internet-browser",
    "href": "workflow_files_rstudio.html#change-the-default-file-download-location-for-your-internet-browser",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers."
  },
  {
    "objectID": "workflow_files_rstudio.html#folderdirectory-structure",
    "href": "workflow_files_rstudio.html#folderdirectory-structure",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "When working on any data science project, I recommend setting up the directory (folder) structure below. Sub-bullets indicate folders that are inside other folders.\n\nDocuments (This should be some place you can find easily through your Finder (Mac) or File Explorer (Windows).)\n\ndescriptive_project_name\n\ncode\n\nraw: For messy code that you’re actively working on\nclean: For code that you have cleaned up, documented, organized, and tested to run as expected\n\ndata\n\nraw: Original data that hasn’t been cleaned\nclean: Any non-original data that has been processed in some way\n\nresults\n\nfigures: Plots that will be used in communicating your project should go here. (Using screenshots of output in RStudio is not a good practice.)\ntables: Any sort of plain text file results (e.g., CSVs)\n\n\n\n\nFrom this point onward, we will use a simplified version of this directory structure for all of our class activities.\n\n\nCreate a folder for this course in a place you can find easily through your Finder (Mac) or File Explorer (Windows). The name of this folder should not have spaces (use underscores _ instead). Suggestion: STAT212 or COMP212\nOrganize your files from class using the following directory structure:\n\nSTAT212 (or COMP212)\n\nadvanced_ggplot (For our Advanced visualization in ggplot2 activity)\n\ncode\n\n02-adv-ggplot.qmd\n\ndata\n\nadvanced_maps (For our Advanced map visualization activity)\n\ncode\n\n03-adv-maps.qmd\n\ndata\n\napportionment.csv\nshp_loc_pop_centers (From shp_loc_pop_centers.zip)\nshp_water_lakes_rivers (From shp_water_lakes_rivers.zip)\nus_states_hexgrid.geojson\n\n\n\n\n\n\n\nIn a code file, when you read in data from a source on your computer, you need to specify the file path correctly. The file path is a text string that tells you how to get from your code file to the data. There are two types of paths: absolute and relative.\nAbsolute file paths start at the “root” directory in a computer system. Examples:\n\nMac: /Users/lesliemyint/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nOn a Mac the tilde ~ in a file path refers to the “Home” directory, which is /Users/lesliemyint. In this case, the path becomes ~/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nWindows: C:/Users/lesliemyint/Documents/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nNote: Windows uses both / (forward slash) and \\ (backward slash) to separate folders in a file path.\n\n\n\nRelative file paths start wherever you are right now (the working directory (WD)). The WD when you’re working in a code file may be different from the working directory in the Console.\nDirectory setup 1: Data is in same folder as code file\n\nsome_folder\n\nyour_code_file.qmd\ndata.csv\n\n\nThere are two options for the relative path:\n\n./data.csv (The ./ refers to the current working directory.)\ndata.csv\n\nDirectory setup 2: Data is within a subfolder called data\n\nsome_folder\n\nyour_code_file.qmd\ndata\n\ndata.csv\n\n\n\nThe relative path would be data/data.csv. (Note: ./data/data.csv would also work.)\nDirectory setup 3: Need to go to a “parent” folder first to get to the data\n\nsome_folder\n\ndata.csv\ncode\n\nyour_code_file.qmd\n\n\n\nTo go “up” a folder in a relative path we use ../.\nThe relative path here would be ../data.csv.\n\n\n\nIn 03-adv-maps.qmd, navigate to the code chunk where you read in us_states_hexgrid.geojson, apportionment.csv, shp_loc_pop_centers, and shp_water_lakes_rivers.\nUpdate the file paths to correctly find the data in the new directory structure."
  },
  {
    "objectID": "workflow_files_rstudio.html#in-rstudio",
    "href": "workflow_files_rstudio.html#in-rstudio",
    "title": "Workflow: Files and RStudio setup",
    "section": "In RStudio",
    "text": "In RStudio\n\nWhen you’re in the Console, hitting the up and down arrow keys allows you to cycle through previous commands\nTab completion\n\nType part of a function or object name (in the Editor or Console) and then hit Tab. A menu of autocomplete options will popup. Select your choice with arrow keys and hit Tab or Enter. (e.g., Type ggp and hit Tab.)\nType part of a function argument and then hit Tab for a menu of autocomplete options."
  },
  {
    "objectID": "workflow_files_rstudio.html#in-general-for-typing",
    "href": "workflow_files_rstudio.html#in-general-for-typing",
    "title": "Workflow: Files and RStudio setup",
    "section": "In general for typing",
    "text": "In general for typing\n\nMoving your cursor to the beginning/end of a word\n\nMac: Option + Left/Right\nWindows: Ctrl + Left/Right\n\nDeleting one word at a time\n\nMac: Option + Backspace\nWindows: Ctrl + Backspace\n\nMoving your cursor to the beginning/end of a line\n\nMac: Command + Left/Right\nWindows: Alt + Left/Right\n\nDeleting a whole line at a time\n\nMac: Command + Backspace\nWindows: Alt + Backspace"
  }
]