[
  {
    "objectID": "01-introductions.html",
    "href": "01-introductions.html",
    "title": "Welcome to the course!",
    "section": "",
    "text": "Welcome to Intermediate Data Science! I’m thrilled to be your partners in journeying this brand new (!) course in MSCS.\nOur goals for today are as follows:\n\nWhat is this course about?\nGet to know your classmates\nShaping our syllabus together\nCreate your personal website!\n\nWebsite content building + connecting with classmates\n\n\nWe’ll primarily be using slides today–following along here."
  },
  {
    "objectID": "02-adv-ggplot.html",
    "href": "02-adv-ggplot.html",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nNavigate the ggplot2 reference page to find the functions needed to create a desired visualization\nUse the information on a function help page to construct desired plot features\n\nScan the information in the Usage section to identify function arguments that must be set\nUnderstand how the function arguments work by using information in the Arguments section\nUse the information in the the Aesthetics and Examples sections to control plot appearance\n\nIdentify when it would be necessary to use different data arguments within the ggplot() and geom_() layers\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)"
  },
  {
    "objectID": "02-adv-ggplot.html#pair-programming-background",
    "href": "02-adv-ggplot.html#pair-programming-background",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "Pair programming background",
    "text": "Pair programming background\nIn pair programming, two individuals use one computer and work together to solve the problem at hand. Each individual takes turns in one of two roles:\n\nDriver: The Driver is at the computer typing and speaking their thought process out loud.\nNavigator: The Navigator reviews all code that the Driver writes as it’s typed, guides the overall direction of the code (keeps the instructions in mind), and pulls up references.\n\nWhy are we using pair programming? Pair programming is used effectively in industry to speed up individual employee’s learning of a company’s codebase and reduce time wasted on fixing bugs."
  },
  {
    "objectID": "02-adv-ggplot.html#your-task",
    "href": "02-adv-ggplot.html#your-task",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "Your task",
    "text": "Your task\nBefore diving in to plot creation, get to know your partner by telling each other about the general themes in your 12 favorite problems (FPs). Try to find some overlap in your themes and share one of your FPs that relates to that overlapping theme.\nWork together until your precipitation plot looks as below.\n\nThe culmPrec variable contains cumulative precipitation for the month up to the given day.\nThe recordP variable is a TRUE/FALSE indicator of whether a day was a precipitation record. These are marked by the downward pointing triangles.\nThe numbers on the plot indicate the total precipitation for the month. Do some searching about the hjust and vjust options to adjust the alignment of the numbers.\nThe blue and tan colors are \"#32a3d8\" and \"#ebeae2\".\n\n\n\n\n\n\n\n\n\n\nWhen should the Driver and Navigator switch roles? For this exercise, you will switch roles once a particular plot layer (one geom) has been implemented correctly. You can send code back and forth via email or a direct message on Slack.\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nAs you pair program, be aware of your comforts and discomforts in the roles of driver and navigator. Pay attention to the comforts and discomforts of your partner. What could you do to support them in becoming more comfortable and confident in both roles?\n\n\n\n\n\n\n\n\n\nRecord Errors\n\n\n\n\n\nEvery time you run into a new error, record the error message and your process for fixing the error in the “Error Log” section of the Quarto file for these exercises."
  },
  {
    "objectID": "03-adv-maps.html",
    "href": "03-adv-maps.html",
    "title": "Advanced Spatial Visualizations",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nUnderstand the basics of a CRS (coordinate reference system)\nUnderstand and recognize different spatial file types and data types in R\nImplement some of the basic plotting with the sf package\nUnderstand foundational ideas in working with spatial data (aggregating spatial point data to a spatial region, joining spatial data sets)\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)\n\nYou can download a template Quarto file to start from here. Put this file in an activities folder within a folder for this course."
  },
  {
    "objectID": "03-adv-maps.html#ellipsoid",
    "href": "03-adv-maps.html#ellipsoid",
    "title": "Advanced Spatial Visualizations",
    "section": "Ellipsoid",
    "text": "Ellipsoid\nWhile you might have learned that the Earth is a sphere, it is actually closer to an ellipsoid with a bulge at the equator. Additionally, the surface is irregular and not smooth. To define a CRS, we first need to choose a mathematical model represent a smooth approximation to the shape of the Earth. The common ellipsoid models are known as WGS84 and GRS80. See the illustration below of one ellipsoid model (shown in black) as compared to Earth’s true irregular surface (shown in red).\n\n\n\nIllustration of ellipsoid model and Earth’s irregular surface, centered to have an overall best fit. Source: www.icsm.gov.au"
  },
  {
    "objectID": "03-adv-maps.html#datum",
    "href": "03-adv-maps.html#datum",
    "title": "Advanced Spatial Visualizations",
    "section": "Datum",
    "text": "Datum\nEach ellipsoid model has different ways to position it self relative to Earth depending on the center or origin. Each potential position and reference frame for representing the position of locations on Earth is called a datum.\nFor example, two different datum for the same ellipsoid model can provide a more accurate fit or approximation of the Earth’s surface depending on the region of interest (South America v. North America). For example, the NAD83 datum is a good fit for the GRS80 ellipsoid in North America, but SIRGAS2000 is a better fit for the GRS80 ellipsoid in South America. The illustration below shows one datum in which the center of the ellipsoid does not coincide with the center of Earth’s mass. With this position of the ellipsoid, we gain a better fit for the southern half of the Earth.\n\n\n\nIllustration of ellipsoid model and Earth’s irregular surface for a datum that better fits southern part (bottom right) of the Earth. Source: www.icsm.gov.au\n\n\nIt is useful to know that the Global Positioning System (GPS) uses the WGS84 ellipsoid model and a datum by the same name, which provides an overall best fit of the Earth.\nIf you have longitude and latitude coordinates for a location, it is important to know what datum and ellipsoid were used to define those positions.\nNote: In practice, the horizontal distance between WGS84 and NAD83 coordinates is about 3-4 feet in the US, which may not be significant for most applications.\n\nExercise 1\nGo to https://epsg.io/. Search for a location important to you (state, country, etc.). Filter based on Datum (Geodetic) on the right. Click on one geodetic datum option for your region of interest. Make sure your location is listed under the “Area of use” attribute.\nProvide the region of interest (e.g. United States), the full datum name (e.g. North American Datum 1983), the shorthand name (e.g. NAD83, EPSG: 6269), and the ellipsoid (e.g. GRS 1980).\n\nLocation:\n\n\n\nExample Solution\n\n\nLocation 1: South Africa, Cape, EPSG:6222, Ellipsoid: Clarke 1880 (Arc)\n\n\nLocation 2: Thailand, Indian 1975, EPSG:6240, Ellipsoid: Everest 1830 (1937 Adjustment)\n\n\nLocation 3: Colombia, Marco Geocentrico Nacional de Referencia, EPSG:6686, Ellipsoid: GRS 1980\n\n\n\n\nExercise 2\nLet’s now practice specifying coordinates in a CRS.\nFor geographic coordinate reference systems, the coordinates of locations are specified by latitude (degrees, minutes, and seconds north or south of the equator), longitude (degrees, minutes, and seconds west or east of a prime meridian), and sometimes height.\nUse the “Get position on a map” feature of https://epsg.io/ to locate the Olin-Rice Science Center at Macalester. The two boxes at the top allow you to specify a longitude (left box) and latitude (right box) in degrees. Enter the following to focus OLRI:\n\nLongitude: -93.168855\nLatitude: 44.936611\n\nFor projected coordinate reference systems, the coordinates of locations are typically specified by easting (x) and northing (y).\nClick the “Transform” button at the top to find the location of OLRI in northing and easting coordinates (in meters) for the CRS EPSG:26993.\n\nEasting:\nNorthing:\n\n\n\nSolution\n\n\nEasting: 865601.0163401571\nNorthing: 315516.10931633075"
  },
  {
    "objectID": "03-adv-maps.html#projection",
    "href": "03-adv-maps.html#projection",
    "title": "Advanced Spatial Visualizations",
    "section": "Projection",
    "text": "Projection\nLastly, the Earth lives in a 3 dimensional (3D) world and most visualizations are on a 2 dimensional (2D) surface. We must choose a projection method to represent points, regions, and lines on Earth on a 2D map with distance units (typically meter, international foot, US survey foot). In that projection process, a 3D element will lose angle, area, and/or distance when projected onto a 2D surface, no matter which method is chosen.\nFor a good overview of common projection methods, see https://pubs.usgs.gov/gip/70047422/report.pdf.\nOne of the most commonly used projection is the Mercator projection which is a cylindrical map projection from the 1500’s. It became popular for navigation because it represented north as up and south as down everywhere and preserves local directions and shape. However, it inflates the size of regions far from the equator. Thus, Greenland, Antarctica, Canada, and Russia appear large relative to their actual land mass as compared to Central Africa. See the illustration below to compare the area/shape of the countries with the Mercator projection of the world (light blue) with the true areas/shapes (dark blue).\n\n\n\nSource: @neilrkaye\n\n\nBelow you can see four different world projections. Take note of what is lost in terms of angle, area, or distance in these projections.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Basic Map w/ labels\nggplot(data = world) + \n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    labs(x = \"Longitude\", y = \"Latitude\", title = \"World Map - Mercator Projection\", subtitle = paste0(\"(\", length(unique(world$name)), \" countries)\")) +\n    theme_bw() \n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs\") + \n    labs(title = \"Lambert Azimuthal Equal-Area Projection\", subtitle = \"Correctly represents area but not angles\") + \n    theme_bw()\n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=fouc\") + \n    labs(title = \"Foucaut Projection\", subtitle = \"Correctly represents area, lots of shape distortion in high latitudes\") + \n    theme_bw() \n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=natearth2\") + \n    labs(title = \"Natural Earth II Projection\", subtitle = \"Represents globe shape, distorted at high latitudes\") + \n    theme_bw()\n\n\n\n\n\nExercise 3\nCreate a world map with a different projection (beyond the four above). Go to https://proj.org/en/9.2/operations/projections/index.html and find another projection. Look for the proj-string and copy that to the crs = argument in coord_sf().\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"??\") + \n    labs(title = \"?? Projection\", subtitle = \"??\") + \n  theme_bw() \n\nWhat is interesting, surprising, or different to you about the map of the Earth based on this projection?\n\nANSWER:\n\nTalk with a neighbor about the projection they tried. What projection did they use and how is it different from the one you chose?\n\nANSWER:\n\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nIf coordinate reference systems are new to you, how do you feel about all of this new information? What are the most important points to take away? What are the documents and sites you can refer back to when you need more details?\nWhen you learn about a new area of study, it can feel overwhelming. Pick out the 3-5 priority ideas to help you organize all of the details."
  },
  {
    "objectID": "03-adv-maps.html#data-models",
    "href": "03-adv-maps.html#data-models",
    "title": "Advanced Spatial Visualizations",
    "section": "Data Models",
    "text": "Data Models\n\nVector\nVector data represents the world as a set of spatial geometries that are defined in terms of location coordinates (with a specified CRS) with non-spatial attributes or properties.\nThe three basic vector geometries are\n\nPoints: Locations defined based on a (x, y) coordinates.\nLines: A set of ordered points connected by straight lines.\nPolygons: A set of ordered points connected by straight lines, first and last point are the same.\n\nFor example, city locations can be represented with points, roads and rivers can be represented by lines, and geo-political boundaries and lakes can be represented by polygons.\nHundreds of file formats exist to store spatial vector data. A text file (such as .csv) can store the coordinates in two columns (x,y) in addition to a group id (needed for lines and polygons) plus attributes or properties in additional columns. Note that text files do not store the CRS. However, shapefiles (.shp) developed by ESRI is one of the most widely supported spatial vector file format (that includes the CRS). Additionally, GeoJSON (.geojson) and KML (.kml) are additional popular formats.\n\n\nExercise 4\nTo create maps, we’ll need to have access to some spatial data.\nGo to the following websites and download the vector data files indicated. Put all of the downloaded files/folders in same folder as this Rmd file.\n\nURL: https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map\n\nDownload File Type: GeoJSON\nName of File: us_states_hexgrid.geojson\n\nURL: https://www2.census.gov/programs-surveys/decennial/2020/data/apportionment/apportionment.csv\n\nDownload File Type: csv\nName of File: apportionment.csv\n\nURL: https://gisdata.mn.gov/dataset/loc-pop-centers\n\nDownload File Type: shapefile (.shp)\nName of File: shp_loc_pop_centers.zip (unzip this file to get a folder with the name shp_loc_pop_centers)\n\nURL: https://gisdata.mn.gov/dataset/us-mn-state-metc-water-lakes-rivers\n\nDownload File Type: shapefile (.shp)\nName of File: shp_water_lakes_rivers.zip (unzip this file to get a folder with the name shp_water_lakes_rivers)\n\n\n\n\nRaster\nRaster data represents the world using a continuous grid of cells where each cell has a single value. These values could be continuous (e.g., elevation, precipitation) or categorical (e.g., land cover type, soil type).\nTypically regular cells are square in shape but they can be rotated and sheared. Rectilinear and curvilinear shapes are also possible, depending on the spatial region of interest and CRS.\n\n\n\nDifference between vector and raster formats. Source: gis.stackexchange.com\n\n\nBe aware that high resolution raster data involves a large number of small cells. This can slow down the computations and visualizations.\nMany raster file formats exist. One of the most popular is GeoTIFF (.tif or .tiff). More complex raster formats include NetCDF (.nc) and HDF (.hdf). To work with raster data in R, you’ll use the raster, terra, and the stars packages. If you are interested in learning more, check out https://r-spatial.github.io/stars/."
  },
  {
    "objectID": "03-adv-maps.html#working-with-spatial-data-in-r",
    "href": "03-adv-maps.html#working-with-spatial-data-in-r",
    "title": "Advanced Spatial Visualizations",
    "section": "Working with Spatial Data in R",
    "text": "Working with Spatial Data in R\n\nRead data into R\nFor each file format, we need to use a different function to read in the data. See the examples below for reading in GeoJSON, CSV, and shapefiles.\n\n# Read in GeoJSON file\nhex_spatial &lt;- geojsonio::geojson_read(\"data/us_states_hexgrid.geojson\", what = \"sp\") \n\n# Read in CSV File\npop_growth &lt;- readr::read_csv(\"data/apportionment.csv\") %&gt;% janitor::clean_names()\n\n# Read in Shapefiles\nmn_cities &lt;- sf::read_sf(\"data/shp_loc_pop_centers\") #shp file/folder\nmn_water &lt;- sf::read_sf(\"data/shp_water_lakes_rivers\") #shp file/folder\n\n\n\nData classes in R\nWhen data is read in, an R data object is created of a default class. Notice the classes of the R objects we read in. Also, notice that an object may have multiple classes, which indicate the type of structure it has and how functions may interact with the object.\n\nclass(hex_spatial)\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\nclass(pop_growth)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nclass(mn_cities)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(mn_water)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nOlder R Spatial classes\nIn the sp package, there are many spatial classes that hold slightly different data. All Spatial* classes have a bounding box (bbox) and a CRS.\n\nSpatialPoints, SpatialLines, and SpatialPolygons provide structure to hold the basic spatial geometries of points, lines, and polygons.\nSpatial*DataFrame extends the geometry classes to a data.frame-like object with non-spatial attribute data.\n\n\n\nExercise 5\nWe can look at the first bit of the hex_spatial object to get a sense for how information in the object is organized:\n\nhead(hex_spatial,1)\n\nAn object of class \"SpatialPolygonsDataFrame\"\nSlot \"data\":\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n            google_name\n1 Maine (United States)\n\nSlot \"polygons\":\n[[1]]\nAn object of class \"Polygons\"\nSlot \"Polygons\":\n[[1]]\nAn object of class \"Polygon\"\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"area\":\n[1] 15.28454\n\nSlot \"hole\":\n[1] FALSE\n\nSlot \"ringDir\":\n[1] 1\n\nSlot \"coords\":\n          [,1]     [,2]\n[1,] -72.62574 55.31320\n[2,] -69.90286 54.40843\n[3,] -69.90286 52.53744\n[4,] -72.62574 51.57081\n[5,] -75.34861 52.53744\n[6,] -75.34861 54.40843\n[7,] -72.62574 55.31320\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"ID\":\n[1] \"1\"\n\nSlot \"area\":\n[1] 15.28454\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"bbox\":\n        min       max\nx -75.34861 -69.90286\ny  51.57081  55.31320\n\nSlot \"proj4string\":\nCoordinate Reference System:\nDeprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs \nWKT2 2019 representation:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]] \n\n\nBased on this information, fill in the following:\n\nCRS:\nBBOX (extent):\nGeometry type:\n\n\n\nSolution\n\n\nCRS: EPSG:4326 (+proj=longlat +datum=WGS84 +no_defs) (From Slot \"proj4string\": Coordinate Reference System:)\nBBOX: x -75.34861 -69.90; y 51.57 55.31 (From Slot \"bbox\")\nGeometry type: Polygons (Inferred from An object of class \"SpatialPolygonsDataFrame\" and class \"Polygon\")\n\n\nNewer R Spatial classes\nThe community is moving away from using older sp classes to sf classes. It is useful for you to know that the older versions exist, but we will stick with the sf classes.\n\nsfc objects are modern, general versions of the spatial geometries from the sp package with a bbox, CRS, and many geometries available.\nsf objects are data.frame-like objects with a geometry column of class sfc.\n\n\nmn_cities\n\nSimple feature collection with 1081 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nProjected CRS: NAD83 / UTM zone 15N\n# A tibble: 1,081 × 9\n      GNIS Name        CTU_Type County      FIPS_Code Sym_Class Population Notes\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;\n 1 2393879 Ada         City     Norman Cou… 27107001… County S…       1681 &lt;NA&gt; \n 2 2393881 Adams       City     Mower Coun… 27099001… Small Ci…        742 &lt;NA&gt; \n 3 2393884 Adrian      City     Nobles Cou… 27105002… Small Ci…       1278 &lt;NA&gt; \n 4 2393887 Afton       City     Washington… 27163003… Small Ci…       2932 &lt;NA&gt; \n 5 2393894 Aitkin      City     Aitkin Cou… 27001004… County S…       2279 &lt;NA&gt; \n 6 2393895 Akeley      City     Hubbard Co… 27057004… Small Ci…        397 &lt;NA&gt; \n 7 2393898 Albany      City     Stearns Co… 27145006… Small Ci…       2618 &lt;NA&gt; \n 8 2393902 Albert Lea  City     Freeborn C… 27047006… County S…      17843 &lt;NA&gt; \n 9 2393903 Alberta     City     Stevens Co… 27149006… Small Ci…        122 &lt;NA&gt; \n10 2393904 Albertville City     Wright Cou… 27171007… Small Ci…       7226 &lt;NA&gt; \n# ℹ 1,071 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\n\n\nExercise 6\nBased on the summary of mn_cities, what are the following:\n\nCRS:\nBBOX:\nGeometry type:\n\n\n\nSolution\n\n\nCRS: NAD83 / UTM zone 15N\nBBOX: xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nGeometry type: Points\n\n\nPutting spatial data into a data.frame with fortify()\nThe data.frame and tbl (tibble) classes are standard data formats that are not specific to spatial data but are really nice for working with because of tidyverse. Our pop_growth data doesn’t include any coordinate information, so it can be stored simply as a data.frame (tbl, tbl_df, and spec_tbl_df are all subclasses of data.frame).\nYou may come across data.frames that contain spatial coordinate information, so let’s see what that might look like. We can fortify() our sp object (hex_spatial) to make it a data frame.\n\n# Convert Spatial*DataFrame to Data Frame\nhex_spatial_df &lt;- fortify(hex_spatial)\nclass(hex_spatial_df)\n\n[1] \"data.frame\"\n\n\n\n\nExercise 7\nWhenever we come across a new function (fortify), it is helpful to explore the structure of information contained within the object that it creates.\nWhat are the variables in hex_spatial_df? Compare the first seven rows with the first spatial polygon of hex_spatial. Using this comparison describe the meaning of the variables in hex_spatial_df. (piece, id, and group are trickier. We’ll talk about this together.)\n\n# Display the first 7 rows of hex_spatial_df\nhead(hex_spatial_df,7)\n\n       long      lat order  hole piece id group\n1 -72.62574 55.31320     1 FALSE     1  1   1.1\n2 -69.90286 54.40843     2 FALSE     1  1   1.1\n3 -69.90286 52.53744     3 FALSE     1  1   1.1\n4 -72.62574 51.57081     4 FALSE     1  1   1.1\n5 -75.34861 52.53744     5 FALSE     1  1   1.1\n6 -75.34861 54.40843     6 FALSE     1  1   1.1\n7 -72.62574 55.31320     7 FALSE     1  1   1.1\n\n# Look at the first polygon in the hex_spatial object (Maine)\nhex_spatial@polygons[[1]]\n\nAn object of class \"Polygons\"\nSlot \"Polygons\":\n[[1]]\nAn object of class \"Polygon\"\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"area\":\n[1] 15.28454\n\nSlot \"hole\":\n[1] FALSE\n\nSlot \"ringDir\":\n[1] 1\n\nSlot \"coords\":\n          [,1]     [,2]\n[1,] -72.62574 55.31320\n[2,] -69.90286 54.40843\n[3,] -69.90286 52.53744\n[4,] -72.62574 51.57081\n[5,] -75.34861 52.53744\n[6,] -75.34861 54.40843\n[7,] -72.62574 55.31320\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"ID\":\n[1] \"1\"\n\nSlot \"area\":\n[1] 15.28454\n\n\n\nANSWER:\n\n\n\nSolution\n\n\nVariables: long, lat, order, hole, piece, id, group\n\n\nlong and lat provide the x and y coordinates of the polygon for a particlar region or area id.\n\n\nThe order is the order in which you connect the coordinate points to make a polygon.\n\n\nhole indicates whether or not it should be included or excluded in the region as a hole.\n\n\npiece indicates the number of the polygon for an individual area\n\n\nid is a unique identifier for each polygon and allows linking to the original spatial object (hex_spatial). (There is a Slot \"ID\" part of the object.)\n\n\ngroup indicates which pieces belong to the same group or should be plotted together as a single entity. This can be useful when you want to apply different aesthetics (e.g., colors, linetypes) to different groups of polygons within your spatial object. It helps in specifying how to group and style the different pieces when creating plots.\n\n\n\n\nConverting between data classes\nSometimes functions for working with spatial data will only work on an object that is of a particular class (e.g., only works on sf objects). If we have an object of a different class, we need to know how to convert it to the right class.\nWe can convert objects between these data classes with the following functions:\n\nfortify(x): sp object x to data.frame\nst_as_sf(x): sp object x to sf\nst_as_sf(x, coords = c(\"long\", \"lat\")): data.frame x to sf as points\nTo convert a data.frame with columns of long, lat, and group containing polygon geometry information, you can use:\n\n\nst_as_sf(x, coords = c(\"long\", \"lat\")) %&gt;%\n    group_by(group) %&gt;%\n    summarise(geometry = st_combine(geometry)) %&gt;%\n    st_cast(\"POLYGON\")\n\n(Note: We won’t often want to convert our data to a Spatial* class from sp package, so we’ll exclude that in this activity.)\n\n\nExercise 8\nConvert the hex_spatial data to an sf object called hex_spatial_sf. Complete these two ways\n\nhex_spatial directly to hex_spatial_sf AND\nhex_spatial_df to hex_spatial_sf.\n\n\n# Convert to SF from hex_spatial_df  \nhex_spatial_sf &lt;- hex_spatial_df %&gt;% ???  \n  \n# Convert to SF from hex_spatial\nhex_spatial_sf &lt;- hex_spatial %&gt;% ???\n\n\n\nSolution\n\n\n# Convert to SF from hex_spatial_df  \nhex_spatial_sf &lt;- hex_spatial_df %&gt;%\n    st_as_sf(coords = c(\"long\", \"lat\")) %&gt;%\n    group_by(group) %&gt;%\n    summarise(geometry = st_combine(geometry)) %&gt;%\n    st_cast(\"POLYGON\") \n  \n# Convert to SF from hex_spatial\nhex_spatial_sf &lt;- hex_spatial %&gt;% st_as_sf()\n\n\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWe’ve now talked about CRSs and how spatial data is stored in R. Thinking on the lesson so far as a whole…\n\nWhat’s making sense? What’s not?\nWhat would help connect everything we’ve talked about?\n\nRecord observations in your Process and Reflection Log.\nShare your observations with your partner. Together try to figure out what themes emerge in what you’re still working on. Then try to come up with strategies that can help you move forward.\nExample themes: What is the “why” behind this? What is the full picture/pipeline/how this is used in practice?\nExample strategies: writing condensed summaries, drawing concept maps"
  },
  {
    "objectID": "03-adv-maps.html#hexbin-choropleth",
    "href": "03-adv-maps.html#hexbin-choropleth",
    "title": "Advanced Spatial Visualizations",
    "section": "Hexbin Choropleth",
    "text": "Hexbin Choropleth\nData Source: https://r-graph-gallery.com/328-hexbin-map-of-the-usa.html\nIn this example, we’ll create an alternative choropleth map. Instead of using the actual geo-political boundaries, we will use hexagons to represent the U.S. states and maintain their relative directional position to each together. This approach results in each state having the same area in the graphic so that large regions don’t dominate the visual story.\n\nExercise 9\nDescribe what the following code chunks are doing. Be sure to consider the class of the data object, what the data object looks like to start, and what it looks like at the end of the chunk.\n\n# Chunk A\nhex_spatial_df  &lt;- hex_spatial_df %&gt;% \n  left_join(\n        data.frame(id = as.character(1:nrow(hex_spatial)) , \n        name = str_replace(hex_spatial$google_name,' \\\\(United States\\\\)',''), \n        abbr = hex_spatial$iso3166_2))\n\n\nANSWER (Chunk A):\n\n\n\nSolution\n\n\n# Chunk A\nhead(hex_spatial_df) # Start with data frame of 357 rows and 7 columns\n\n       long      lat order  hole piece id group\n1 -72.62574 55.31320     1 FALSE     1  1   1.1\n2 -69.90286 54.40843     2 FALSE     1  1   1.1\n3 -69.90286 52.53744     3 FALSE     1  1   1.1\n4 -72.62574 51.57081     4 FALSE     1  1   1.1\n5 -75.34861 52.53744     5 FALSE     1  1   1.1\n6 -75.34861 54.40843     6 FALSE     1  1   1.1\n\nhex_spatial_df  &lt;- hex_spatial_df %&gt;% \n  left_join( # Left join, a mutating join, a dataset with information from hex_spatial\n        data.frame(id = as.character(1:nrow(hex_spatial)) , # Create a data frame with variables id (1,2,3...), name (defined as the google_name from hex_spatial after removing \"(United States)\"), and abbr (the state abbreviation in hex_spatial as variable iso3166_2)\n        name = str_replace(hex_spatial$google_name,' \\\\(United States\\\\)',''), \n        abbr = hex_spatial$iso3166_2))\n\nhead(hex_spatial_df) # End with data frame of 357 rows and 9 columns (new: name and abbr)\n\n       long      lat order  hole piece id group  name abbr\n1 -72.62574 55.31320     1 FALSE     1  1   1.1 Maine   ME\n2 -69.90286 54.40843     2 FALSE     1  1   1.1 Maine   ME\n3 -69.90286 52.53744     3 FALSE     1  1   1.1 Maine   ME\n4 -72.62574 51.57081     4 FALSE     1  1   1.1 Maine   ME\n5 -75.34861 52.53744     5 FALSE     1  1   1.1 Maine   ME\n6 -75.34861 54.40843     6 FALSE     1  1   1.1 Maine   ME\n\n\n\n\n# Chunk B\nhex_spatial_sf &lt;- hex_spatial_sf %&gt;% \n    mutate(\n        name = str_replace(google_name,' \\\\(United States\\\\)',''),\n        abbr = iso3166_2\n    )\n\n\nANSWER (Chunk B):\n\n\n\nSolution\n\n\n# Chunk B\n\nhead(hex_spatial_sf) # Start with sf object with 51 regions and 7 variables/features\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -113.4688 ymin: 30.53798 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1217 2015-05-13 17:24:35 2015-10-05 11:00:16  R.I. 47.8        RI\n3       1218 2015-05-13 17:25:00 2015-10-05 11:00:16   Vt. 33.9        VT\n4        231 2015-05-13 17:02:22 2015-10-05 11:00:16 Okla. 63.4        OK\n5        244 2015-05-13 17:02:22 2015-10-05 11:00:16  N.C. 41.5        NC\n6        259 2015-05-13 17:02:22 2015-10-05 11:00:16   Va. 45.6        VA\n                     google_name                       geometry\n1          Maine (United States) POLYGON ((-72.62574 55.3132...\n2   Rhode Island (United States) POLYGON ((-72.62574 49.5743...\n3        Vermont (United States) POLYGON ((-80.79436 52.5374...\n4       Oklahoma (United States) POLYGON ((-110.746 35.79821...\n5 North Carolina (United States) POLYGON ((-91.68585 39.5301...\n6       Virginia (United States) POLYGON ((-88.96298 43.0717...\n\nhex_spatial_sf &lt;- hex_spatial_sf %&gt;% # Create new variables: name (defined as the google_name after removing \"(United States)\"), and abbr (the state abbreviation from variable iso3166_2)\n    mutate(\n        name = str_replace(google_name,' \\\\(United States\\\\)',''),\n        abbr = iso3166_2\n    )\n\nhead(hex_spatial_sf) # Ends with sf object with 51 regions and 9 variables/features\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -113.4688 ymin: 30.53798 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1217 2015-05-13 17:24:35 2015-10-05 11:00:16  R.I. 47.8        RI\n3       1218 2015-05-13 17:25:00 2015-10-05 11:00:16   Vt. 33.9        VT\n4        231 2015-05-13 17:02:22 2015-10-05 11:00:16 Okla. 63.4        OK\n5        244 2015-05-13 17:02:22 2015-10-05 11:00:16  N.C. 41.5        NC\n6        259 2015-05-13 17:02:22 2015-10-05 11:00:16   Va. 45.6        VA\n                     google_name                       geometry           name\n1          Maine (United States) POLYGON ((-72.62574 55.3132...          Maine\n2   Rhode Island (United States) POLYGON ((-72.62574 49.5743...   Rhode Island\n3        Vermont (United States) POLYGON ((-80.79436 52.5374...        Vermont\n4       Oklahoma (United States) POLYGON ((-110.746 35.79821...       Oklahoma\n5 North Carolina (United States) POLYGON ((-91.68585 39.5301... North Carolina\n6       Virginia (United States) POLYGON ((-88.96298 43.0717...       Virginia\n  abbr\n1   ME\n2   RI\n3   VT\n4   OK\n5   NC\n6   VA\n\n\n\n\n# Chunk C\nhex_growth_df &lt;- left_join(hex_spatial_df, pop_growth, by = 'name')\nhex_growth_sf &lt;- left_join(hex_spatial_sf, pop_growth, by = 'name')\n\n\nANSWER (Chunk C):\n\n\n\nSolution\n\n\n# Chunk C\n\nhex_growth_df &lt;- left_join(hex_spatial_df, pop_growth, by = 'name') # Add in pop_growth variables to data frame using left_join; in the process duplicate the geometry for each region for each year\nhead(hex_growth_df)\n\n       long     lat order  hole piece id group  name abbr geography_type year\n1 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1910\n2 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1920\n3 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1930\n4 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1940\n5 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1950\n6 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1960\n  resident_population percent_change_in_resident_population\n1              742371                                   6.9\n2              768014                                   3.5\n3              797423                                   3.8\n4              847226                                   6.2\n5              913774                                   7.9\n6              969265                                   6.1\n  resident_population_density resident_population_density_rank\n1                        24.1                               33\n2                        24.9                               34\n3                        25.9                               36\n4                        27.5                               36\n5                        29.6                               37\n6                        31.4                               38\n  number_of_representatives change_in_number_of_representatives\n1                         4                                   0\n2                         4                                   0\n3                         3                                  -1\n4                         3                                   0\n5                         3                                   0\n6                         2                                  -1\n  average_apportionment_population_per_representative\n1                                              185593\n2                                              192004\n3                                              265806\n4                                              282409\n5                                              304591\n6                                              484633\n\ndim(hex_growth_df) # end with data frame of 4284 rows and 18 variables\n\n[1] 4284   18\n\nhex_growth_sf &lt;- left_join(hex_spatial_sf, pop_growth, by = 'name') # add in pop_growth variables to sf object using left join; in the process duplicate the geometry for each region for each year \nhead(hex_growth_sf)\n\nSimple feature collection with 6 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -75.34861 ymin: 51.57081 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n3       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n4       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n5       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n6       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n            google_name  name abbr geography_type year resident_population\n1 Maine (United States) Maine   ME          State 1910              742371\n2 Maine (United States) Maine   ME          State 1920              768014\n3 Maine (United States) Maine   ME          State 1930              797423\n4 Maine (United States) Maine   ME          State 1940              847226\n5 Maine (United States) Maine   ME          State 1950              913774\n6 Maine (United States) Maine   ME          State 1960              969265\n  percent_change_in_resident_population resident_population_density\n1                                   6.9                        24.1\n2                                   3.5                        24.9\n3                                   3.8                        25.9\n4                                   6.2                        27.5\n5                                   7.9                        29.6\n6                                   6.1                        31.4\n  resident_population_density_rank number_of_representatives\n1                               33                         4\n2                               34                         4\n3                               36                         3\n4                               36                         3\n5                               37                         3\n6                               38                         2\n  change_in_number_of_representatives\n1                                   0\n2                                   0\n3                                  -1\n4                                   0\n5                                   0\n6                                  -1\n  average_apportionment_population_per_representative\n1                                              185593\n2                                              192004\n3                                              265806\n4                                              282409\n5                                              304591\n6                                              484633\n                        geometry\n1 POLYGON ((-72.62574 55.3132...\n2 POLYGON ((-72.62574 55.3132...\n3 POLYGON ((-72.62574 55.3132...\n4 POLYGON ((-72.62574 55.3132...\n5 POLYGON ((-72.62574 55.3132...\n6 POLYGON ((-72.62574 55.3132...\n\ndim(hex_growth_sf) #end with sf object of 612 region/year combinations and 19 variables\n\n[1] 612  19\n\n\n\n\n# Chunk D\ncenters &lt;- data.frame(\n    rgeos::gCentroid(hex_spatial,byid = TRUE), \n    abbr = hex_spatial$iso3166_2\n)\n  \nhex_growth_df %&gt;% \n    filter(year == 2020) %&gt;%\n    ggplot(aes(x = long, y = lat)) +\n        geom_polygon(aes(group = group, fill = percent_change_in_resident_population)) + \n        geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') +\n        labs(fill = 'Population Change (%)') + \n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right')\n\n\nANSWER (Chunk D):\n\n\n\nSolution\n\n\n# Chunk D\ncenters &lt;- data.frame(\n    rgeos::gCentroid(hex_spatial,byid = TRUE), # Create data frame of the center of each region and the state abbreviation\n    abbr = hex_spatial$iso3166_2\n)\n  \nhex_growth_df %&gt;% \n    filter(year == 2020) %&gt;% # focus only on the data from 2020\n    ggplot(aes(x = long, y = lat)) + # create frame of longitude and latitude\n        geom_polygon(aes(group = group, fill = percent_change_in_resident_population)) +  # add hex polygons defined by x and y but grouped according to group and color filled by the percent_change in resident population\n        geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') + # add text at the centers of the polygons and add text labels from the abbr variable in the centers data we created\n        labs(fill = 'Population Change (%)') +  # change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\n\n\n\n# Chunk E\nhex_growth_sf %&gt;% \n    filter(year == 2020) %&gt;%\n    ggplot() +\n        geom_sf(aes(fill = percent_change_in_resident_population)) + \n        geom_sf_text( aes(label = abbr), color = 'white') +\n        labs(fill = 'Population Change (%)') + \n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right')\n\n\nANSWER (Chunk E):\n\n\n\nSolution\n\n\n# Chunk E\nhex_growth_sf %&gt;%  # start with sf object\n    filter(year == 2020) %&gt;% #filter to focus on data from 2020\n    ggplot() +\n        geom_sf(aes(fill = percent_change_in_resident_population)) + # plot the sf geometry (polygons) and fill color according to percent change in population\n        geom_sf_text( aes(label = abbr), color = 'white') + # add text labels to the sf geometry regions using abbr for the text\n        labs(fill = 'Population Change (%)') + # Change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right \n\n\n\n\n\n\n\nExercise 10\nUsing the hexbin spatial boundaries and the pop_growth data, make the following updates to the choropleth graphic:\n\nChange the outcome variable (different year or variable).\nChange the fill scale to be more meaningful and effective.\nMake one more update beyond the fill color to improve the effectiveness of the graphic.\n\nMake the graphic twice, once with geom_polygon() and once with geom_sf().\n\n\nExample Solution\n\n\nhex_growth_df %&gt;% \n    ggplot(aes(x = long, y = lat)) + # create frame of longitude and latitude\n        geom_polygon(aes(group = group, fill = change_in_number_of_representatives)) +  # add hex polygons defined by x and y but grouped according to group and color by change in number of representatives\n        # geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') + # add text at the centers of the polygons and add text labels from the abbr variable in the centers data we created\n        facet_wrap(~ year, ncol = 3) +\n        labs(fill = 'Population Change (%)') +  # change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\nhex_growth_sf %&gt;%  # start with sf object\n    ggplot() +\n        geom_sf(aes(fill = change_in_number_of_representatives)) + # plot the sf geometry (polygons) and fill color according to change in number of representatives\n        # geom_sf_text( aes(label = abbr), color = 'white') + # add text labels to the sf geometry regions using abbr for the text\n        facet_wrap(~ year, ncol = 3) +\n        labs(fill = 'Population Change (%)') + # Change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\n\n\n\n\nBonus Challenge\nFind external state-level data online, read it into R, join it, and create a U.S. state hexbin map displaying that new state-level outcome."
  },
  {
    "objectID": "03-adv-maps.html#mn-citycounty-example",
    "href": "03-adv-maps.html#mn-citycounty-example",
    "title": "Advanced Spatial Visualizations",
    "section": "MN City/County example",
    "text": "MN City/County example\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWhen looking through code examples, notice familiar functions and syntax patterns. Also, notice new functions and try figure out what they are doing.\nAdd comments to the code so that you can come back to the examples when you need them.\n\n\n\n\nUnifying CRSs across different spatial datasets\nTo demonstrate other spatial geometries beyond polygons (the hexagons in the last example were spatial polygons), we’ll walk through create a map of MN with different layers of information (city point locations, county polygon boundaries, rivers as lines and polygons, and a raster elevation map). To add all of this information on one map, we need to ensure that the CRS is the same for all spatial datasets.\n\n# Check CRS\nst_crs(mn_cities)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n# Check CRS\nst_crs(mn_water)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n# (They're both NAD83 / UTM zone 15N but we'll transform anyway)\n\n# Transform CRS of water to the same of the cities\nmn_water &lt;- mn_water %&gt;%\n    st_transform(crs = st_crs(mn_cities))\n\n\n# Load country boundaries data as sf object\nmn_counties &lt;- us_counties(resolution = \"high\", states = \"Minnesota\")\n\n# Remove duplicate column names\nnames_counties &lt;- names(mn_counties)\nnames(mn_counties)[names_counties == 'state_name'] &lt;- c(\"state_name1\", \"state_name2\")\n\n# Check CRS\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n# (They're different!)\n\n# Transform the CRS of county data to the more local CRS of the cities\nmn_counties &lt;- mn_counties %&gt;%\n  st_transform(crs = st_crs(mn_cities))\n\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n\n\n\nInitial map: counties and cities\n\nggplot() + # plot frame\n    geom_sf(data = mn_counties, fill = NA) + # county boundary layer\n    geom_sf(data = mn_cities, size = 0.5) + # city point layer\n    ggthemes::theme_map()\n\n\n\n\n\nggplot() +\n    geom_sf(data = mn_counties, fill = \"wheat\", color = \"tan\") + \n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population), alpha = 0.8)+ #cities layer\n    scale_color_viridis_c() + # continuous (gradient) color scale\n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"bottom\")  #move legend\n\n\n\n\n\n\nUpdated map: counties and cities plus elevation\n\nelevation &lt;- elevatr::get_elev_raster(mn_counties, z = 5, clip = 'bbox')\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to Data Frame for plotting\nelev_df &lt;- elevation %&gt;% terra::as.data.frame(xy = TRUE)\nnames(elev_df) &lt;-c('x','y','value')\n\nggplot() +\n    geom_raster(data = elev_df, aes(x = x,y = y,fill = value)) + # adding the elevation as first (bottom) layer\n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + \n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population,size = Population), alpha = 0.8)+ #cities layer\n    scale_color_viridis_c() + #continuous (gradient) color scale\n    scale_fill_gradient(low = 'darkgreen',high = 'white', guide = FALSE) + \n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"bottom\")  #move legend\n\n\n\n\n\n\nUpdated map: zoom in to Twin Cities\n\nseven_countyarea &lt;- st_bbox(mn_counties %&gt;% filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")))\n\n\nelevation &lt;- elevatr::get_elev_raster(mn_counties %&gt;% st_crop(seven_countyarea), z = 9, clip = 'bbox')\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation %&gt;% terra::as.data.frame(xy = TRUE)\nnames(elev_df) &lt;-c('x','y','value')\n\nggplot() +\n    geom_raster(data = elev_df, aes(x = x,y = y,fill = value)) + \n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + # county boundary layer\n    geom_sf(data = mn_water, fill = 'lightsteelblue1',color = 'lightsteelblue1') + # added a river/lake layer\n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population,size = Population)) + # cities layer\n    coord_sf(xlim = seven_countyarea[c(1,3)], ylim = seven_countyarea[c(2,4)]) + # crop map to coordinates of seven county area\n    scale_color_viridis_c(option = 'magma') + # continuous (gradient) color scale\n    scale_fill_gradient(low = 'darkgreen',high = 'white') + # continuous (gradient) fill scale\n    labs(title = \"Twin Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"none\")  # remove legend\n\n\n\n\n\n\nTwin Cities Leaflet\nBelow we show how to make the MN counties map in the leaflet package.\n\nlibrary(leaflet)\n\nmn_counties_leaf &lt;- mn_counties %&gt;% st_transform(4326) # Leaflet expects this CRS for vectors\nmn_cities_leaf &lt;- mn_cities %&gt;% st_transform(4326) # Leaflet expects this CRS for vectors\n\nCities_per_County &lt;- st_join(mn_cities_leaf, mn_counties_leaf) %&gt;%\n  st_drop_geometry() %&gt;% #removes geometry - makes the following calculation more efficient \n  count(name) \n\nmn_counties_leaf %&gt;% \n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) %&gt;%\n    left_join(Cities_per_County) %&gt;%\n    leaflet() %&gt;% \n    addProviderTiles(\"CartoDB.Positron\") %&gt;% \n    addPolygons(color = \"#444444\", weight = 1, smoothFactor = 0.5,\n    opacity = 1.0, fillOpacity = 0.5, fillColor = ~colorQuantile(\"YlOrRd\", n)(n), highlightOptions = highlightOptions(color = \"white\", weight = 2,\n      bringToFront = TRUE)) %&gt;%\n    addCircles(data = mn_cities_leaf %&gt;% filter(County %in% paste(c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\"),'County')), color = \"#444444\")"
  },
  {
    "objectID": "03-adv-maps.html#open-ended-exercise-homework",
    "href": "03-adv-maps.html#open-ended-exercise-homework",
    "title": "Advanced Spatial Visualizations",
    "section": "Open-ended Exercise (Homework)",
    "text": "Open-ended Exercise (Homework)\nThe following exercises will use census tract tidycensus data for Ramsey and Hennepin county and Crash.csv (2019-2022) from the pedestrian/bike crash database for St. Paul within Ramsey county in the Twin Cities. We provide several variables that you can choose from in order to create maps that best fit your interest.\nLoad the data with the following code:\n\ncensus2020 &lt;- tidycensus::get_acs(year = 2020, state = \"MN\", geography = \"tract\", variables = c(    \n\"B01003_001\", \"B19013_001\", \"B23006_023\", \"B25058_001\", \"B25107_001\", \"B25003_001\", \"B25003_002\", \"B25003_003\", \"B25077_001\"), output = 'wide', geometry = TRUE) %&gt;%\n  filter(word(NAME, 4) %in% c(\"Ramsey\",\"Hennepin\"))%&gt;%\n               mutate(tract = word(NAME, 3),\n                      tract = str_remove(tract, \",\"),\n                      county = word(NAME, 4)) %&gt;%\n               select(-NAME) %&gt;%\n               rename(\"population\" = \"B01003_001E\", \n                      \"medianIncome\" = \"B19013_001E\", \n                      \"bachelors\" = \"B23006_023E\",\n                      \"medContractRent\" = \"B25058_001E\", \n                      \"tenureTotal\" = \"B25003_001E\", \n                      \"tenureOwned\" = \"B25003_002E\", \n                      \"tenureRented\" = \"B25003_003E\",\n                      \"medianHomeValue\"= \"B25077_001E\") %&gt;%\n  select(-contains(\"_\"))\n\ncrashes &lt;- read_csv(\"https://lmyint.github.io/212_fall_2023/data/Crash.csv\") %&gt;%\n    filter(!is.na(Latitude), !is.na(Longitude))\n\n\nExercise: Joining and aggregation\nCreate a map of crashes per census tract in Ramsey county.\nFirst, transform the crashes data frame to a sf object have a point geometry using the code below.\n\ncrashes &lt;- st_as_sf(crashes, coords = c(\"Longitude\", \"Latitude\"), crs = \"NAD83\")\n\nCheck the CRS are the same for census2020 and crashes using st_crs() and transform if needed.\n\n# code here\n\nJoin the crashes and census dataset together and count the number of crashes per census tract. The function st_join can join to spatial data sets according to whether the spatial geometries of the right table intersect with the spatial geometries of the left table.\n\ncrashes_per_tract &lt;- st_join(??,??) %&gt;%\n    st_drop_geometry() %&gt;% # removes geometry - makes the following calculation more efficient \n    filter(!is.na(Accident_Datetime)) %&gt;%\n    count(??) \n\nJoin the census data with crashes_per_tract and then use a filter of n &gt; 0 to only keep the census tracts where crashes were recorded instead of all of Ramsey and Hennepin County.\n\ncrashes_per_tract_geo &lt;- ??? %&gt;% # sf object with census geometry goes first\n    left_join(??, by = ??) %&gt;%\n    filter(n &gt; 0)\n\nCreate the plot!!\n\nggplot() +\n    geom_sf(???) +\n    scale_fill_gradientn(colours = c(\"lightcyan\", \"lightcyan2\", \"lightskyblue3\", \"lightskyblue4\"))+\n    labs(fill = \"Crashes\", color = \"\", title = \"Number of pedestrian/bike crashes per census tract\") +\n    ggthemes::theme_map() + theme(legend.position = \"bottom\")\n\n\n\nExercise: Adding layers\nPlot a variable of your choice for census tracts in Hennepin and Ramsey County and add roads to the map.\nStart by downloading a shape file. For example, you could search for “Minnesota roads shape file”. For this example, visit this site and download the Shapefile Zip File. Unzip the file and put the folder in the same location as this Rmd file.\nLoad in the shapefile using st_read() and transform roads to have the same CRS as census2020 if necessary.\n\nroads &lt;- sf::st_read(\"tl_2019_27_prisecroads\")\n\n# Check CRS of roads and transform if necessary\n\nStart by using st_crop() to crop the roads map to the area we are interested in (Hennepin and Ramsey County).\n\nroads_sub &lt;- st_crop(roads,st_bbox(census2020))\n\nCreate the map!!\n\nggplot() +\n    geom_sf(??)+ #put census tracts on map and fill by your variable of interest\n    geom_sf(?? ,fill = \"gray\", color = \"gray\", lwd = 0.2)+ #roads data here\n    labs(??)+ # add labels to fit your variables \n    scale_fill_gradientn(colours = c(\"lightcyan\", \"lightcyan2\", \"lightskyblue3\", \"lightskyblue4\"))+ # change to preferred color palette\n    theme_classic()+\n    theme(axis.line = element_blank(), \n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        legend.position = \"bottom\", \n        plot.title.position = \"plot\", \n        plot.title = element_text(size = 8), \n        plot.subtitle = element_text(size = 8))\n\nHow to cite AI and other resources: If you use AI tools like ChatGPT or Google Bard, please copy and paste all prompts and output into an “Appendix” section of this assignment. If you use an AI tool, also list one environmentally-friendly action you could adopt (that you don’t already do) to offset the energy usage. Also list any websites used in this Appendix.\nSubmission details: Click the “Render” button to create an HTML report from your Quarto file. Open the HTML in your web browser and save the webpage as a PDF (Ctrl-P/Command P, choose “Save as PDF” as the Destination). Submit this PDF on Moodle AND the .qmd file by midnight on Wednesday, 9/20."
  },
  {
    "objectID": "03-adv-maps.html#additional-resources",
    "href": "03-adv-maps.html#additional-resources",
    "title": "Advanced Spatial Visualizations",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nSpatial Data Science https://r-spatial.org/book/\nLeaflet in R https://rstudio.github.io/leaflet/"
  },
  {
    "objectID": "04-interactive-viz.html",
    "href": "04-interactive-viz.html",
    "title": "Interactive visualization",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nEvaluate when it would be useful to use an interactive visualization or an animation and when it might not be necessary\nConstruct interactive visualizations and animations with plotly\nBuild a Shiny app that enables user to adjust visualization choices and explore linked visualizations\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)"
  },
  {
    "objectID": "04-interactive-viz.html#why-use-interactivity",
    "href": "04-interactive-viz.html#why-use-interactivity",
    "title": "Interactive visualization",
    "section": "Why use interactivity?",
    "text": "Why use interactivity?\nPros\n\nUsers can click, hover, zoom, and pan to get more detailed information\nUsers can get quickly and deeply explore the data via linked data representations\nAllows guided exploration of results without needing to share data\n\nCons\n\nTakes longer to design\nAnalyst might spend longer exploring an interactive visualization than a series of static visualizations\nPoor design could result in information overload"
  },
  {
    "objectID": "04-interactive-viz.html#common-features-of-interactive-visualizations",
    "href": "04-interactive-viz.html#common-features-of-interactive-visualizations",
    "title": "Interactive visualization",
    "section": "Common features of interactive visualizations",
    "text": "Common features of interactive visualizations\nCommon features of interactive visualizations include (reference):\n\nChanging data representation: providing options to change the type of plot displayed (e.g., allowing users to visualize temperature patterns over a month vs. over years)\nFocusing and getting details: mousing over part of a visualization to see an exact data value, zooming and panning\nData transformation: e.g., changing color scale, switching to/from log scale\nData selection and filtering: highlighting and brushing regions of a plot to focus the selected points; reordering and filtering data show in tables\nFinding corresponding information in multiple views: linked views that update dynamically based on interaction in another plot (often by zooming, panning, or selecting certain points)"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-0-app-planning",
    "href": "04-interactive-viz.html#exercise-0-app-planning",
    "title": "Interactive visualization",
    "section": "Exercise 0: App planning",
    "text": "Exercise 0: App planning\nCatalog the app’s layout and interactivity features as part of the app planning phase.\n\nNavigator: Open up the neighborhood diversity app for reference. The Navigator should explore the interactive features of the app and help the Driver sketch out a schematic of the app.\nDriver: Sketch the layout and general features of the app as the Navigator navigates. Draw arrows to indicate what parts of the app update in response to user input.\n\n\n\n\n\n\n\nReflect: App design\n\n\n\n\n\nIs the interactivity in this app needed? Does the interactivity actually help you gain more insight (and perhaps more efficiently) than a series of static visualizations? What static visualizations might be more useful?"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-1-setup-and-getting-acquainted",
    "href": "04-interactive-viz.html#exercise-1-setup-and-getting-acquainted",
    "title": "Interactive visualization",
    "section": "Exercise 1: Setup and getting acquainted",
    "text": "Exercise 1: Setup and getting acquainted\nSetup part 1: Load required packages at the top of app.R: shiny, tidyverse, sf, and plotly.\nSetup part 2: Data download and folder setup\nNavigate to the “Data for interactive viz activity” folder on Moodle and save the two files with the folder setup below:\n\n📂 YOUR_CLASS_FOLDER\n\n📂 interactive_viz\n\n📂 neighborhood_diversity\n\napp.R\n📂 data\n\ndata_by_dist.rds\ndata_by_year.csv\n\n\n\n\n\nSetup part 3: Below your library() calls, add the following commands to read in the data:\n\ndata_by_dist &lt;- read_rds(\"Enter the correct relative path to data_by_dist.rds\")\ndata_by_year &lt;- read_csv(\"Enter the correct relative path to data_by_year.csv\")\n\nGetting acquainted with the app and underlying code: Open this PDF or have the code printout distributed at the start of class in front of you. Also have the app running in your browser.\n\nDraw lines on the printout/PDF of what visual parts of the app correspond to which parts of code.\nWhat names/labels in the User Interface (ui) part of the app seem to be shared with the server part of the app? (Draw lines between the ui and server parts of the code.)\n\n\n\n\n\n\n\nStop to Share\n\n\n\n\n\nAs you work on the “Getting acquainted” part of this exercise, share with your partner some struggles you have with code and some strategies that you have tried."
  },
  {
    "objectID": "04-interactive-viz.html#input-functions",
    "href": "04-interactive-viz.html#input-functions",
    "title": "Interactive visualization",
    "section": "*Input() functions",
    "text": "*Input() functions\n\nBackground\nThe *Input() functions collect inputs from the user. The various types are listed on the right-hand side of the first page of the cheatsheet. You will list all the *Input() functions you want to use with their accompanying arguments inside the fluidPage() function in the ui portion. Separate the *Input() functions with commas.\nIn all the *Input() functions, the first two arguments are the same:\n\ninputId is how you will refer to this input in the server portion later\nlabel is how this will actually be labeled in your UI (what text shows up in the app)\n\nEach function has some additional arguments depending what you want to do.\n\n\nExercise 2: Add *Input()s\nAdd the following two user inputs to your app:\n\nDropdown to select the city name\nSlider to choose the span parameter for the scatterplot smooth\n\nUse the Shiny cheatsheet to find the *Input() functions that correspond to the two inputs above. Add them to the appropriate place within the ui object. Use commas to separate the inputs. You will have to look at the documentation for the *Input() functions to know how to use arguments beyond inputId and label. To view this documentation, type ?function_name in the Console.\nTo get the collection of city names from the data_by_dist dataset, you can use the pull() and unique() functions. Save the city names in an object called metro_names—this code can go just beneath where you read in the data.\nOnce you finish, run your app. Make sure you can select and move things around as expected. You won’t see any plots yet–we’ll work on those in the next exercises."
  },
  {
    "objectID": "04-interactive-viz.html#output-functions",
    "href": "04-interactive-viz.html#output-functions",
    "title": "Interactive visualization",
    "section": "*Output() functions",
    "text": "*Output() functions\n\nBackground\n*Output() functions in the ui portion work with the render*() functions in the server portion to to add R output to the UI. The *Output() functions are listed in the bottom center part of the first page of the cheatsheet.\nAll the *Output() functions have the same first argument, outputId, which is used how you will refer to this output in the server portion later (like the inputId in the *Input() functions).\n\n\nExercise 3: Add *Output()s\nAdd 3 plotOutput()s to the ui that will eventually be:\n\nA scatterplot of diversity score (entropy) versus distance to city hall (distmiles) with a smoothing line (smoothness controlled by the span parameter on your slider input)\nA map of diversity scores across the counties in the selected city\nA bar chart of the overall race distribution in the selected city (i.e., the total number of people in each race category in the city)\n\nFor now, don’t worry that the layout of the plots exactly matches the original neighborhood diversity app. (You will update this in your homework.)\nRun the app with the output. Notice that nothing really changes. Think of the outputs you just placed as placeholders—the app knows there will be a plot in the UI, but the details of what the plots will look like and the R code to create them will be in the server portion. Let’s talk about that now!"
  },
  {
    "objectID": "04-interactive-viz.html#render-functions",
    "href": "04-interactive-viz.html#render-functions",
    "title": "Interactive visualization",
    "section": "render*() functions",
    "text": "render*() functions\nThe render*() functions go in the server function of the app. The render*() functions use R code (i.e., standard ggplot code) to communicate with (“listen to”) the user inputs to create the desired output.\nThe render*() function you use will depend on the desired output. The bottom center of the cheatsheet shows how *Output() and render*() functions connect.\nIn general, the server section of code will look something like this:\n\nserver &lt;- function(input, output) {\n    output$outputId_of_interest &lt;- render*({ # Note the curly braces that enclose the R code below\n        # R code that creates the output and calls various input$InputId's\n    })\n}\n\nExample: Suppose that inside ui, we used plotOutput(outputId = \"timeplot\"):\n\nIn the server function, we would use output$timeplot &lt;- renderPlot({...}).\n\nThe ... would be replaced by detailed R plotting code.\nTo reference the inputs we create in the ui, we use input$inputID_name. e.g., if we had an *Input() with inputId = \"years\", we would use input$years in the server function.\n\n\n\nExercise 4: Add renderPlot()\nWhile our main goals is to make 3 plots, you will just make one of them in this exercise.\nAdd a renderPlot() functions inside the server portion of the code to make the scatterplot of diversity score (entropy) versus distance to city hall (distmiles) with a smoothing line. Reference the inputs you’ve already created in previous exercises by using filter() and ggplot() to render the desired interactive plot.\nNote: the geom_??? used to create the smoothing line has a span parameter. (Check out the documentation for that geom by entering ?geom_??? in the Console.)\nRun the app and check that the scatterplot displays and reacts to the chosen city and span parameter.\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWhat challenges are you encountering as we go through this new material? What parts of your interactions with your partner have been helpful or less helpful for your learning today?"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-5-turn-plots-into-plotlys",
    "href": "04-interactive-viz.html#exercise-5-turn-plots-into-plotlys",
    "title": "Interactive visualization",
    "section": "Exercise 5: Turn plots into plotlys",
    "text": "Exercise 5: Turn plots into plotlys\nIn a web application, having plots be plotly objects is just nice by default because of the great mouseover, zoom, and pan features.\nInside app.R, change all instances of plotOutput to plotlyOutput and all instances of renderPlot to renderPlotly. Make sure to add calls to ggplotly() too."
  },
  {
    "objectID": "05-data-types.html",
    "href": "05-data-types.html",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nDetermine the class of a given object and identify concerns to be wary of when manipulating that class of object (classes: numerics, logicals, factors, dates, strings, lists, data.frames/tibbles, matrices)\nExplain what vector recycling is, when it is used, when it can be a problem, and how to avoid those problems\nExplain the difference between implicit and explicit coercion\nExtract date-time information using the lubridate package\nRecode and manage factors using the forcats package\nManipulate and explore strings using the stringr package\nLists:\n\nSee how many objects (like the result of lm()) are lists\nSubset lists by index and name\nExplore the structure of nested lists with str()\n\nData frames/tibbles\n\nExplain the difference between a data.frame and a tibble (list columns)\n\nMatrices\n\nSubset matrices\n\nWrite R code to wrangle data from these different types\nRecognize several new R errors and warnings related to data types"
  },
  {
    "objectID": "05-data-types.html#numeric-and-integer-classes",
    "href": "05-data-types.html#numeric-and-integer-classes",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "Numeric and integer classes",
    "text": "Numeric and integer classes\nNumbers that we see in R are generally of the numeric class, which are numbers with decimals. The c() function below is a way to create a vector of multiple numbers.\n\nnumbers &lt;- c(1, 2, 3)\nclass(numbers)\n\n[1] \"numeric\"\n\n\nR also has an integer class which will most often be formed when using the : operator to form regularly spaced sequences.\n\nintegers &lt;- 1:3\nclass(integers)\n\n[1] \"integer\"\n\n\nIt will be important to know how to check whether a number is a numeric or integer because we’ll be using the purrr package very shortly which checks types very strictly (e.g., 1 as an integer cannot be combined with 1 as a numeric)"
  },
  {
    "objectID": "05-data-types.html#vector-recycling",
    "href": "05-data-types.html#vector-recycling",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "Vector recycling",
    "text": "Vector recycling\nSuppose that we wanted to update just the first two points values (e.g., we learned of a typo).\n\npoint_update &lt;- c(2,3)\nlakers2 &lt;- lakers %&gt;%\n    mutate(points = points + point_update)\nhead(lakers$points)\n\n[1] 0 0 0 0 0 2\n\nhead(lakers2$points)\n\n[1] 2 3 2 3 2 5\n\n\nUh oh! It looks like the 2,3 point update vector got repeated multiple times. This is called vector recycling. If you are trying to combine or compare vectors of different lengths, R will repeat (recycle) the shorter one as many times as it takes to make them the same length. When the longer vector’s length isn’t a multiple of the smaller one, we’ll get a warning.\n\npoint_update &lt;- c(2,3,2)\nlakers2 &lt;- lakers %&gt;%\n    mutate(points = points + point_update)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `points = points + point_update`.\nCaused by warning in `points + point_update`:\n! longer object length is not a multiple of shorter object length"
  },
  {
    "objectID": "05-data-types.html#explicit-coercion",
    "href": "05-data-types.html#explicit-coercion",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "Explicit coercion",
    "text": "Explicit coercion\nIn R there is a family of coercion functions that force a variable to be represented as a particular type. We have as.numeric() and as.integer() for numbers.\nMost commonly we will use these when numbers have accidentally been read in as a character or a factor. (More on factors later.)\nIn the example below we have a set of 4 points values, but the last entry was mistakenly typed as a space in the spreadsheet (instead of as an empty cell). We can see when we display points that all of the values have quotes around them and that the class of the points object is a character vector. (More on working with character objects next time.)\n\npoints &lt;- c(2, 3, 0, \" \")\npoints\n\n[1] \"2\" \"3\" \"0\" \" \"\n\nclass(points)\n\n[1] \"character\""
  },
  {
    "objectID": "05-data-types.html#regular-expressions",
    "href": "05-data-types.html#regular-expressions",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "Regular expressions",
    "text": "Regular expressions\n\nstr_view() - View the first occurrence in a string that matches the regex\nstr_view_all() - View all occurrences in a string that match the regex\nstr_count() - count the number of times a regex matches within a string\nstr_detect() - determine if regex is found within string\nstr_subset() - return subset of strings that match the regex\nstr_extract() - return portion of each string that matches the regex\nstr_replace_{all}() - replace portion of string that matches the regex with something else\nstr_remove_{all}() - like `str_replace(x, the_pattern, ““)"
  },
  {
    "objectID": "05-data-types.html#glue-package",
    "href": "05-data-types.html#glue-package",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "glue package",
    "text": "glue package\n\nlibrary(glue)\nmsleep %&gt;%\n  mutate(description = glue(\"The {name} typically sleeps for {sleep_total * 60} minutes and is awake for {awake * 60} minutes each day.\")) %&gt;% \n  select(name, sleep_total, awake, description)\n\n# A tibble: 83 × 4\n   name                       sleep_total awake description                     \n   &lt;chr&gt;                            &lt;dbl&gt; &lt;dbl&gt; &lt;glue&gt;                          \n 1 Cheetah                           12.1  11.9 The Cheetah typically sleeps fo…\n 2 Owl monkey                        17     7   The Owl monkey typically sleeps…\n 3 Mountain beaver                   14.4   9.6 The Mountain beaver typically s…\n 4 Greater short-tailed shrew        14.9   9.1 The Greater short-tailed shrew …\n 5 Cow                                4    20   The Cow typically sleeps for 24…\n 6 Three-toed sloth                  14.4   9.6 The Three-toed sloth typically …\n 7 Northern fur seal                  8.7  15.3 The Northern fur seal typically…\n 8 Vesper mouse                       7    17   The Vesper mouse typically slee…\n 9 Dog                               10.1  13.9 The Dog typically sleeps for 60…\n10 Roe deer                           3    21   The Roe deer typically sleeps f…\n# ℹ 73 more rows"
  },
  {
    "objectID": "05-data-types.html#tidytext-package",
    "href": "05-data-types.html#tidytext-package",
    "title": "Topic 5: Wrangling numerics, logicals, factors, and dates",
    "section": "tidytext package",
    "text": "tidytext package"
  },
  {
    "objectID": "06-functions-control-structs.html",
    "href": "06-functions-control-structs.html",
    "title": "Topic 6: Functions and control structures",
    "section": "",
    "text": "Learning goals\nAfter this lesson, you should be able to:\n\nRecognize when it would be useful to write a function\nIdentify the core components of a function definition and explain their role (the function() directive, arguments, argument defaults, function body, return value)\nDescribe the difference between argument matching by position and by name\nDescribe what the ... argument does and the rationale underlying the rules for named arguments in conjunction with ...\nWrite if-else, if-else if-else statements to conditionally execute code\nWrite your own function to carry out a repeated task\nProvide feedback on functions written by others\n\n\n\nNOTES\nInstead of introducing purrr, just do functions and basic control structures for this lesson\n\n\nPre-class preparation\nRead https://bookdown.org/rdpeng/rprogdatascience/functions.html or rather https://r4ds.had.co.nz/functions.html\nMoodle quiz - Ask students for input on “Gosh I just wish it was easier to do ___ in R”. This will lead into the “Finding existing functions” part of the activity.\n\n\nSetup\npurrr resources\n\nhttps://jennybc.github.io/purrr-tutorial/index.html\nhttps://www.rebeccabarter.com/blog/2019-08-19_purrr\n\n\nlibrary(purrr)\nlibrary(repurrrsive)\n\n\ndata(got_chars)\ngot &lt;- got_chars\n\n\n\nActivity ideas\nWriting functions from scratch: Function Challenge Relay: Divide the students into groups and set up stations with different R function challenges. Each station has a specific task that requires creating or using R functions. The groups rotate through the stations, completing the challenges together. For example, one station might require writing a function to calculate factorial, another to find the mean of a dataset, and so on.\nWrite a function that fits a linear model within subgroups of the data.\nFinding existing functions: Function Library Creation: Assign each group a specific topic or problem domain (e.g., mathematical functions, data manipulation, data visualization). Each group works together to research, design, and implement a set of R functions that address various aspects of their assigned topic. They can then share their function library with the class. Function Scavenger Hunt: Create a scavenger hunt where each group receives a list of R functions to find and examples of tasks to perform using those functions. The hunt can involve finding functions in R documentation, tutorials, or online resources. The group that completes the most tasks correctly wins.\nGroups can put together a nice resource for others (e.g., a cheat sheet). Something more user-friendly than a Google Doc.\nEditing functions writen by others: Function Debugging Party: Give each group a set of R functions with intentional errors or bugs. The groups work together to debug and correct the functions. This activity reinforces the importance of testing and troubleshooting code collaboratively. Function Code Review Workshop: Each group writes an R function and shares it with another group. The receiving group reviews the code, provides feedback, and suggests improvements. This exercise promotes collaborative code development and helps students learn from each other’s code.\n\n\nHomework\nHave students go from gap_nested -&gt; gap_simple and gap_split -&gt; gap_simple\nExtra: other combinations: ehh I don’t know if this is that useful\n\n\npurrr"
  },
  {
    "objectID": "activities.html",
    "href": "activities.html",
    "title": "Activities",
    "section": "",
    "text": "In-class activities"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework",
    "section": "",
    "text": "General instructions for homework:\n\nProcess section:\n\nOn getting help\n\nThings I Googled or asked on ChatGPT: There is no shame in having items here! But making note of this is important for noticing what you’re not “fluent” in yet. (e.g., when learning a new language, it would be helpful to write down words that you frequently have to look up to translate)\nThings I consulted with peers about\nOther resources that I consulted\n\nWhat was easy, medium, hard? Why?\n\n\nCommon elements of weekly homework:\n\nFirst part will always be to work on the most recent Tidy Tuesday."
  },
  {
    "objectID": "homework0.html",
    "href": "homework0.html",
    "title": "Homework 0",
    "section": "",
    "text": "A note from your instructor\n\n\n\nWhen I started college, the main thinking I did about my capital-F Future (that nebulous thing way out in the distance) was about what I would be doing after college. It made me very anxious.\nThrough the many years since my college experience, I have come to see that what allows me to be more at peace with my capital-F Future now is a deeper understanding of who I am and what my values are.\nI want to give you a chance to do this kind of thinking now with this “assignment”.\n\n\nI invite you to write an essay (tentatively) titled “My past, present and future and the values they express”. (Change the title if you wish!)\nThis essay does not need to be submitted and is not due at any point. If you ever wish to talk to me about what you wrote, the process of writing it, or what you’ve thought about after writing it, I’d love to do that over a walk or a cup of hot chocolate.\nI do hope that by writing it you are able to move forward with your college experience this semester with more peace and clarity. For that reason alone, I suggest that you write this essay by the end of the first week of class (Sunday, September 10).\nIt might be helpful to do/think about the following as you write:\n\nVisit this Values Exercise page to read a very short bit about core values and their role in a fulfilling life. Click the “Start the Exercise” button to complete a ~15 minute exercise to identify your core values.\nWhat events brought you to Macalester, and what core values do you think led you to choose Mac?\nWhere do you see yourself in 10 years? How do you see yourself living? What would it take to get to that point? To think through that process in steps, think about:\n\n10-year vision (what’s going on in 2033 and why?)\n5-year vision (what’s going on in 2028 and why?)\n2-year vision (what’s going on in 2025 and why?)\n1-year vision (what’s going on in 2024 and why?)\n6-month vision (what’s going on in Spring 2024 and why?)\nThinking about the “why” for these visions can help affirm and clarify the core values you ended up with from the Values Exercise above. For example, if part of your 5-year vision wasn’t happening, how would you feel and why?\n\n\nIf it helps at all to look at someone else’s vision as you craft your own, I tried to write my own 10-year vision earlier this summer."
  },
  {
    "objectID": "homework1.html",
    "href": "homework1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Required parts\nFinish the plot that we started in our Advanced Data Visualization in ggplot2 class activity up to the minimum requirements.\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework2.html",
    "href": "homework2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Required parts\n\nFinish the Open-ended Exercise in our Advanced Map Visualization class activity.\n\nSubmission details: Click the “Render” button to create an HTML report from your Quarto file. Open the HTML in your web browser and save the webpage as a PDF (Ctrl-P/Command P, choose “Save as PDF” as the Destination). Submit this PDF on Moodle AND the .qmd file by midnight on Wednesday, 9/20.\n\nComplete Milestone 1 of the course project. (Brainstorming ideas and data sources). Put this information in a # Project section that you add to the end of your 03-adv-maps.qmd.\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework3.html",
    "href": "homework3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Required parts\n\nFinish the Shiny app from the interactive viz class activity up to the minimum requirements.\n\nSubmission details: Submit the app.R file on Moodle by midnight on Wednesday, 9/27.\n\nWork towards Milestone 2 of the course project. (Nothing to turn in for Homework 3, but you should be making progress.)\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "",
    "text": "This is the course website for STAT/COMP 212: Intermediate Data Science at Macalester College for the Fall 2023 semester taught by Professor Leslie Myint. Materials were developed by Leslie Myint and Brianna Heggeseth."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/19",
    "text": "9/19\n\nOn Thursday:\n\nWe will spend the first 30 moving our course projects moving forward.\nIn the last hour of class, facilitators will come in to run an activity for the Classroom Community and Connectedness Survey. (I will be leaving.) A reminder of why this activity is important to me from our syllabus:\n“A sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).”"
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/14",
    "text": "9/14\n\nBefore next Tuesday’s class\n\nCheck the Schedule page. There is a short podcast segment (~7 min) to listen to and one guiding question to answer. This podcast segment shares a bit of wisdom about when it is/isn’t useful to make fancy visualizations.\nInstall the shiny and plotly packages. Post on the #questions channel on Slack if you run into problems. (Share your commands and error messages.)\n\nNext Thursday we will be having facilitators come in for the last hour of class for the Classroom Community and Connectedness Survey. (I will be leaving.)\n\nWe will use the first 30 to get our course projects moving forward."
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/12",
    "text": "9/12\n\nHomework 1 due Wednesday at midnight (Finishing up the temperature + precipitation plots from last Tuesday)\n\nUpdated submission instructions can be found here. (Also in the most recent Moodle announcement.)\n\nHomework 2 due next Wednesday, 9/20 has two parts:\n\nFinish Open-ended Exercise from today’s Advanced Map Visualization activity.\nComplete Milestone 1 of the course project\n\nThere is a final version of our syllabus that incorporates the learning goals and grading option that we discussed on our first day."
  },
  {
    "objectID": "index.html#section-3",
    "href": "index.html#section-3",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/7",
    "text": "9/7\n\nI’ll be adding a new version of the syllabus to our course website that incorporates our final choice for grading system and the learning goals that you contributed.\nComplete the pre-course survey by 3pm today to shape when I hold drop-in hours (office hours).\nLook at the updated Schedule page. We have Guiding Questions for next Tuesday’s class: advanced map visualization.\n\nNote that Guiding Questions never have to be turned in. Do answer them to the best of your ability before class. We’ll spend time at the start of class checking in on these."
  },
  {
    "objectID": "index.html#section-4",
    "href": "index.html#section-4",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/5",
    "text": "9/5\nTo do before class on Thursday:\n\nSet up R and RStudio using these instructions.\nJoin our Slack workspace.\n\nUpdate your Slack profile with preferred name, pronouns, name pronunciation. (To find your profile, click on your name under Direct Messages on the left menu, and click “Edit Profile”.)\nIntroduce yourself in the #general channel.\n\nComplete the pre-course survey.\nLook at the Guiding Questions for Thursday’s class on advanced ggplot2.\nTake a look at Homework 0.\n\nThis is a personal essay that doesn’t need to be turned in.\nTopic: Your 10-year vision\nMy hope is that writing this allows gives you more clarity on how to align what you do this semester (and beyond) with who/what/how you want to be.\n\nFinish writing your 12 favorite problems and post them in the #12-favorite-problems channel on Slack.\n\nWhen you connect with peers from Thursday onward, you’ll be using your 12FPs to get to know each other a bit first before working on activities together."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "The goal of the project is to build something awesome that you can showcase on your digital portfolio (your personal website)."
  },
  {
    "objectID": "project.html#milestone-1",
    "href": "project.html#milestone-1",
    "title": "Project",
    "section": "Milestone 1",
    "text": "Milestone 1\nIdentify a data context that interests you. (Your 12 favorite problems might serve as a good source of inspiration.) Identify 3 different data sources that relate to that context. Think beyond a spreadsheet; the most interesting projects may involve collecting and aggregating data from multiple sources and formats. We might not have covered all of the tools needed to acquire that data at this point, so check in with the instructor about the sources that you’ve found to make sure that they’re workable.\n\nExample non-spreadsheet data sources: search results on a webpage, text of an article, Tweets, other social media posts.\n\nBrainstorm 3 questions about your data context and sources that pique your curiosity.\nDue date: Wednesday, 9/20 as part of HW2."
  },
  {
    "objectID": "project.html#milestone-2",
    "href": "project.html#milestone-2",
    "title": "Project",
    "section": "Milestone 2",
    "text": "Milestone 2\nForm project teams. Finalize one initial data source and questions related to that source. Each team member should create 1 “ugly” (not fully polished) visualization to demonstrate viability of the research questions. (Think of this as visualization “prototyping”.)\nDue date: Wednesday, 10/4 as part of HW4."
  },
  {
    "objectID": "project.html#milestone-3",
    "href": "project.html#milestone-3",
    "title": "Project",
    "section": "Milestone 3",
    "text": "Milestone 3\n(NOT FINALIZED YET)\nPerform the data acquisition, wrangling, visualization, and modeling needed to answer one of your research questions. Note that your question might not be amenable to modeling (or to modeling that you’ve learned about so far). For that reason, modeling is not required, but visualization is.\nDue date: Present your visualization to the class for feedback on Thursday, 10/12."
  },
  {
    "objectID": "project.html#milestone-4",
    "href": "project.html#milestone-4",
    "title": "Project",
    "section": "Milestone 4",
    "text": "Milestone 4\n(NOT FINALIZED YET)\nAdjust data sources and research questions as needed based on the results of explorations so far. Perform the data acquisition, wrangling, visualization, and modeling needed to answer another one of your research questions. Submit “Rough Draft” to instructor for feedback.\nDue date: TBD"
  },
  {
    "objectID": "project.html#milestone-5",
    "href": "project.html#milestone-5",
    "title": "Project",
    "section": "Milestone 5",
    "text": "Milestone 5\n(NOT FINALIZED YET)\nAdjust data sources and research questions as needed based on the results of explorations so far. Perform the data acquisition, wrangling, visualization, and modeling needed to answer another one of your research questions. Submit “Final Draft”.\nDue date: TBD"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Readings in the schedule below refer to the following two textbooks (freely available online):\n\nModern Data Science with R (3e) by Baumer, Kaplan, and Horton (Abbreviated as MDSR)\nR for Data Science (2e) by Wickham, Cetinkaya-Rundel, and Grolemund (Abbreviated as R4DS)\n\nGuiding questions for the readings are available at the bottom of this page.\n\n\n\n  \n    Week\n    Tuesday\n    Thursday\n    Announcements\n  \n\n\n\n  \n    1\n    \n    \n      9/5: Welcome! Meeting each other and designing our learning community \n      Before class: Review the syllabus and think about the questions posed in the green \"Reflect\" blocks.\n    \n    \n      9/7: Advanced visualization in ggplot \n      Before class: Review the construction of plots from STAT 112 and STAT 155. Answer the Guiding Questions at the bottom of this page. \n    \n    \n    \n      Work on HW0 (your 10-year vision, doesn't need to be turned in).Look ahead to HW1\n    \n  \n  \n  \n  \n  \n    2\n    \n      9/12: Advanced map visualization \n      Before class: Watch this video on Coordinate Reference Systems, and answer the Guiding Questions at the bottom of this page.\n    \n    \n    \n      9/14: Advanced map visualization (continued) \n    \n    \n    Turn in HW1 by midnight on Wed 9/13. Look ahead to HW2 due Wednesday 9/20 at midnight.\n  \n  \n  \n  \n  \n    3\n    \n      9/19: Interactive visualization \n      Before class: Listen to this podcast from Chapter 7 (timestamp 18:09) through Chapter 8 (ending at timestamp 25:27). Answer the Guiding Question at the bottom of this page. Install the \"shiny\" and \"plotly\" R packages.\n    \n    \n    \n      9/21: Classroom Community and Connectedness (CC&C) Survey \n      For the first 30 minutes, we will move our course projects forward. In the last hour of class, CC&C facilitators will come in to run an activity on how community-building is going in our course.\n    \n    \n    Turn in HW2 by midnight on Wednesday 9/20. Look ahead to HW3.\n  \n  \n  \n  \n  \n    4\n    \n      9/26: Working with different data classes (Part 1)\n      \n    \n    \n    \n      9/28: Working with different data classes (Part 2) \n      \n    \n    \n    Turn in HW3 Look ahead to HW4.\n  \n  \n  \n  \n  \n    5\n    \n      10/3: Writing functions \n      Before class: (NOT FINAL YET) Read Chapter 26 (Functions) and Section 13.1 (if-else). \n    \n    \n    \n      10/5: Loops and iteration \n      Before class: (NOT FINAL YET) Read Chapter 27 (Iteration) and the following parts of this tutorial: Up through (and including) \"Simplest usage: repeated looping with map\" \n    \n    \n    Turn in HW4. Look ahead to HW5.\n  \n  \n  \n  \n  \n    6\n    \n      10/10: Iteration with purrr \n      Before class: (NOT FINAL YET) Read the remainder of this purrr tutorial. \n    \n    \n    \n      10/12: Data acquisition: databases \n      Before class: (NOT FINAL YET) Read Chapter 22 (Databases). \n    \n    \n    Turn in HW5. Look ahead to HW6.\n  \n  \n  \n  \n  \n    7\n    \n      10:17: Data acquisition: APIs \n      Before class: (NOT FINAL YET) Read Getting started with httr \n    \n    \n    \n      10/19: Data acquisition: Scraping \n      Before class: (NOT FINAL YET) Read the rvest vignette \n    \n    \n    Turn in HW6. Look ahead to HW7."
  },
  {
    "objectID": "schedule.html#advanced-visualization-in-ggplot",
    "href": "schedule.html#advanced-visualization-in-ggplot",
    "title": "Schedule",
    "section": "9/7: Advanced visualization in ggplot",
    "text": "9/7: Advanced visualization in ggplot\nTo review plot creation skills from STAT/COMP 112 and STAT 155, use the diamonds dataset in the ggplot2 package to recreate the following visualizations:\n\nlibrary(ggplot2)\ndata(diamonds)"
  },
  {
    "objectID": "schedule.html#advanced-map-visualization",
    "href": "schedule.html#advanced-map-visualization",
    "title": "Schedule",
    "section": "9/12: Advanced map visualization",
    "text": "9/12: Advanced map visualization\nAfter/while watching this video on Coordinate Reference Systems (CRS), answer the following questions:\n\nWhat is the shape of the Earth?\nWhy is GDA94 a great datum name?\nWhat are the two components of a CRS/GCS?\nWhy do we use many different local CRSs rather than just one CRS for the whole earth?\nWhy is it insufficient to identify a location by its latitude and longitude?\nWhy do we need to be mindful about CRSs when working with different spatial datasets?"
  },
  {
    "objectID": "schedule.html#interactive-visualization",
    "href": "schedule.html#interactive-visualization",
    "title": "Schedule",
    "section": "9/19: Interactive visualization",
    "text": "9/19: Interactive visualization\nAfter listening to this podcast from Chapter 7 (timestamp 18:09) through Chapter 8 (ending at timestamp 25:27), reflect on the following question:\n\nWhat was new, unexpected, or interesting in the discussion about animations, interactivity, and dashboards?"
  },
  {
    "objectID": "slides/02-adv-ggplot.html#welcome-back",
    "href": "slides/02-adv-ggplot.html#welcome-back",
    "title": "Day 2",
    "section": "Welcome back!",
    "text": "Welcome back!\nAs we prepare to gather as a class, think about the following:\n\nWhat themes emerge in your 12 favorite problems? (You’ll be sharing with partner(s) today.)\n\nRandom\n\nHow do you pronounce the name Sean Bean? 😆\n\nQuote of the day\n\nYou don’t rise to the level of your goals. You fall to the level of your systems.\n\nJames Clear, Atomic Habits"
  },
  {
    "objectID": "slides/03-adv-maps.html#as-we-gather",
    "href": "slides/03-adv-maps.html#as-we-gather",
    "title": "Advanced Spatial Visualizations",
    "section": "As we gather…",
    "text": "As we gather…\nCheck in with those around you–how is the semester going so far?\nOpen up your Process and Reflection Log (Google Doc)."
  },
  {
    "objectID": "slides/03-adv-maps.html#as-we-gather-1",
    "href": "slides/03-adv-maps.html#as-we-gather-1",
    "title": "Advanced Spatial Visualizations",
    "section": "As we gather…",
    "text": "As we gather…\nSit next to someone new. Share a favorite problem that helps you feel curious this week. In talking with your partner, what connections do you see to your own FPs?\nQuote of the day:\n\nThe more stuff you love the happier you will be.\n― Ross Gay, The Book of Delights\n\nOpen up your Process and Reflection Log (Google Doc).\n\nReshare it with me so that I can be a Commenter, and check the “Notify people” box.\nLeave it open. We are going to stop and reflect a few times today."
  },
  {
    "objectID": "slides/04-interactive-viz.html#as-we-gather",
    "href": "slides/04-interactive-viz.html#as-we-gather",
    "title": "Interactive visualization",
    "section": "As we gather…",
    "text": "As we gather…\nThink about what makes learning new code challenging for you and what strategies tend to work well or less well. You will work with someone random (and possibly new)–how can you best support your own and their learning?\nQuote of the day:\n\nIn fact, in addition to the fact that we all die, the most salient or unifying feature of we the living is that we cannot survive without help.\n― Ross Gay, Inciting Joy\n\nOpen up your Process and Reflection Log (Google Doc).\n\nLeave it open. We are going to stop and reflect a few times today."
  },
  {
    "objectID": "slides/04-interactive-viz.html#reflecting-on-our-shiny-activity",
    "href": "slides/04-interactive-viz.html#reflecting-on-our-shiny-activity",
    "title": "Interactive visualization",
    "section": "Reflecting on our Shiny activity",
    "text": "Reflecting on our Shiny activity\nComment/uncomment the selected lines—super useful for debugging!!\n\nMac: Command-Shift-C\nWindows: Ctrl-Shift-C\n\nWrite a few observations in your Process and Reflection Log (Google Doc):\n\nWhat was challenging about learning Shiny? (When) did things start to click?\nWe’ve worked with a few different partners now–in general what has been helpful/less helpful about working with others? What would you like to change in the future?"
  },
  {
    "objectID": "slides/day1.html#plan-for-today",
    "href": "slides/day1.html#plan-for-today",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Plan for today",
    "text": "Plan for today\n\nWhat is this course about?\nGet to know your classmates\nShaping our syllabus together\nCreate your personal website!\n\nWebsite content building + connecting with classmates"
  },
  {
    "objectID": "slides/day1.html#what-is-this-course-about",
    "href": "slides/day1.html#what-is-this-course-about",
    "title": "Welcome to Intermediate Data Science!",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nExpanding your abilities for self-reflection in service of:\n\nYour lifelong independent learning\nOur course community\n\nExpanding your data science toolbox:\n\nVisualization\nWrangling\nData acquisition\nData storytelling\n\n\nI’ve intentionally put reflection first and data science skills second not necessarily in order of importance but because cultivating data science skills will come automatically—reflection and community-building won’t."
  },
  {
    "objectID": "slides/day1.html#get-to-know-your-classmates",
    "href": "slides/day1.html#get-to-know-your-classmates",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Get to know your classmates",
    "text": "Get to know your classmates\nIn groups, introduce yourselves with the following prompts: (~2 minutes/person)\n\nName, preferred pronouns\nMacalester connections (e.g., majors/minors/concentrations, clubs, teams, events regularly attended)\nHow are you feeling about starting the academic year?\nWhat is one thing you wish came up more in conversation?\nIf you could use data to investigate anything, what would it be?\n\nWhen we come back together, you will introduce someone else from your group briefly with:\n\nTheir name and preferred pronouns\n1 memorable thing you learned about them from your conversation"
  },
  {
    "objectID": "slides/day1.html#syllabus-shaping-learning-goals",
    "href": "slides/day1.html#syllabus-shaping-learning-goals",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Syllabus shaping: learning goals",
    "text": "Syllabus shaping: learning goals\nNavigate to the Course learning goals section of our syllabus.\nPart 1: Reflect (~3 min)\nWrite a few sentences responding to the following questions:\n\nWhat are your goals in taking this class?\nDo you see your goals reflected in the course learning goals? If not, how would you like to see the course goals amended to see your goals reflected in them?\n\nPart 2: Share (~5 min)\nAt your tables, take turns sharing your responses to the above questions. As a group, summarize your discussion in this Google Doc. Elect 1 person to present this summary when we come together as a class to share."
  },
  {
    "objectID": "slides/day1.html#my-qualms-with-grades",
    "href": "slides/day1.html#my-qualms-with-grades",
    "title": "Welcome to Intermediate Data Science!",
    "section": "My qualms with grades",
    "text": "My qualms with grades\nGrades (final and intermediate letter grades/points) make me uncomfortable because they:\n\nTend to distract from learning (due to a greater focus on the grade than on qualitative feedback)\nCreate anxiety that hinders risk-taking and exploration\nCreate a power dynamic between me and you that I am uncomfortable with. (I feel like a gatekeeper.)\n\nIf I had my way, I would never assign letter grades and only give qualitative comments all semester. Unfortunately, I am required to submit a letter grade at the end of the course.\n\nI need your input: which of the following two grading systems should we use for the semester?"
  },
  {
    "objectID": "slides/day1.html#option-1",
    "href": "slides/day1.html#option-1",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Option 1",
    "text": "Option 1\nSummary: evaluation of learning is done by instructor\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nPass all homework assignments\nPass all but 1 homework assignment\nPass all but 2 homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects"
  },
  {
    "objectID": "slides/day1.html#option-2",
    "href": "slides/day1.html#option-2",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Option 2",
    "text": "Option 2\nSummary: evaluation of learning is done by students in conversation with instructor\nMain difference: The standards below are the basis for your self-evaluation. I will join in on the conversation after reviewing your work and your self-evaluation. We will assign grades through conversation.\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects"
  },
  {
    "objectID": "slides/day1.html#syllabus-shaping-grading-system",
    "href": "slides/day1.html#syllabus-shaping-grading-system",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Syllabus shaping: grading system",
    "text": "Syllabus shaping: grading system\nNavigate to the Grading and feedback section of our syllabus to refer to details of the two grading options as needed.\nPart 1: Reflect (~5 min)\nWrite a few sentences responding to the following questions:\n\nWhich of the two options would be better for motivating you to learn as much as possible, and why? For reducing stress?\nWith regards to motivation and stress, are there any other parts of the course (not directly related to the grading system) that you think would benefit from changing?\n\nPart 2: Share (~10-15 min)\nAt your tables, take turns sharing your responses to the above questions. As a group, summarize your discussion in this Google Doc. Elect 1 person to present this summary when we come together as a class to share."
  },
  {
    "objectID": "slides/day1.html#start-your-personal-website-quarto",
    "href": "slides/day1.html#start-your-personal-website-quarto",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Start your personal website: Quarto",
    "text": "Start your personal website: Quarto\nFile &gt; New Project &gt; New Directory &gt; Quarto Website\n\nName the directory personal_website.\nPut this directory in a place you’ll access beyond this course (and beyond Mac)\n\nSome files will get created in the directory, and your newly created website will open in your browser."
  },
  {
    "objectID": "slides/day1.html#your-quarto-site-what-are-these-files",
    "href": "slides/day1.html#your-quarto-site-what-are-these-files",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Your Quarto site: what are these files?",
    "text": "Your Quarto site: what are these files?\nQuarto markdown files: The formatting in these files is almost identical to RMarkdown files (e.g., * for italics, ** for bold, # for headers).\n\nindex.qmd: This generates the content on the Home page.\nabout.qmd: This generates the content on the About page.\n\nOther files:\n\n_quarto.yml: Controls metadata about the website and how it should be built\nstyles.css: Controls the visual appearance of the site (e.g., color themes, fonts, spacing)\n\nWARNING: The more you know about CSS, the more addicting it is! It is very easy to unintentionally spend hours playing with colors and site appearance. 😆"
  },
  {
    "objectID": "slides/day1.html#todays-goal-the-about-page",
    "href": "slides/day1.html#todays-goal-the-about-page",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Today’s goal: the “About” page",
    "text": "Today’s goal: the “About” page\nOne of the first questions that comes up in every job interview is a question about yourself: “Tell me about yourself. How did you get to this point? What type of work do you want to do?”\nCrafting your homepage and About page can help you prepare for this question and have benefits even before the interview.\nLet’s take a look at an approach for crafting a thoughtful about page."
  },
  {
    "objectID": "slides/day1.html#some-context",
    "href": "slides/day1.html#some-context",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Some context",
    "text": "Some context\nRichard Feynman was a Nobel prize-winning physicist whose contributions fundamentally reshaped our understanding of the physical world.\nA major part of his success was a method for viewing the world: a mindset of viewing the world through the lens of several open-ended questions. Feynman called these his “favorite problems.” He said of these problems:\n\nYou have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did [they] do it? [They] must be a genius!”\nQuote source: Forte Labs"
  },
  {
    "objectID": "slides/day1.html#the-12-favorite-problems-framework",
    "href": "slides/day1.html#the-12-favorite-problems-framework",
    "title": "Welcome to Intermediate Data Science!",
    "section": "The 12 Favorite Problems framework",
    "text": "The 12 Favorite Problems framework\nEveryone can generate a list of their own 12 favorite problems - a set of meaningful open-ended questions that allow you to learn, explore, and act with intention on your biggest interests in life. Their benefits:\n\n\nDedicate your time and attention to ideas that truly spark your curiosity\nSee how a piece of information might be useful and why it’s worth keeping\nSee insightful patterns across multiple subjects that seem unrelated, but might share a common thread\nFocus the impact of your work on problems where you can make a real difference\nPrime your subconscious to notice helpful solutions to your biggest challenges in the world around you\nAttract like-minded people who have the same interests and goals as you\n\nSource: Forte Labs"
  },
  {
    "objectID": "slides/day1.html#brainstorming-our-12-favorite-problems-fps",
    "href": "slides/day1.html#brainstorming-our-12-favorite-problems-fps",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Brainstorming our 12 favorite problems (FPs)",
    "text": "Brainstorming our 12 favorite problems (FPs)\nNavigate to this article by Tiago Forte, and scroll down to the first step “Get started with these prompts.”\nWe’ll take 15-20 minutes to brainstorm our 12 FPs in the about.qmd file of your new website project.\nTiago Forte provides examples of his 12 FPs in his post. Feel free to also look at my own for more examples. (I’m working on updating my 12 FPs today alongside you!)\nWhat does this have to do with data science?? The 12 FP framework is a way of filtering the deluge of information thrown at us to the precious subset that matter most to our deepest questions. In other words, using data of all forms most effectively in our day-to-day lives. I truly believe that adopting this approach will help you become the kinds of data scientists who will be invaluable wherever you go."
  },
  {
    "objectID": "slides/day1.html#sharing-our-12-fps",
    "href": "slides/day1.html#sharing-our-12-fps",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Sharing our 12 FPs",
    "text": "Sharing our 12 FPs\nIn groups, each person will have ~2 minutes to share their top 2 FPs and get some feedback from the group. The group should give feedback to help make the FPs more specific, counterintuitive, and interdiscipinary:\n\nSpecific:\n\nOriginal: “How can I be a better leader?” is a little broad.\nPossible improvement: “How can I be a better leader as an introvert?”\n\nCounterintuitive:\n\nOriginal: “How can I improve the standard of living in the global south?”\nPossible improvement: “How can I improve the standard of living in the global south without further contributing to the climate change that threatens those regions the most?”\n\nInterdisciplinary:\n\nOriginal: How can I improve education?”\nPossible improvement: “How can I improve education by borrowing ideas from video games?”\n\n\n(Examples from Forte Labs)"
  },
  {
    "objectID": "slides/day1.html#free-time",
    "href": "slides/day1.html#free-time",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Free time",
    "text": "Free time\nThe remainder of the class period is free time. Some suggestions for spending the time:\n\nGet up and sit with new people. Share your 12 FPs with each other and get further feedback.\nKeep working on your website. Google to learn more about CSS and play with the appearance of your page in the styles.css file.\nClarify anything about the course with me."
  },
  {
    "objectID": "slides/day1.html#announcements",
    "href": "slides/day1.html#announcements",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Announcements",
    "text": "Announcements\nTo do before class on Thursday:\n\nSet up R and RStudio using these instructions.\nJoin our Slack workspace.\n\nUpdate your Slack profile with preferred name, pronouns, name pronunciation. (To find your profile, click on your name under Direct Messages on the left menu, and click “Edit Profile”.)\nIntroduce yourself in the #general channel.\n\nComplete the pre-course survey.\nLook at the Guiding Questions for Thursday’s class on advanced ggplot2.\nTake a look at Homework 0.\n\nThis is a personal essay that doesn’t need to be turned in.\nTopic: Your 10-year vision\nMy hope is that writing this allows gives you more clarity on how to align what you do this semester (and beyond) with who/what/how you want to be.\n\nFinish writing your 12 favorite problems and post them in the #12-favorite-problems channel on Slack.\n\nWhen you connect with peers from Thursday onward, you’ll be using your 12FPs to get to know each other a bit first before working on activities together."
  },
  {
    "objectID": "syllabus_final.html",
    "href": "syllabus_final.html",
    "title": "Final Syllabus",
    "section": "",
    "text": "Nature doesn’t reveal its secrets easily. - Thomas Kempa\n\nNor do data.\nBut that is exactly what can make data science so thrilling!\nThis course is about empowering you with the wisdom to ask the best questions of data–ones that are meaningful, adaptive, and equity-minded–and the technical savvy to answer them.\nBecause your careers (whether in data science or not), will all involve further learning and working with others, my other primary goal is for you to cultivate self-reflection skills with regards to your own learning and your collaboration with others. In this way, I hope that you feel confident learning new skills on your own in the future and contributing to a welcoming work community.\n\n\n\n\n\n\nCourse catalog description\n\n\n\n\n\nThis second course in the data science curriculum emphasizes advanced data wrangling and manipulation, interactive visualization, writing functions, working with data in databases, version control, and data ethics. Through open-ended and interdisciplinary projects, students practice the constant feedback loop of asking questions of the data, manipulating the data to help answer the question, and then returning to more questions. Prerequisite(s): COMP 112 and COMP 123 and STAT 155; STAT 253 recommended but not required.\n\n\n\n\n\nBy the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(+) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases (*)\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python (*)\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\n\n(+) Collect data ethically in a way that doesn’t undermine communities and people\n\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nYour feedback\n\n\n\nBased on our first day of class discussions, I’ve indicated with a (+) clarifications/details that you added to our existing learning goals and put a (*) next to existing goals that were underscored as desired ones."
  },
  {
    "objectID": "syllabus_final.html#course-learning-goals",
    "href": "syllabus_final.html#course-learning-goals",
    "title": "Final Syllabus",
    "section": "",
    "text": "By the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(+) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases (*)\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python (*)\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\n\n(+) Collect data ethically in a way that doesn’t undermine communities and people\n\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nYour feedback\n\n\n\nBased on our first day of class discussions, I’ve indicated with a (+) clarifications/details that you added to our existing learning goals and put a (*) next to existing goals that were underscored as desired ones."
  },
  {
    "objectID": "syllabus_final.html#how-to-contact-me",
    "href": "syllabus_final.html#how-to-contact-me",
    "title": "Final Syllabus",
    "section": "How to contact me",
    "text": "How to contact me\n\n\n\n\n\n\nCall me “Leslie”\n\n\n\nStudents sometimes wonder what to call their professors. I prefer to be called Leslie (lez-lee), but if you prefer to be more formal, I am also ok with Professor Myint (pronounced “mee-int”). My preferred gender pronouns are she/her/hers.\nPlease help me make sure that I call you by your preferred name and pronouns too!\n\n\nI love getting to talk to students outside of class time—whether about class-related topics or anything else. Come chat with me!\nI’ll be setting times for drop-in hours based on feedback from the pre-course survey. I’ll update my drop-in hours on our course homepage and Moodle when they’re finalized.\nI’m also happy to meet one-on-one if my normal drop-in hours don’t work. You can schedule a time to meet with me via Calendly.\nI’ll also often be in the Leonard Center weight room from about 4:30-5:10 some weekdays. Feel free to say hello!"
  },
  {
    "objectID": "syllabus_final.html#discussion-board-slack",
    "href": "syllabus_final.html#discussion-board-slack",
    "title": "Final Syllabus",
    "section": "Discussion board (Slack)",
    "text": "Discussion board (Slack)\nSlack is a commonly used communication tool in industry and is useful to be familiar with, so we’ll be using it as our discussion board.\n\nIf you’re new to Slack, this video provides a quick overview.\nFirst join our STAT/COMP 212: Fall 2023 workspace here.\nAfter joining, you can access our workspace here. (You might want to bookmark this if view)"
  },
  {
    "objectID": "syllabus_final.html#community-is-key",
    "href": "syllabus_final.html#community-is-key",
    "title": "Final Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nOur class is participating in the Classroom Community & Connectedness Project this semester. On Thursday, September 21 our class sessions will be a facilitated class activity (peers and facilitators only; I will not be present) to collectively reflect on strengthening our classroom community, with the intent of improving the learning environment for all of us.\nYour participation is voluntary, but very much appreciated. The project is co-sponsored by Macalester’s Serie Center for Scholarship and Teaching and our Office of Institutional Research & Assessment."
  },
  {
    "objectID": "syllabus_final.html#reflection-is-paramount",
    "href": "syllabus_final.html#reflection-is-paramount",
    "title": "Final Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that as technology evolves, some part of it will become out of date during your careers. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content–it’s fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection as a goal for our course in both content learning and collaborative activities. (Note that these reflection goals are the first two course learning goals.)"
  },
  {
    "objectID": "syllabus_final.html#mistakes-are-essential",
    "href": "syllabus_final.html#mistakes-are-essential",
    "title": "Final Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field. - Niels Bohr, Nobel Prize-winning physicist\n\nI don’t feel comfortable working with a new R package until I’ve seen the same errors over and over again. Seeing new errors helps me understand the constraints of the code and the assumptions that I was making about my data.\nWe’re going to be seeking out mistakes like my cats hunt for leftover food scraps.\n\n\n\nMy cat Potato attempting to eat my daughter’s dinner"
  },
  {
    "objectID": "syllabus_final.html#communication-is-a-superpower",
    "href": "syllabus_final.html#communication-is-a-superpower",
    "title": "Final Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas–whether through writing, visuals, or oral presentation–I want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What’s more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n— David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus_final.html#outside-of-class",
    "href": "syllabus_final.html#outside-of-class",
    "title": "Final Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class reading: Most class periods will have a required reading to review ideas from previous courses or to familiarize yourself with new concepts before seeing them again in class. My goal for these readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. I will provide Guiding Questions for each reading to focus your attention.\n\n\n\n\n\n\nSuggestion\n\n\n\nScan the Guiding Questions before reading to preview the main ideas. Fill in answers to these questions as you read. Ask (and answer!) questions in the #questions channel in our Slack workspace.\n\n\nPodcast discussions: About every other week, we will discuss a podcast for the first ~20 minutes of class. These podcasts are meant to expose you aspects of data science in industry. Record anything that you’re curious about, and come prepared to discuss.\n\n\n\n\n\n\nYour own media contributions\n\n\n\nThroughout the semester, if you come across any media that is relevant to the course, feel free to suggest it as a discussion piece by emailing the instructor or posting it in the #general channel in our Slack workspace.\n\n\n\n\n\n\n\n\nOther suggestions for out-of-class time\n\n\n\n\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the weekly homework.\nCome to instructor drop-in hours to chat about the course or anything else 😃"
  },
  {
    "objectID": "syllabus_final.html#during-class",
    "href": "syllabus_final.html#during-class",
    "title": "Final Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.) I’ll always leave a few minutes at the end of class for synthesis. Use this time to update your reflections and summarize the key takeaways from class."
  },
  {
    "objectID": "syllabus_final.html#instructors-philosophy",
    "href": "syllabus_final.html#instructors-philosophy",
    "title": "Final Syllabus",
    "section": "Instructor’s philosophy",
    "text": "Instructor’s philosophy\nFor a long time, I have been uncomfortable with the outsized role that letter grades play in education. The article Teaching More by Grading Less (Or Differently) by Schinske and Tanner (source) shaped many of my viewpoints and may be an interesting read for you.\nIn short, grades tend to distract from learning (due to a greater focus on the grade than on qualitative feedback), create anxiety that hinders risk-taking and exploration, and create a power dynamic between the instructor and students that I am uncomfortable with.\nIf I had my way, I would never assign letter grades and only give qualitative comments all semester. Unfortunately, I am required to submit a letter grade at the end of the course.\n\nThere were two grading options presented in the preliminary syllabus. The consensus of both course sections was Option 2, which is detailed below."
  },
  {
    "objectID": "syllabus_final.html#grading-system",
    "href": "syllabus_final.html#grading-system",
    "title": "Final Syllabus",
    "section": "Grading system",
    "text": "Grading system\n\nOverview\nIn the grading system chosen, evaluation (assigning of letter grades) occurs as a conversation between you and me–a conversation that you start. Using the qualities of A, B, and C letter grades (section below), you will self-assess your work using more detailed evaluation guidelines provided in reflection prompts and comments on your work. As part of this assessment you will propose your letter grade. I will also do this evaluation on my own and read your self-assessment afterwards. We will use all of this information to have a conversation about your progress. If we agree on the letter grade, that will be the grade you receive. If we disagree, we will use our conversation to come to a consensus. As part of consensus-building, we may discuss reframing both of our perspectives or additional work/revisions.\nI recognize that no single grading system can be ideal for everyone, but I do hope that the reflection, honesty, and conversation that are central to this system support your learning. Please reach out to me if something could be going better for you. I am always willing to talk. It’s your education–I want you to have a voice in it.\n\n\nWhat kind of work characterizes A, B, and C grades?\nThe table below describes the qualities of A, B, and C grades in terms of the 3 core course components: reflections, homework, and the final project.\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\nDetails about the course components are given below:\n\nSelf-reflection:\n\nWe will look at the growth in your reflection process over the course of 3 substantive reflections. These will roughly come a month into the course, mid-course, and the end of the semester.\n\nMy expectation is that your mid-course and end-of-course reflections show that your are using feedback from previous reflections.\n\nWe will look at the consistency in your reflection process by monitoring your Process and Reflection Google Doc.\n\nMy expectation is that you are filling this in regularly throughout class activities and through work outside of class.\n\n\nHomework: We will have weekly homework in which you will complete activities that we start in class. The requirements for passing the assignment will be clearly stated in the homework directions.\n\nIf you do not pass an assignment and wish to revise your work, you may resubmit the assignment the following week. This revision needs to be submitted by 2 weeks after the original homework due date. (See my policy on late work.)\n\nFinal project: For this semester-long project, you will receive regular feedback on the quality of the different project aspects and will have the opportunity to improve the quality of the different aspects as you continue working.\n\n\n\nHow will course components be evaluated?\nIn each of the 3 substantive reflections (month, mid-semester, end-of-semester), you will evaluate yourselves using self-assessment prompts and qualitative feedback from me on your reflections, homework, and project work.\nFor each of the 3 substantive reflections, you will receive a prompt that guides you through how to look at your work, my comments, solutions, and prior reflections to craft your self-assessment on your reflection process, homework, and project work. I will use the same prompts/process to assess your work before we come together for conversation.\nNote: Your self-assessments need to be based on demonstrated evidence in the work that you submit. For example, if you have struggled with the data wrangling homework assignments and say in your self-evaluation that your understanding is now strong after reviewing feedback, this is not sufficient evidence. You would need to demonstrate your stronger understanding of data wrangling by submitting a revision of the data wrangling homework. (See policy on late work.)"
  },
  {
    "objectID": "syllabus_final.html#late-work",
    "href": "syllabus_final.html#late-work",
    "title": "Final Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will be due weekly on Wednesdays at midnight. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. Limited extensions will always be granted:\n\nMy ideal extension: Turn in the homework by the following Monday morning at 9am. (A 4 day, 9 hour extension)\n\nWhy is this ideal for me? I want to return feedback on homework to everyone before the following Tuesday’s class because we will be briefly reviewing homework feedback in small groups.\n\nFirm limit on extensions: You must turn in the homework by 2 weeks after the due date (Wednesdays at 9am).\n\nWhy is this my firm limit? I post solutions to the homework at this point.\nWhat if it’s past the 2-week limit and you still want to turn in the homework in some form? If this is the case, you need to create your own equivalent homework. This involves mapping the original homework’s exercises to a new dataset and completing those exercises. Note that I can’t make any guarantees about when I can get you feedback on this late submission. (Only guarantee = by the end of the semester)"
  },
  {
    "objectID": "syllabus_final.html#academic-integrity",
    "href": "syllabus_final.html#academic-integrity",
    "title": "Final Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus_final.html#artificial-intelligence-ai-use",
    "href": "syllabus_final.html#artificial-intelligence-ai-use",
    "title": "Final Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nLearning to use AI tools is an emerging skill that we will explore together in this course. I expect you to use AI (ChatGPT, Google Bard)—in fact, some assignments may require it.\nHowever, you should be aware of the limits of AI:\n\nAI is a tool, but one that you need to acknowledge using. Any ideas, language, or code that is produced by AI must be cited, just like any other resource. [sample suggestion: Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you used to get the results.] Failure to do so is in violation of the academic integrity policy at Macalester College.\nDon’t trust anything AI says. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you understand.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nHow to cite usage of AI: Please copy and paste all prompts and output into an Appendix section accompanying each problem of an assignment.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "syllabus_prelim.html",
    "href": "syllabus_prelim.html",
    "title": "Preliminary Syllabus",
    "section": "",
    "text": "Nature doesn’t reveal its secrets easily. - Thomas Kempa\n\nNor do data.\nBut that is exactly what can make data science so thrilling!\nThis course is about empowering you with the wisdom to ask the best questions of data–ones that are meaningful, adaptive, and equity-minded–and the technical savvy to answer them.\nBecause your careers (whether in data science or not), will all involve further learning and working with others, my other primary goal is for you to cultivate self-reflection skills with regards to your own learning and your collaboration with others. In this way, I hope that you feel confident learning new skills on your own in the future and contributing to a welcoming work community.\n\n\n\n\n\n\nCourse catalog description\n\n\n\n\n\nThis second course in the data science curriculum emphasizes advanced data wrangling and manipulation, interactive visualization, writing functions, working with data in databases, version control, and data ethics. Through open-ended and interdisciplinary projects, students practice the constant feedback loop of asking questions of the data, manipulating the data to help answer the question, and then returning to more questions. Prerequisite(s): COMP 112 and COMP 123 and STAT 155; STAT 253 recommended but not required.\n\n\n\n\n\nBy the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nReflect\n\n\n\n\nWhich of the learning goals above do you disagree with or want more clarity on?\nDo you have any goals that you’d like to include on this list?"
  },
  {
    "objectID": "syllabus_prelim.html#course-learning-goals",
    "href": "syllabus_prelim.html#course-learning-goals",
    "title": "Preliminary Syllabus",
    "section": "",
    "text": "By the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nReflect\n\n\n\n\nWhich of the learning goals above do you disagree with or want more clarity on?\nDo you have any goals that you’d like to include on this list?"
  },
  {
    "objectID": "syllabus_prelim.html#how-to-contact-me",
    "href": "syllabus_prelim.html#how-to-contact-me",
    "title": "Preliminary Syllabus",
    "section": "How to contact me",
    "text": "How to contact me\n\n\n\n\n\n\nCall me “Leslie”\n\n\n\nStudents sometimes wonder what to call their professors. I prefer to be called Leslie (lez-lee), but if you prefer to be more formal, I am also ok with Professor Myint (pronounced “mee-int”). My preferred gender pronouns are she/her/hers.\nPlease help me make sure that I call you by your preferred name and pronouns too!\n\n\nI love getting to talk to students outside of class time—whether about class-related topics or anything else. Come chat with me!\nI’ll be setting times for drop-in hours based on feedback from the pre-course survey. I’ll update my drop-in hours on our course homepage and Moodle when they’re finalized.\nI’m also happy to meet one-on-one if my normal drop-in hours don’t work. You can schedule a time to meet with me via Calendly.\nI’ll also often be in the Leonard Center weight room from about 4:30-5:10 some weekdays. Feel free to say hello!"
  },
  {
    "objectID": "syllabus_prelim.html#discussion-board-slack",
    "href": "syllabus_prelim.html#discussion-board-slack",
    "title": "Preliminary Syllabus",
    "section": "Discussion board (Slack)",
    "text": "Discussion board (Slack)\nSlack is a commonly used communication tool in industry and is useful to be familiar with, so we’ll be using it as our discussion board.\n\nIf you’re new to Slack, this video provides a quick overview.\nFirst join our STAT/COMP 212: Fall 2023 workspace here.\nAfter joining, you can access our workspace here. (You might want to bookmark this if view)"
  },
  {
    "objectID": "syllabus_prelim.html#community-is-key",
    "href": "syllabus_prelim.html#community-is-key",
    "title": "Preliminary Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nOur class is participating in the Classroom Community & Connectedness Project this semester. On Thursday, September 21 our class sessions will be a facilitated class activity (peers and facilitators only; I will not be present) to collectively reflect on strengthening our classroom community, with the intent of improving the learning environment for all of us.\nYour participation is voluntary, but very much appreciated. The project is co-sponsored by Macalester’s Serie Center for Scholarship and Teaching and our Office of Institutional Research & Assessment."
  },
  {
    "objectID": "syllabus_prelim.html#reflection-is-paramount",
    "href": "syllabus_prelim.html#reflection-is-paramount",
    "title": "Preliminary Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that as technology evolves, some part of it will become out of date during your careers. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content–it’s fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection as a goal for our course in both content learning and collaborative activities. (Note that these reflection goals are the first two course learning goals.)"
  },
  {
    "objectID": "syllabus_prelim.html#mistakes-are-essential",
    "href": "syllabus_prelim.html#mistakes-are-essential",
    "title": "Preliminary Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field. - Niels Bohr, Nobel Prize-winning physicist\n\nI don’t feel comfortable working with a new R package until I’ve seen the same errors over and over again. Seeing new errors helps me understand the constraints of the code and the assumptions that I was making about my data.\nWe’re going to be seeking out mistakes like my cats hunt for leftover food scraps.\n\n\n\nMy cat Potato attempting to eat my daughter’s dinner"
  },
  {
    "objectID": "syllabus_prelim.html#communication-is-a-superpower",
    "href": "syllabus_prelim.html#communication-is-a-superpower",
    "title": "Preliminary Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas–whether through writing, visuals, or oral presentation–I want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What’s more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n— David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus_prelim.html#outside-of-class",
    "href": "syllabus_prelim.html#outside-of-class",
    "title": "Preliminary Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class reading: Most class periods will have a required reading to review ideas from previous courses or to familiarize yourself with new concepts before seeing them again in class. My goal for these readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. I will provide Guiding Questions for each reading to focus your attention.\n\n\n\n\n\n\nSuggestion\n\n\n\nScan the Guiding Questions before reading to preview the main ideas. Fill in answers to these questions as you read. Ask (and answer!) questions in the #questions channel in our Slack workspace.\n\n\nPodcast discussions: About every other week, we will discuss a podcast for the first ~20 minutes of class. These podcasts are meant to expose you aspects of data science in industry. Record anything that you’re curious about, and come prepared to discuss.\n\n\n\n\n\n\nYour own media contributions\n\n\n\nThroughout the semester, if you come across any media that is relevant to the course, feel free to suggest it as a discussion piece by emailing the instructor or posting it in the #general channel in our Slack workspace.\n\n\n\n\n\n\n\n\nOther suggestions for out-of-class time\n\n\n\n\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the weekly homework.\nCome to instructor drop-in hours to chat about the course or anything else 😃"
  },
  {
    "objectID": "syllabus_prelim.html#during-class",
    "href": "syllabus_prelim.html#during-class",
    "title": "Preliminary Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.) I’ll always leave a few minutes at the end of class for synthesis. Use this time to update your reflections and summarize the key takeaways from class."
  },
  {
    "objectID": "syllabus_prelim.html#option-1-evaluation-of-learning-is-done-by-instructor",
    "href": "syllabus_prelim.html#option-1-evaluation-of-learning-is-done-by-instructor",
    "title": "Preliminary Syllabus",
    "section": "Option 1: evaluation of learning is done by instructor",
    "text": "Option 1: evaluation of learning is done by instructor\nThe table below describes the qualities of A, B, and C grades in terms of the 3 core course components: reflections, homework, and the final project.\nIn order to earn a given letter grade, ALL of the requirements in the column must be met. (e.g., In order to earn an A, everything in the first column must be true.)\nThere is a possibility that by the end of the semester, work for the different course components falls under different letter grades. (e.g., A-level for reflections and homework, but B-level for project).\n\nIf this happens, towards the end of the semester I will ask you to submit a written justification for the grade that you think you deserve. We will have a conference in which we discuss your justification.\nIf we agree, your proposed grade will be your final grade.\nIf we disagree, we will discuss what needs to be done next to come to an agreement. (This may involve being doing extra work or revisions.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nPass all homework assignments\nPass all but 1 homework assignment\nPass all but 2 homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\nDetails about the course components are given below:\n\nSelf-reflection:\n\nI will look at the growth in your reflection process over the course of 3 substantive reflections. These will roughly come a month into the course, mid-course, and the end of the semester.\n\nMy expectation is that your mid-course and end-of-course reflections show that your are using feedback from previous reflections.\n\nI will look at the consistency in your reflection process by monitoring your Process and Reflection Google Doc.\n\nMy expectation is that you are filling this in regularly throughout class activities and through work outside of class.\n\n\nHomework: We will have weekly homework in which you will complete activities that we start in class. The requirements for passing the assignment will be clearly stated in the homework directions.\n\nIf you do not pass an assignment and wish to revise your work, you may resubmit the assignment the following week. This revision needs to be submitted by 2 weeks after the original homework due date. (See my policy on late work.)\n\nFinal project: For this semester-long project, you will receive regular feedback on the quality of the different project aspects and will have the opportunity to improve the quality of the different aspects as you continue working."
  },
  {
    "objectID": "syllabus_prelim.html#option-2-evaluation-of-learning-is-done-by-students-in-conversation-with-instructor",
    "href": "syllabus_prelim.html#option-2-evaluation-of-learning-is-done-by-students-in-conversation-with-instructor",
    "title": "Preliminary Syllabus",
    "section": "Option 2: evaluation of learning is done by students in conversation with instructor",
    "text": "Option 2: evaluation of learning is done by students in conversation with instructor\nWhat constitutes A, B, and C-level work is essentially identical in Options 1 and 2 (see table below). That is, my standards for high quality work are the same between the two.\nWhat’s different is how (who) participates in the evaluation process. In Option 1, I am making the final judgment on the quality of your work for all course components. In Option 2, you will start the assessment of quality by evaluating yourselves using qualitative feedback on all of your work.\nIn Option 2, the qualitative comments that you receive on all your work (reflections, homework, project) will form the basis of your self-evaluation. That is, you will review all comments from me and use this to gauge the degree to which you are meeting the course learning goals. (On homework, you will not receive a pass/not passing designation—you’ll just receive comments.) You will write self-evaluations ~1 month into the semester, in the middle of the semester (before midterm grades are due), and a final one at the end of the semester. In all of these self-evaluations, you will propose the grade that you think deserve. I will also evaluate your work, and if we disagree on the grade, we will meet to discuss what needs to be done next to come to an agreement. (This may involve being doing extra work or revisions.)\nNote: Your self-evaluations need to be based on demonstrated evidence in the work that you submit. For example, if you have struggled with the data wrangling homework assignments and say in your self-evaluation that your understanding is now strong after reviewing feedback, this is not sufficient evidence. You would need to demonstrate your stronger understanding of data wrangling by submitting a revision of the data wrangling homework. (See policy on late work.)\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\n\n\n\n\n\n\nComparing Options 1 and 2\n\n\n\nBoth options satisfy my goal to have high standards for your learning that are achievable through thoughtful revision. No matter what option we use, you’ll have a personal Google Sheet for tracking your progress over time.\nMy other goals for our grading system are for it to motivate you to learn as much as possible and to reduce stress. For these goals, your input during our Day 1 discussion will be very valuable."
  },
  {
    "objectID": "syllabus_prelim.html#late-work",
    "href": "syllabus_prelim.html#late-work",
    "title": "Preliminary Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will be due weekly on Wednesdays at midnight. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. Limited extensions will always be granted:\n\nMy ideal extension: Turn in the homework by the following Monday morning at 9am. (A 4 day, 9 hour extension)\n\nWhy is this ideal for me? I want to return feedback on homework to everyone before the following Tuesday’s class because we will be briefly reviewing homework feedback in small groups.\n\nFirm limit on extensions: You must turn in the homework by 2 weeks after the due date (Wednesdays at 9am).\n\nWhy is this my firm limit? I post solutions to the homework at this point.\nWhat if it’s past the 2-week limit and you still want to turn in the homework in some form? If this is the case, you need to create your own equivalent homework. This involves mapping the original homework’s exercises to a new dataset and completing those exercises. Note that I can’t make any guarantees about when I can get you feedback on this late submission. (Only guarantee = by the end of the semester)"
  },
  {
    "objectID": "syllabus_prelim.html#academic-integrity",
    "href": "syllabus_prelim.html#academic-integrity",
    "title": "Preliminary Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus_prelim.html#artificial-intelligence-ai-use",
    "href": "syllabus_prelim.html#artificial-intelligence-ai-use",
    "title": "Preliminary Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nLearning to use AI tools is an emerging skill that we will explore together in this course. I expect you to use AI (ChatGPT, Google Bard)—in fact, some assignments may require it.\nHowever, you should be aware of the limits of AI:\n\nAI is a tool, but one that you need to acknowledge using. Any ideas, language, or code that is produced by AI must be cited, just like any other resource. [sample suggestion: Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you used to get the results.] Failure to do so is in violation of the academic integrity policy at Macalester College.\nDon’t trust anything AI says. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you understand.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nHow to cite usage of AI: Please copy and paste all prompts and output into an Appendix section accompanying each problem of an assignment.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "tech_setup.html",
    "href": "tech_setup.html",
    "title": "Tech Setup",
    "section": "",
    "text": "Ideally before class on Tuesday, September 5 and definitely before class on Thursday, September 7, you should follow these instructions to set up the software that we’ll be using throughout the semester. Even if you’ve already downloaded both R and RStudio, you’ll want to re-download to make sure that you have the most current versions.\n\nRequired: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\nRequired: (Re)Download R and RStudio\n\nFIRST: Download R here.\n\nIn the top section, tou will see three links “Download R for …”\nChoose the link that corresponds to your computer.\nAs of September 1, 2023, the latest version of R is 4.3.1 (“Beagle Scouts”).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\nAs of September 1, 2023, the latest version of RStudio is 2023.06.2+561.\n\nTHIRD: Check that when you go to File &gt; New Project &gt; New Directory, you see “Quarto Website” as an option.\n\n\nSuggested: Watch this video describing key configuration options for RStudio.\n\nRequired: Install required packages.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\"))\n\n\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(tidyverse) and hit Enter.\nIf you see an error message, then there was a problem installing the package. Post the full error message in the #questions channel in our Slack workspace and\nQuit RStudio. You’re done setting up!\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio."
  },
  {
    "objectID": "workflow_files_rstudio.html",
    "href": "workflow_files_rstudio.html",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\n\n\nWhen working on any data science project, I recommend setting up the directory (folder) structure below. Sub-bullets indicate folders that are inside other folders.\n\nDocuments (This should be some place you can find easily through your Finder (Mac) or File Explorer (Windows).)\n\ndescriptive_project_name\n\ncode\n\nraw: For messy code that you’re actively working on\nclean: For code that you have cleaned up, documented, organized, and tested to run as expected\n\ndata\n\nraw: Original data that hasn’t been cleaned\nclean: Any non-original data that has been processed in some way\n\nresults\n\nfigures: Plots that will be used in communicating your project should go here. (Using screenshots of output in RStudio is not a good practice.)\ntables: Any sort of plain text file results (e.g., CSVs)\n\n\n\n\nFrom this point onward, we will use a simplified version of this directory structure for all of our class activities.\n\n\nCreate a folder for this course in a place you can find easily through your Finder (Mac) or File Explorer (Windows). The name of this folder should not have spaces (use underscores _ instead). Suggestion: STAT212 or COMP212\nOrganize your files from class using the following directory structure:\n\nSTAT212 (or COMP212)\n\nadvanced_ggplot (For our Advanced visualization in ggplot2 activity)\n\ncode\n\n02-adv-ggplot.qmd\n\ndata\n\nadvanced_maps (For our Advanced map visualization activity)\n\ncode\n\n03-adv-maps.qmd\n\ndata\n\napportionment.csv\nshp_loc_pop_centers (From shp_loc_pop_centers.zip)\nshp_water_lakes_rivers (From shp_water_lakes_rivers.zip)\nus_states_hexgrid.geojson\n\n\n\n\n\n\n\nIn a code file, when you read in data from a source on your computer, you need to specify the file path correctly. The file path is a text string that tells you how to get from your code file to the data. There are two types of paths: absolute and relative.\nAbsolute file paths start at the “root” directory in a computer system. Examples:\n\nMac: /Users/lesliemyint/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nOn a Mac the tilde ~ in a file path refers to the “Home” directory, which is /Users/lesliemyint. In this case, the path becomes ~/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nWindows: C:/Users/lesliemyint/Documents/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nNote: Windows uses both / (forward slash) and \\ (backward slash) to separate folders in a file path.\n\n\n\nRelative file paths start wherever you are right now (the working directory (WD)). The WD when you’re working in a code file may be different from the working directory in the Console.\nDirectory setup 1: Data is in same folder as code file\n\nsome_folder\n\nyour_code_file.qmd\ndata.csv\n\n\nThere are two options for the relative path:\n\n./data.csv (The ./ refers to the current working directory.)\ndata.csv\n\nDirectory setup 2: Data is within a subfolder called data\n\nsome_folder\n\nyour_code_file.qmd\ndata\n\ndata.csv\n\n\n\nThe relative path would be data/data.csv. (Note: ./data/data.csv would also work.)\nDirectory setup 3: Need to go to a “parent” folder first to get to the data\n\nsome_folder\n\ndata.csv\ncode\n\nyour_code_file.qmd\n\n\n\nTo go “up” a folder in a relative path we use ../.\nThe relative path here would be ../data.csv.\n\n\n\nIn 03-adv-maps.qmd, navigate to the code chunk where you read in us_states_hexgrid.geojson, apportionment.csv, shp_loc_pop_centers, and shp_water_lakes_rivers.\nUpdate the file paths to correctly find the data in the new directory structure."
  },
  {
    "objectID": "workflow_files_rstudio.html#change-the-default-file-download-location-for-your-internet-browser",
    "href": "workflow_files_rstudio.html#change-the-default-file-download-location-for-your-internet-browser",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers."
  },
  {
    "objectID": "workflow_files_rstudio.html#folderdirectory-structure",
    "href": "workflow_files_rstudio.html#folderdirectory-structure",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "When working on any data science project, I recommend setting up the directory (folder) structure below. Sub-bullets indicate folders that are inside other folders.\n\nDocuments (This should be some place you can find easily through your Finder (Mac) or File Explorer (Windows).)\n\ndescriptive_project_name\n\ncode\n\nraw: For messy code that you’re actively working on\nclean: For code that you have cleaned up, documented, organized, and tested to run as expected\n\ndata\n\nraw: Original data that hasn’t been cleaned\nclean: Any non-original data that has been processed in some way\n\nresults\n\nfigures: Plots that will be used in communicating your project should go here. (Using screenshots of output in RStudio is not a good practice.)\ntables: Any sort of plain text file results (e.g., CSVs)\n\n\n\n\nFrom this point onward, we will use a simplified version of this directory structure for all of our class activities.\n\n\nCreate a folder for this course in a place you can find easily through your Finder (Mac) or File Explorer (Windows). The name of this folder should not have spaces (use underscores _ instead). Suggestion: STAT212 or COMP212\nOrganize your files from class using the following directory structure:\n\nSTAT212 (or COMP212)\n\nadvanced_ggplot (For our Advanced visualization in ggplot2 activity)\n\ncode\n\n02-adv-ggplot.qmd\n\ndata\n\nadvanced_maps (For our Advanced map visualization activity)\n\ncode\n\n03-adv-maps.qmd\n\ndata\n\napportionment.csv\nshp_loc_pop_centers (From shp_loc_pop_centers.zip)\nshp_water_lakes_rivers (From shp_water_lakes_rivers.zip)\nus_states_hexgrid.geojson\n\n\n\n\n\n\n\nIn a code file, when you read in data from a source on your computer, you need to specify the file path correctly. The file path is a text string that tells you how to get from your code file to the data. There are two types of paths: absolute and relative.\nAbsolute file paths start at the “root” directory in a computer system. Examples:\n\nMac: /Users/lesliemyint/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nOn a Mac the tilde ~ in a file path refers to the “Home” directory, which is /Users/lesliemyint. In this case, the path becomes ~/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nWindows: C:/Users/lesliemyint/Documents/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nNote: Windows uses both / (forward slash) and \\ (backward slash) to separate folders in a file path.\n\n\n\nRelative file paths start wherever you are right now (the working directory (WD)). The WD when you’re working in a code file may be different from the working directory in the Console.\nDirectory setup 1: Data is in same folder as code file\n\nsome_folder\n\nyour_code_file.qmd\ndata.csv\n\n\nThere are two options for the relative path:\n\n./data.csv (The ./ refers to the current working directory.)\ndata.csv\n\nDirectory setup 2: Data is within a subfolder called data\n\nsome_folder\n\nyour_code_file.qmd\ndata\n\ndata.csv\n\n\n\nThe relative path would be data/data.csv. (Note: ./data/data.csv would also work.)\nDirectory setup 3: Need to go to a “parent” folder first to get to the data\n\nsome_folder\n\ndata.csv\ncode\n\nyour_code_file.qmd\n\n\n\nTo go “up” a folder in a relative path we use ../.\nThe relative path here would be ../data.csv.\n\n\n\nIn 03-adv-maps.qmd, navigate to the code chunk where you read in us_states_hexgrid.geojson, apportionment.csv, shp_loc_pop_centers, and shp_water_lakes_rivers.\nUpdate the file paths to correctly find the data in the new directory structure."
  },
  {
    "objectID": "workflow_files_rstudio.html#in-rstudio",
    "href": "workflow_files_rstudio.html#in-rstudio",
    "title": "Workflow: Files and RStudio setup",
    "section": "In RStudio",
    "text": "In RStudio\n\nWhen you’re in the Console, hitting the up and down arrow keys allows you to cycle through previous commands\nTab completion\n\nType part of a function or object name (in the Editor or Console) and then hit Tab. A menu of autocomplete options will popup. Select your choice with arrow keys and hit Tab or Enter. (e.g., Type ggp and hit Tab.)\nType part of a function argument and then hit Tab for a menu of autocomplete options."
  },
  {
    "objectID": "workflow_files_rstudio.html#in-general-for-typing",
    "href": "workflow_files_rstudio.html#in-general-for-typing",
    "title": "Workflow: Files and RStudio setup",
    "section": "In general for typing",
    "text": "In general for typing\n\nMoving your cursor to the beginning/end of a word\n\nMac: Option + Left/Right\nWindows: Ctrl + Left/Right\n\nDeleting one word at a time\n\nMac: Option + Backspace\nWindows: Ctrl + Backspace\n\nMoving your cursor to the beginning/end of a line\n\nMac: Command + Left/Right\nWindows: Alt + Left/Right\n\nDeleting a whole line at a time\n\nMac: Command + Backspace\nWindows: Alt + Backspace"
  }
]