[
  {
    "objectID": "01-introductions.html",
    "href": "01-introductions.html",
    "title": "Welcome to the course!",
    "section": "",
    "text": "Welcome to Intermediate Data Science! I’m thrilled to be your partners in journeying this brand new (!) course in MSCS.\nOur goals for today are as follows:\n\nWhat is this course about?\nGet to know your classmates\nShaping our syllabus together\nCreate your personal website!\n\nWebsite content building + connecting with classmates\n\n\nWe’ll primarily be using slides today–following along here."
  },
  {
    "objectID": "02-adv-ggplot.html",
    "href": "02-adv-ggplot.html",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nNavigate the ggplot2 reference page to find the functions needed to create a desired visualization\nUse the information on a function help page to construct desired plot features\n\nScan the information in the Usage section to identify function arguments that must be set\nUnderstand how the function arguments work by using information in the Arguments section\nUse the information in the the Aesthetics and Examples sections to control plot appearance\n\nIdentify when it would be necessary to use different data arguments within the ggplot() and geom_() layers\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)"
  },
  {
    "objectID": "02-adv-ggplot.html#pair-programming-background",
    "href": "02-adv-ggplot.html#pair-programming-background",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "Pair programming background",
    "text": "Pair programming background\nIn pair programming, two individuals use one computer and work together to solve the problem at hand. Each individual takes turns in one of two roles:\n\nDriver: The Driver is at the computer typing and speaking their thought process out loud.\nNavigator: The Navigator reviews all code that the Driver writes as it’s typed, guides the overall direction of the code (keeps the instructions in mind), and pulls up references.\n\nWhy are we using pair programming? Pair programming is used effectively in industry to speed up individual employee’s learning of a company’s codebase and reduce time wasted on fixing bugs."
  },
  {
    "objectID": "02-adv-ggplot.html#your-task",
    "href": "02-adv-ggplot.html#your-task",
    "title": "Advanced Data Visualization in ggplot2",
    "section": "Your task",
    "text": "Your task\nBefore diving in to plot creation, get to know your partner by telling each other about the general themes in your 12 favorite problems (FPs). Try to find some overlap in your themes and share one of your FPs that relates to that overlapping theme.\nWork together until your precipitation plot looks as below.\n\nThe culmPrec variable contains cumulative precipitation for the month up to the given day.\nThe recordP variable is a TRUE/FALSE indicator of whether a day was a precipitation record. These are marked by the downward pointing triangles.\nThe numbers on the plot indicate the total precipitation for the month. Do some searching about the hjust and vjust options to adjust the alignment of the numbers.\nThe blue and tan colors are \"#32a3d8\" and \"#ebeae2\".\n\n\n\n\n\n\n\n\n\n\nWhen should the Driver and Navigator switch roles? For this exercise, you will switch roles once a particular plot layer (one geom) has been implemented correctly. You can send code back and forth via email or a direct message on Slack.\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nAs you pair program, be aware of your comforts and discomforts in the roles of driver and navigator. Pay attention to the comforts and discomforts of your partner. What could you do to support them in becoming more comfortable and confident in both roles?\n\n\n\n\n\n\n\n\n\nRecord Errors\n\n\n\n\n\nEvery time you run into a new error, record the error message and your process for fixing the error in the “Error Log” section of the Quarto file for these exercises."
  },
  {
    "objectID": "03-adv-maps.html",
    "href": "03-adv-maps.html",
    "title": "Advanced Spatial Visualizations",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nUnderstand the basics of a CRS (coordinate reference system)\nUnderstand and recognize different spatial file types and data types in R\nImplement some of the basic plotting with the sf package\nUnderstand foundational ideas in working with spatial data (aggregating spatial point data to a spatial region, joining spatial data sets)\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)\n\nYou can download a template Quarto file to start from here. Put this file in an activities folder within a folder for this course."
  },
  {
    "objectID": "03-adv-maps.html#ellipsoid",
    "href": "03-adv-maps.html#ellipsoid",
    "title": "Advanced Spatial Visualizations",
    "section": "Ellipsoid",
    "text": "Ellipsoid\nWhile you might have learned that the Earth is a sphere, it is actually closer to an ellipsoid with a bulge at the equator. Additionally, the surface is irregular and not smooth. To define a CRS, we first need to choose a mathematical model represent a smooth approximation to the shape of the Earth. The common ellipsoid models are known as WGS84 and GRS80. See the illustration below of one ellipsoid model (shown in black) as compared to Earth’s true irregular surface (shown in red).\n\n\n\nIllustration of ellipsoid model and Earth’s irregular surface, centered to have an overall best fit. Source: www.icsm.gov.au"
  },
  {
    "objectID": "03-adv-maps.html#datum",
    "href": "03-adv-maps.html#datum",
    "title": "Advanced Spatial Visualizations",
    "section": "Datum",
    "text": "Datum\nEach ellipsoid model has different ways to position it self relative to Earth depending on the center or origin. Each potential position and reference frame for representing the position of locations on Earth is called a datum.\nFor example, two different datum for the same ellipsoid model can provide a more accurate fit or approximation of the Earth’s surface depending on the region of interest (South America v. North America). For example, the NAD83 datum is a good fit for the GRS80 ellipsoid in North America, but SIRGAS2000 is a better fit for the GRS80 ellipsoid in South America. The illustration below shows one datum in which the center of the ellipsoid does not coincide with the center of Earth’s mass. With this position of the ellipsoid, we gain a better fit for the southern half of the Earth.\n\n\n\nIllustration of ellipsoid model and Earth’s irregular surface for a datum that better fits southern part (bottom right) of the Earth. Source: www.icsm.gov.au\n\n\nIt is useful to know that the Global Positioning System (GPS) uses the WGS84 ellipsoid model and a datum by the same name, which provides an overall best fit of the Earth.\nIf you have longitude and latitude coordinates for a location, it is important to know what datum and ellipsoid were used to define those positions.\nNote: In practice, the horizontal distance between WGS84 and NAD83 coordinates is about 3-4 feet in the US, which may not be significant for most applications.\n\nExercise 1\nGo to https://epsg.io/. Search for a location important to you (state, country, etc.). Filter based on Datum (Geodetic) on the right. Click on one geodetic datum option for your region of interest. Make sure your location is listed under the “Area of use” attribute.\nProvide the region of interest (e.g. United States), the full datum name (e.g. North American Datum 1983), the shorthand name (e.g. NAD83, EPSG: 6269), and the ellipsoid (e.g. GRS 1980).\n\nLocation:\n\n\n\nExample Solution\n\n\nLocation 1: South Africa, Cape, EPSG:6222, Ellipsoid: Clarke 1880 (Arc)\n\n\nLocation 2: Thailand, Indian 1975, EPSG:6240, Ellipsoid: Everest 1830 (1937 Adjustment)\n\n\nLocation 3: Colombia, Marco Geocentrico Nacional de Referencia, EPSG:6686, Ellipsoid: GRS 1980\n\n\n\n\nExercise 2\nLet’s now practice specifying coordinates in a CRS.\nFor geographic coordinate reference systems, the coordinates of locations are specified by latitude (degrees, minutes, and seconds north or south of the equator), longitude (degrees, minutes, and seconds west or east of a prime meridian), and sometimes height.\nUse the “Get position on a map” feature of https://epsg.io/ to locate the Olin-Rice Science Center at Macalester. The two boxes at the top allow you to specify a longitude (left box) and latitude (right box) in degrees. Enter the following to focus OLRI:\n\nLongitude: -93.168855\nLatitude: 44.936611\n\nFor projected coordinate reference systems, the coordinates of locations are typically specified by easting (x) and northing (y).\nClick the “Transform” button at the top to find the location of OLRI in northing and easting coordinates (in meters) for the CRS EPSG:26993.\n\nEasting:\nNorthing:\n\n\n\nSolution\n\n\nEasting: 865601.0163401571\nNorthing: 315516.10931633075"
  },
  {
    "objectID": "03-adv-maps.html#projection",
    "href": "03-adv-maps.html#projection",
    "title": "Advanced Spatial Visualizations",
    "section": "Projection",
    "text": "Projection\nLastly, the Earth lives in a 3 dimensional (3D) world and most visualizations are on a 2 dimensional (2D) surface. We must choose a projection method to represent points, regions, and lines on Earth on a 2D map with distance units (typically meter, international foot, US survey foot). In that projection process, a 3D element will lose angle, area, and/or distance when projected onto a 2D surface, no matter which method is chosen.\nFor a good overview of common projection methods, see https://pubs.usgs.gov/gip/70047422/report.pdf.\nOne of the most commonly used projection is the Mercator projection which is a cylindrical map projection from the 1500’s. It became popular for navigation because it represented north as up and south as down everywhere and preserves local directions and shape. However, it inflates the size of regions far from the equator. Thus, Greenland, Antarctica, Canada, and Russia appear large relative to their actual land mass as compared to Central Africa. See the illustration below to compare the area/shape of the countries with the Mercator projection of the world (light blue) with the true areas/shapes (dark blue).\n\n\n\nSource: @neilrkaye\n\n\nBelow you can see four different world projections. Take note of what is lost in terms of angle, area, or distance in these projections.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n# Basic Map w/ labels\nggplot(data = world) + \n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    labs(x = \"Longitude\", y = \"Latitude\", title = \"World Map - Mercator Projection\", subtitle = paste0(\"(\", length(unique(world$name)), \" countries)\")) +\n    theme_bw() \n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +units=m +no_defs\") + \n    labs(title = \"Lambert Azimuthal Equal-Area Projection\", subtitle = \"Correctly represents area but not angles\") + \n    theme_bw()\n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=fouc\") + \n    labs(title = \"Foucaut Projection\", subtitle = \"Correctly represents area, lots of shape distortion in high latitudes\") + \n    theme_bw() \n\n\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"+proj=natearth2\") + \n    labs(title = \"Natural Earth II Projection\", subtitle = \"Represents globe shape, distorted at high latitudes\") + \n    theme_bw()\n\n\n\n\n\nExercise 3\nCreate a world map with a different projection (beyond the four above). Go to https://proj.org/en/9.2/operations/projections/index.html and find another projection. Look for the proj-string and copy that to the crs = argument in coord_sf().\n\nggplot(data = world) +\n    geom_sf(color = \"black\", fill = \"#bada55\") +\n    coord_sf(crs = \"??\") + \n    labs(title = \"?? Projection\", subtitle = \"??\") + \n  theme_bw() \n\nWhat is interesting, surprising, or different to you about the map of the Earth based on this projection?\n\nANSWER:\n\nTalk with a neighbor about the projection they tried. What projection did they use and how is it different from the one you chose?\n\nANSWER:\n\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nIf coordinate reference systems are new to you, how do you feel about all of this new information? What are the most important points to take away? What are the documents and sites you can refer back to when you need more details?\nWhen you learn about a new area of study, it can feel overwhelming. Pick out the 3-5 priority ideas to help you organize all of the details."
  },
  {
    "objectID": "03-adv-maps.html#data-models",
    "href": "03-adv-maps.html#data-models",
    "title": "Advanced Spatial Visualizations",
    "section": "Data Models",
    "text": "Data Models\n\nVector\nVector data represents the world as a set of spatial geometries that are defined in terms of location coordinates (with a specified CRS) with non-spatial attributes or properties.\nThe three basic vector geometries are\n\nPoints: Locations defined based on a (x, y) coordinates.\nLines: A set of ordered points connected by straight lines.\nPolygons: A set of ordered points connected by straight lines, first and last point are the same.\n\nFor example, city locations can be represented with points, roads and rivers can be represented by lines, and geo-political boundaries and lakes can be represented by polygons.\nHundreds of file formats exist to store spatial vector data. A text file (such as .csv) can store the coordinates in two columns (x,y) in addition to a group id (needed for lines and polygons) plus attributes or properties in additional columns. Note that text files do not store the CRS. However, shapefiles (.shp) developed by ESRI is one of the most widely supported spatial vector file format (that includes the CRS). Additionally, GeoJSON (.geojson) and KML (.kml) are additional popular formats.\n\n\nExercise 4\nTo create maps, we’ll need to have access to some spatial data.\nGo to the following websites and download the vector data files indicated. Put all of the downloaded files/folders in same folder as this Rmd file.\n\nURL: https://team.carto.com/u/andrew/tables/andrew.us_states_hexgrid/public/map\n\nDownload File Type: GeoJSON\nName of File: us_states_hexgrid.geojson\n\nURL: https://www2.census.gov/programs-surveys/decennial/2020/data/apportionment/apportionment.csv\n\nDownload File Type: csv\nName of File: apportionment.csv\n\nURL: https://gisdata.mn.gov/dataset/loc-pop-centers\n\nDownload File Type: shapefile (.shp)\nName of File: shp_loc_pop_centers.zip (unzip this file to get a folder with the name shp_loc_pop_centers)\n\nURL: https://gisdata.mn.gov/dataset/us-mn-state-metc-water-lakes-rivers\n\nDownload File Type: shapefile (.shp)\nName of File: shp_water_lakes_rivers.zip (unzip this file to get a folder with the name shp_water_lakes_rivers)\n\n\n\n\nRaster\nRaster data represents the world using a continuous grid of cells where each cell has a single value. These values could be continuous (e.g., elevation, precipitation) or categorical (e.g., land cover type, soil type).\nTypically regular cells are square in shape but they can be rotated and sheared. Rectilinear and curvilinear shapes are also possible, depending on the spatial region of interest and CRS.\n\n\n\nDifference between vector and raster formats. Source: gis.stackexchange.com\n\n\nBe aware that high resolution raster data involves a large number of small cells. This can slow down the computations and visualizations.\nMany raster file formats exist. One of the most popular is GeoTIFF (.tif or .tiff). More complex raster formats include NetCDF (.nc) and HDF (.hdf). To work with raster data in R, you’ll use the raster, terra, and the stars packages. If you are interested in learning more, check out https://r-spatial.github.io/stars/."
  },
  {
    "objectID": "03-adv-maps.html#working-with-spatial-data-in-r",
    "href": "03-adv-maps.html#working-with-spatial-data-in-r",
    "title": "Advanced Spatial Visualizations",
    "section": "Working with Spatial Data in R",
    "text": "Working with Spatial Data in R\n\nRead data into R\nFor each file format, we need to use a different function to read in the data. See the examples below for reading in GeoJSON, CSV, and shapefiles.\n\n# Read in GeoJSON file\nhex_spatial &lt;- geojsonio::geojson_read(\"data/us_states_hexgrid.geojson\", what = \"sp\") \n\n# Read in CSV File\npop_growth &lt;- readr::read_csv(\"data/apportionment.csv\") %&gt;% janitor::clean_names()\n\n# Read in Shapefiles\nmn_cities &lt;- sf::read_sf(\"data/shp_loc_pop_centers\") #shp file/folder\nmn_water &lt;- sf::read_sf(\"data/shp_water_lakes_rivers\") #shp file/folder\n\n\n\nData classes in R\nWhen data is read in, an R data object is created of a default class. Notice the classes of the R objects we read in. Also, notice that an object may have multiple classes, which indicate the type of structure it has and how functions may interact with the object.\n\nclass(hex_spatial)\n\n[1] \"SpatialPolygonsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\nclass(pop_growth)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\nclass(mn_cities)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(mn_water)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nOlder R Spatial classes\nIn the sp package, there are many spatial classes that hold slightly different data. All Spatial* classes have a bounding box (bbox) and a CRS.\n\nSpatialPoints, SpatialLines, and SpatialPolygons provide structure to hold the basic spatial geometries of points, lines, and polygons.\nSpatial*DataFrame extends the geometry classes to a data.frame-like object with non-spatial attribute data.\n\n\n\nExercise 5\nWe can look at the first bit of the hex_spatial object to get a sense for how information in the object is organized:\n\nhead(hex_spatial,1)\n\nAn object of class \"SpatialPolygonsDataFrame\"\nSlot \"data\":\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n            google_name\n1 Maine (United States)\n\nSlot \"polygons\":\n[[1]]\nAn object of class \"Polygons\"\nSlot \"Polygons\":\n[[1]]\nAn object of class \"Polygon\"\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"area\":\n[1] 15.28454\n\nSlot \"hole\":\n[1] FALSE\n\nSlot \"ringDir\":\n[1] 1\n\nSlot \"coords\":\n          [,1]     [,2]\n[1,] -72.62574 55.31320\n[2,] -69.90286 54.40843\n[3,] -69.90286 52.53744\n[4,] -72.62574 51.57081\n[5,] -75.34861 52.53744\n[6,] -75.34861 54.40843\n[7,] -72.62574 55.31320\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"ID\":\n[1] \"1\"\n\nSlot \"area\":\n[1] 15.28454\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"bbox\":\n        min       max\nx -75.34861 -69.90286\ny  51.57081  55.31320\n\nSlot \"proj4string\":\nCoordinate Reference System:\nDeprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs \nWKT2 2019 representation:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]] \n\n\nBased on this information, fill in the following:\n\nCRS:\nBBOX (extent):\nGeometry type:\n\n\n\nSolution\n\n\nCRS: EPSG:4326 (+proj=longlat +datum=WGS84 +no_defs) (From Slot \"proj4string\": Coordinate Reference System:)\nBBOX: x -75.34861 -69.90; y 51.57 55.31 (From Slot \"bbox\")\nGeometry type: Polygons (Inferred from An object of class \"SpatialPolygonsDataFrame\" and class \"Polygon\")\n\n\nNewer R Spatial classes\nThe community is moving away from using older sp classes to sf classes. It is useful for you to know that the older versions exist, but we will stick with the sf classes.\n\nsfc objects are modern, general versions of the spatial geometries from the sp package with a bbox, CRS, and many geometries available.\nsf objects are data.frame-like objects with a geometry column of class sfc.\n\n\nmn_cities\n\nSimple feature collection with 1081 features and 8 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nProjected CRS: NAD83 / UTM zone 15N\n# A tibble: 1,081 × 9\n      GNIS Name        CTU_Type County      FIPS_Code Sym_Class Population Notes\n     &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;\n 1 2393879 Ada         City     Norman Cou… 27107001… County S…       1681 &lt;NA&gt; \n 2 2393881 Adams       City     Mower Coun… 27099001… Small Ci…        742 &lt;NA&gt; \n 3 2393884 Adrian      City     Nobles Cou… 27105002… Small Ci…       1278 &lt;NA&gt; \n 4 2393887 Afton       City     Washington… 27163003… Small Ci…       2932 &lt;NA&gt; \n 5 2393894 Aitkin      City     Aitkin Cou… 27001004… County S…       2279 &lt;NA&gt; \n 6 2393895 Akeley      City     Hubbard Co… 27057004… Small Ci…        397 &lt;NA&gt; \n 7 2393898 Albany      City     Stearns Co… 27145006… Small Ci…       2618 &lt;NA&gt; \n 8 2393902 Albert Lea  City     Freeborn C… 27047006… County S…      17843 &lt;NA&gt; \n 9 2393903 Alberta     City     Stevens Co… 27149006… Small Ci…        122 &lt;NA&gt; \n10 2393904 Albertville City     Wright Cou… 27171007… Small Ci…       7226 &lt;NA&gt; \n# ℹ 1,071 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\n\n\nExercise 6\nBased on the summary of mn_cities, what are the following:\n\nCRS:\nBBOX:\nGeometry type:\n\n\n\nSolution\n\n\nCRS: NAD83 / UTM zone 15N\nBBOX: xmin: 190832.6 ymin: 4816672 xmax: 747463.4 ymax: 5468045\nGeometry type: Points\n\n\nPutting spatial data into a data.frame with fortify()\nThe data.frame and tbl (tibble) classes are standard data formats that are not specific to spatial data but are really nice for working with because of tidyverse. Our pop_growth data doesn’t include any coordinate information, so it can be stored simply as a data.frame (tbl, tbl_df, and spec_tbl_df are all subclasses of data.frame).\nYou may come across data.frames that contain spatial coordinate information, so let’s see what that might look like. We can fortify() our sp object (hex_spatial) to make it a data frame.\n\n# Convert Spatial*DataFrame to Data Frame\nhex_spatial_df &lt;- fortify(hex_spatial)\nclass(hex_spatial_df)\n\n[1] \"data.frame\"\n\n\n\n\nExercise 7\nWhenever we come across a new function (fortify), it is helpful to explore the structure of information contained within the object that it creates.\nWhat are the variables in hex_spatial_df? Compare the first seven rows with the first spatial polygon of hex_spatial. Using this comparison describe the meaning of the variables in hex_spatial_df. (piece, id, and group are trickier. We’ll talk about this together.)\n\n# Display the first 7 rows of hex_spatial_df\nhead(hex_spatial_df,7)\n\n       long      lat order  hole piece id group\n1 -72.62574 55.31320     1 FALSE     1  1   1.1\n2 -69.90286 54.40843     2 FALSE     1  1   1.1\n3 -69.90286 52.53744     3 FALSE     1  1   1.1\n4 -72.62574 51.57081     4 FALSE     1  1   1.1\n5 -75.34861 52.53744     5 FALSE     1  1   1.1\n6 -75.34861 54.40843     6 FALSE     1  1   1.1\n7 -72.62574 55.31320     7 FALSE     1  1   1.1\n\n# Look at the first polygon in the hex_spatial object (Maine)\nhex_spatial@polygons[[1]]\n\nAn object of class \"Polygons\"\nSlot \"Polygons\":\n[[1]]\nAn object of class \"Polygon\"\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"area\":\n[1] 15.28454\n\nSlot \"hole\":\n[1] FALSE\n\nSlot \"ringDir\":\n[1] 1\n\nSlot \"coords\":\n          [,1]     [,2]\n[1,] -72.62574 55.31320\n[2,] -69.90286 54.40843\n[3,] -69.90286 52.53744\n[4,] -72.62574 51.57081\n[5,] -75.34861 52.53744\n[6,] -75.34861 54.40843\n[7,] -72.62574 55.31320\n\n\n\nSlot \"plotOrder\":\n[1] 1\n\nSlot \"labpt\":\n[1] -72.62574  53.45575\n\nSlot \"ID\":\n[1] \"1\"\n\nSlot \"area\":\n[1] 15.28454\n\n\n\nANSWER:\n\n\n\nSolution\n\n\nVariables: long, lat, order, hole, piece, id, group\n\n\nlong and lat provide the x and y coordinates of the polygon for a particlar region or area id.\n\n\nThe order is the order in which you connect the coordinate points to make a polygon.\n\n\nhole indicates whether or not it should be included or excluded in the region as a hole.\n\n\npiece indicates the number of the polygon for an individual area\n\n\nid is a unique identifier for each polygon and allows linking to the original spatial object (hex_spatial). (There is a Slot \"ID\" part of the object.)\n\n\ngroup indicates which pieces belong to the same group or should be plotted together as a single entity. This can be useful when you want to apply different aesthetics (e.g., colors, linetypes) to different groups of polygons within your spatial object. It helps in specifying how to group and style the different pieces when creating plots.\n\n\n\n\nConverting between data classes\nSometimes functions for working with spatial data will only work on an object that is of a particular class (e.g., only works on sf objects). If we have an object of a different class, we need to know how to convert it to the right class.\nWe can convert objects between these data classes with the following functions:\n\nfortify(x): sp object x to data.frame\nst_as_sf(x): sp object x to sf\nst_as_sf(x, coords = c(\"long\", \"lat\")): data.frame x to sf as points\nTo convert a data.frame with columns of long, lat, and group containing polygon geometry information, you can use:\n\n\nst_as_sf(x, coords = c(\"long\", \"lat\")) %&gt;%\n    group_by(group) %&gt;%\n    summarise(geometry = st_combine(geometry)) %&gt;%\n    st_cast(\"POLYGON\")\n\n(Note: We won’t often want to convert our data to a Spatial* class from sp package, so we’ll exclude that in this activity.)\n\n\nExercise 8\nConvert the hex_spatial data to an sf object called hex_spatial_sf. Complete these two ways\n\nhex_spatial directly to hex_spatial_sf AND\nhex_spatial_df to hex_spatial_sf.\n\n\n# Convert to SF from hex_spatial_df  \nhex_spatial_sf &lt;- hex_spatial_df %&gt;% ???  \n  \n# Convert to SF from hex_spatial\nhex_spatial_sf &lt;- hex_spatial %&gt;% ???\n\n\n\nSolution\n\n\n# Convert to SF from hex_spatial_df  \nhex_spatial_sf &lt;- hex_spatial_df %&gt;%\n    st_as_sf(coords = c(\"long\", \"lat\")) %&gt;%\n    group_by(group) %&gt;%\n    summarise(geometry = st_combine(geometry)) %&gt;%\n    st_cast(\"POLYGON\") \n  \n# Convert to SF from hex_spatial\nhex_spatial_sf &lt;- hex_spatial %&gt;% st_as_sf()\n\n\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWe’ve now talked about CRSs and how spatial data is stored in R. Thinking on the lesson so far as a whole…\n\nWhat’s making sense? What’s not?\nWhat would help connect everything we’ve talked about?\n\nRecord observations in your Process and Reflection Log.\nShare your observations with your partner. Together try to figure out what themes emerge in what you’re still working on. Then try to come up with strategies that can help you move forward.\nExample themes: What is the “why” behind this? What is the full picture/pipeline/how this is used in practice?\nExample strategies: writing condensed summaries, drawing concept maps"
  },
  {
    "objectID": "03-adv-maps.html#hexbin-choropleth",
    "href": "03-adv-maps.html#hexbin-choropleth",
    "title": "Advanced Spatial Visualizations",
    "section": "Hexbin Choropleth",
    "text": "Hexbin Choropleth\nData Source: https://r-graph-gallery.com/328-hexbin-map-of-the-usa.html\nIn this example, we’ll create an alternative choropleth map. Instead of using the actual geo-political boundaries, we will use hexagons to represent the U.S. states and maintain their relative directional position to each together. This approach results in each state having the same area in the graphic so that large regions don’t dominate the visual story.\n\nExercise 9\nDescribe what the following code chunks are doing. Be sure to consider the class of the data object, what the data object looks like to start, and what it looks like at the end of the chunk.\n\n# Chunk A\nhex_spatial_df  &lt;- hex_spatial_df %&gt;% \n  left_join(\n        data.frame(id = as.character(1:nrow(hex_spatial)) , \n        name = str_replace(hex_spatial$google_name,' \\\\(United States\\\\)',''), \n        abbr = hex_spatial$iso3166_2))\n\n\nANSWER (Chunk A):\n\n\n\nSolution\n\n\n# Chunk A\nhead(hex_spatial_df) # Start with data frame of 357 rows and 7 columns\n\n       long      lat order  hole piece id group\n1 -72.62574 55.31320     1 FALSE     1  1   1.1\n2 -69.90286 54.40843     2 FALSE     1  1   1.1\n3 -69.90286 52.53744     3 FALSE     1  1   1.1\n4 -72.62574 51.57081     4 FALSE     1  1   1.1\n5 -75.34861 52.53744     5 FALSE     1  1   1.1\n6 -75.34861 54.40843     6 FALSE     1  1   1.1\n\nhex_spatial_df  &lt;- hex_spatial_df %&gt;% \n  left_join( # Left join, a mutating join, a dataset with information from hex_spatial\n        data.frame(id = as.character(1:nrow(hex_spatial)) , # Create a data frame with variables id (1,2,3...), name (defined as the google_name from hex_spatial after removing \"(United States)\"), and abbr (the state abbreviation in hex_spatial as variable iso3166_2)\n        name = str_replace(hex_spatial$google_name,' \\\\(United States\\\\)',''), \n        abbr = hex_spatial$iso3166_2))\n\nhead(hex_spatial_df) # End with data frame of 357 rows and 9 columns (new: name and abbr)\n\n       long      lat order  hole piece id group  name abbr\n1 -72.62574 55.31320     1 FALSE     1  1   1.1 Maine   ME\n2 -69.90286 54.40843     2 FALSE     1  1   1.1 Maine   ME\n3 -69.90286 52.53744     3 FALSE     1  1   1.1 Maine   ME\n4 -72.62574 51.57081     4 FALSE     1  1   1.1 Maine   ME\n5 -75.34861 52.53744     5 FALSE     1  1   1.1 Maine   ME\n6 -75.34861 54.40843     6 FALSE     1  1   1.1 Maine   ME\n\n\n\n\n# Chunk B\nhex_spatial_sf &lt;- hex_spatial_sf %&gt;% \n    mutate(\n        name = str_replace(google_name,' \\\\(United States\\\\)',''),\n        abbr = iso3166_2\n    )\n\n\nANSWER (Chunk B):\n\n\n\nSolution\n\n\n# Chunk B\n\nhead(hex_spatial_sf) # Start with sf object with 51 regions and 7 variables/features\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -113.4688 ymin: 30.53798 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1217 2015-05-13 17:24:35 2015-10-05 11:00:16  R.I. 47.8        RI\n3       1218 2015-05-13 17:25:00 2015-10-05 11:00:16   Vt. 33.9        VT\n4        231 2015-05-13 17:02:22 2015-10-05 11:00:16 Okla. 63.4        OK\n5        244 2015-05-13 17:02:22 2015-10-05 11:00:16  N.C. 41.5        NC\n6        259 2015-05-13 17:02:22 2015-10-05 11:00:16   Va. 45.6        VA\n                     google_name                       geometry\n1          Maine (United States) POLYGON ((-72.62574 55.3132...\n2   Rhode Island (United States) POLYGON ((-72.62574 49.5743...\n3        Vermont (United States) POLYGON ((-80.79436 52.5374...\n4       Oklahoma (United States) POLYGON ((-110.746 35.79821...\n5 North Carolina (United States) POLYGON ((-91.68585 39.5301...\n6       Virginia (United States) POLYGON ((-88.96298 43.0717...\n\nhex_spatial_sf &lt;- hex_spatial_sf %&gt;% # Create new variables: name (defined as the google_name after removing \"(United States)\"), and abbr (the state abbreviation from variable iso3166_2)\n    mutate(\n        name = str_replace(google_name,' \\\\(United States\\\\)',''),\n        abbr = iso3166_2\n    )\n\nhead(hex_spatial_sf) # Ends with sf object with 51 regions and 9 variables/features\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -113.4688 ymin: 30.53798 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1217 2015-05-13 17:24:35 2015-10-05 11:00:16  R.I. 47.8        RI\n3       1218 2015-05-13 17:25:00 2015-10-05 11:00:16   Vt. 33.9        VT\n4        231 2015-05-13 17:02:22 2015-10-05 11:00:16 Okla. 63.4        OK\n5        244 2015-05-13 17:02:22 2015-10-05 11:00:16  N.C. 41.5        NC\n6        259 2015-05-13 17:02:22 2015-10-05 11:00:16   Va. 45.6        VA\n                     google_name                       geometry           name\n1          Maine (United States) POLYGON ((-72.62574 55.3132...          Maine\n2   Rhode Island (United States) POLYGON ((-72.62574 49.5743...   Rhode Island\n3        Vermont (United States) POLYGON ((-80.79436 52.5374...        Vermont\n4       Oklahoma (United States) POLYGON ((-110.746 35.79821...       Oklahoma\n5 North Carolina (United States) POLYGON ((-91.68585 39.5301... North Carolina\n6       Virginia (United States) POLYGON ((-88.96298 43.0717...       Virginia\n  abbr\n1   ME\n2   RI\n3   VT\n4   OK\n5   NC\n6   VA\n\n\n\n\n# Chunk C\nhex_growth_df &lt;- left_join(hex_spatial_df, pop_growth, by = 'name')\nhex_growth_sf &lt;- left_join(hex_spatial_sf, pop_growth, by = 'name')\n\n\nANSWER (Chunk C):\n\n\n\nSolution\n\n\n# Chunk C\n\nhex_growth_df &lt;- left_join(hex_spatial_df, pop_growth, by = 'name') # Add in pop_growth variables to data frame using left_join; in the process duplicate the geometry for each region for each year\nhead(hex_growth_df)\n\n       long     lat order  hole piece id group  name abbr geography_type year\n1 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1910\n2 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1920\n3 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1930\n4 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1940\n5 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1950\n6 -72.62574 55.3132     1 FALSE     1  1   1.1 Maine   ME          State 1960\n  resident_population percent_change_in_resident_population\n1              742371                                   6.9\n2              768014                                   3.5\n3              797423                                   3.8\n4              847226                                   6.2\n5              913774                                   7.9\n6              969265                                   6.1\n  resident_population_density resident_population_density_rank\n1                        24.1                               33\n2                        24.9                               34\n3                        25.9                               36\n4                        27.5                               36\n5                        29.6                               37\n6                        31.4                               38\n  number_of_representatives change_in_number_of_representatives\n1                         4                                   0\n2                         4                                   0\n3                         3                                  -1\n4                         3                                   0\n5                         3                                   0\n6                         2                                  -1\n  average_apportionment_population_per_representative\n1                                              185593\n2                                              192004\n3                                              265806\n4                                              282409\n5                                              304591\n6                                              484633\n\ndim(hex_growth_df) # end with data frame of 4284 rows and 18 variables\n\n[1] 4284   18\n\nhex_growth_sf &lt;- left_join(hex_spatial_sf, pop_growth, by = 'name') # add in pop_growth variables to sf object using left join; in the process duplicate the geometry for each region for each year \nhead(hex_growth_sf)\n\nSimple feature collection with 6 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -75.34861 ymin: 51.57081 xmax: -69.90286 ymax: 55.3132\nGeodetic CRS:  WGS 84\n  cartodb_id          created_at          updated_at label bees iso3166_2\n1       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n2       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n3       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n4       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n5       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n6       1219 2015-05-13 17:26:15 2015-10-05 11:00:16 Maine 60.5        ME\n            google_name  name abbr geography_type year resident_population\n1 Maine (United States) Maine   ME          State 1910              742371\n2 Maine (United States) Maine   ME          State 1920              768014\n3 Maine (United States) Maine   ME          State 1930              797423\n4 Maine (United States) Maine   ME          State 1940              847226\n5 Maine (United States) Maine   ME          State 1950              913774\n6 Maine (United States) Maine   ME          State 1960              969265\n  percent_change_in_resident_population resident_population_density\n1                                   6.9                        24.1\n2                                   3.5                        24.9\n3                                   3.8                        25.9\n4                                   6.2                        27.5\n5                                   7.9                        29.6\n6                                   6.1                        31.4\n  resident_population_density_rank number_of_representatives\n1                               33                         4\n2                               34                         4\n3                               36                         3\n4                               36                         3\n5                               37                         3\n6                               38                         2\n  change_in_number_of_representatives\n1                                   0\n2                                   0\n3                                  -1\n4                                   0\n5                                   0\n6                                  -1\n  average_apportionment_population_per_representative\n1                                              185593\n2                                              192004\n3                                              265806\n4                                              282409\n5                                              304591\n6                                              484633\n                        geometry\n1 POLYGON ((-72.62574 55.3132...\n2 POLYGON ((-72.62574 55.3132...\n3 POLYGON ((-72.62574 55.3132...\n4 POLYGON ((-72.62574 55.3132...\n5 POLYGON ((-72.62574 55.3132...\n6 POLYGON ((-72.62574 55.3132...\n\ndim(hex_growth_sf) #end with sf object of 612 region/year combinations and 19 variables\n\n[1] 612  19\n\n\n\n\n# Chunk D\ncenters &lt;- data.frame(\n    rgeos::gCentroid(hex_spatial,byid = TRUE), \n    abbr = hex_spatial$iso3166_2\n)\n  \nhex_growth_df %&gt;% \n    filter(year == 2020) %&gt;%\n    ggplot(aes(x = long, y = lat)) +\n        geom_polygon(aes(group = group, fill = percent_change_in_resident_population)) + \n        geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') +\n        labs(fill = 'Population Change (%)') + \n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right')\n\n\nANSWER (Chunk D):\n\n\n\nSolution\n\n\n# Chunk D\ncenters &lt;- data.frame(\n    rgeos::gCentroid(hex_spatial,byid = TRUE), # Create data frame of the center of each region and the state abbreviation\n    abbr = hex_spatial$iso3166_2\n)\n  \nhex_growth_df %&gt;% \n    filter(year == 2020) %&gt;% # focus only on the data from 2020\n    ggplot(aes(x = long, y = lat)) + # create frame of longitude and latitude\n        geom_polygon(aes(group = group, fill = percent_change_in_resident_population)) +  # add hex polygons defined by x and y but grouped according to group and color filled by the percent_change in resident population\n        geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') + # add text at the centers of the polygons and add text labels from the abbr variable in the centers data we created\n        labs(fill = 'Population Change (%)') +  # change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\n\n\n\n# Chunk E\nhex_growth_sf %&gt;% \n    filter(year == 2020) %&gt;%\n    ggplot() +\n        geom_sf(aes(fill = percent_change_in_resident_population)) + \n        geom_sf_text( aes(label = abbr), color = 'white') +\n        labs(fill = 'Population Change (%)') + \n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right')\n\n\nANSWER (Chunk E):\n\n\n\nSolution\n\n\n# Chunk E\nhex_growth_sf %&gt;%  # start with sf object\n    filter(year == 2020) %&gt;% #filter to focus on data from 2020\n    ggplot() +\n        geom_sf(aes(fill = percent_change_in_resident_population)) + # plot the sf geometry (polygons) and fill color according to percent change in population\n        geom_sf_text( aes(label = abbr), color = 'white') + # add text labels to the sf geometry regions using abbr for the text\n        labs(fill = 'Population Change (%)') + # Change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right \n\n\n\n\n\n\n\nExercise 10\nUsing the hexbin spatial boundaries and the pop_growth data, make the following updates to the choropleth graphic:\n\nChange the outcome variable (different year or variable).\nChange the fill scale to be more meaningful and effective.\nMake one more update beyond the fill color to improve the effectiveness of the graphic.\n\nMake the graphic twice, once with geom_polygon() and once with geom_sf().\n\n\nExample Solution\n\n\nhex_growth_df %&gt;% \n    ggplot(aes(x = long, y = lat)) + # create frame of longitude and latitude\n        geom_polygon(aes(group = group, fill = change_in_number_of_representatives)) +  # add hex polygons defined by x and y but grouped according to group and color by change in number of representatives\n        # geom_text(data = centers, aes( x = x, y = y, label = abbr), color = 'white') + # add text at the centers of the polygons and add text labels from the abbr variable in the centers data we created\n        facet_wrap(~ year, ncol = 3) +\n        labs(fill = 'Population Change (%)') +  # change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\nhex_growth_sf %&gt;%  # start with sf object\n    ggplot() +\n        geom_sf(aes(fill = change_in_number_of_representatives)) + # plot the sf geometry (polygons) and fill color according to change in number of representatives\n        # geom_sf_text( aes(label = abbr), color = 'white') + # add text labels to the sf geometry regions using abbr for the text\n        facet_wrap(~ year, ncol = 3) +\n        labs(fill = 'Population Change (%)') + # Change legend label\n        ggthemes::theme_map() + theme(legend.position = 'bottom', legend.justification = 'right') # remove the background theme and move the legend to the bottom right\n\n\n\n\n\n\n\nBonus Challenge\nFind external state-level data online, read it into R, join it, and create a U.S. state hexbin map displaying that new state-level outcome."
  },
  {
    "objectID": "03-adv-maps.html#mn-citycounty-example",
    "href": "03-adv-maps.html#mn-citycounty-example",
    "title": "Advanced Spatial Visualizations",
    "section": "MN City/County example",
    "text": "MN City/County example\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWhen looking through code examples, notice familiar functions and syntax patterns. Also, notice new functions and try figure out what they are doing.\nAdd comments to the code so that you can come back to the examples when you need them.\n\n\n\n\nUnifying CRSs across different spatial datasets\nTo demonstrate other spatial geometries beyond polygons (the hexagons in the last example were spatial polygons), we’ll walk through create a map of MN with different layers of information (city point locations, county polygon boundaries, rivers as lines and polygons, and a raster elevation map). To add all of this information on one map, we need to ensure that the CRS is the same for all spatial datasets.\n\n# Check CRS\nst_crs(mn_cities)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n# Check CRS\nst_crs(mn_water)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n# (They're both NAD83 / UTM zone 15N but we'll transform anyway)\n\n# Transform CRS of water to the same of the cities\nmn_water &lt;- mn_water %&gt;%\n    st_transform(crs = st_crs(mn_cities))\n\n\n# Load country boundaries data as sf object\nmn_counties &lt;- us_counties(resolution = \"high\", states = \"Minnesota\")\n\n# Remove duplicate column names\nnames_counties &lt;- names(mn_counties)\nnames(mn_counties)[names_counties == 'state_name'] &lt;- c(\"state_name1\", \"state_name2\")\n\n# Check CRS\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n# (They're different!)\n\n# Transform the CRS of county data to the more local CRS of the cities\nmn_counties &lt;- mn_counties %&gt;%\n  st_transform(crs = st_crs(mn_cities))\n\nst_crs(mn_counties)\n\nCoordinate Reference System:\n  User input: NAD83 / UTM zone 15N \n  wkt:\nPROJCRS[\"NAD83 / UTM zone 15N\",\n    BASEGEOGCRS[\"NAD83\",\n        DATUM[\"North American Datum 1983\",\n            ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4269]],\n    CONVERSION[\"UTM zone 15N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",-93,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    ID[\"EPSG\",26915]]\n\n\n\n\nInitial map: counties and cities\n\nggplot() + # plot frame\n    geom_sf(data = mn_counties, fill = NA) + # county boundary layer\n    geom_sf(data = mn_cities, size = 0.5) + # city point layer\n    ggthemes::theme_map()\n\n\n\n\n\nggplot() +\n    geom_sf(data = mn_counties, fill = \"wheat\", color = \"tan\") + \n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population, size = Population), alpha = 0.8)+ #cities layer\n    scale_color_viridis_c() + # continuous (gradient) color scale\n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"bottom\")  #move legend\n\n\n\n\n\n\nUpdated map: counties and cities plus elevation\n\nelevation &lt;- elevatr::get_elev_raster(mn_counties, z = 5, clip = 'bbox')\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to Data Frame for plotting\nelev_df &lt;- elevation %&gt;% terra::as.data.frame(xy = TRUE)\nnames(elev_df) &lt;-c('x','y','value')\n\nggplot() +\n    geom_raster(data = elev_df, aes(x = x,y = y,fill = value)) + # adding the elevation as first (bottom) layer\n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + \n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population,size = Population), alpha = 0.8)+ #cities layer\n    scale_color_viridis_c() + #continuous (gradient) color scale\n    scale_fill_gradient(low = 'darkgreen',high = 'white', guide = FALSE) + \n    labs(title = \"Minnesota Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"bottom\")  #move legend\n\n\n\n\n\n\nUpdated map: zoom in to Twin Cities\n\nseven_countyarea &lt;- st_bbox(mn_counties %&gt;% filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")))\n\n\nelevation &lt;- elevatr::get_elev_raster(mn_counties %&gt;% st_crop(seven_countyarea), z = 9, clip = 'bbox')\nraster::crs(elevation) &lt;- sf::st_crs(mn_counties)\n\n# Convert to data frame for plotting\nelev_df &lt;- elevation %&gt;% terra::as.data.frame(xy = TRUE)\nnames(elev_df) &lt;-c('x','y','value')\n\nggplot() +\n    geom_raster(data = elev_df, aes(x = x,y = y,fill = value)) + \n    geom_sf(data = mn_counties, fill = NA, color = \"black\") + # county boundary layer\n    geom_sf(data = mn_water, fill = 'lightsteelblue1',color = 'lightsteelblue1') + # added a river/lake layer\n    geom_sf(data = mn_cities %&gt;% filter(Population &gt;= 10000), mapping = aes(color = Population,size = Population)) + # cities layer\n    coord_sf(xlim = seven_countyarea[c(1,3)], ylim = seven_countyarea[c(2,4)]) + # crop map to coordinates of seven county area\n    scale_color_viridis_c(option = 'magma') + # continuous (gradient) color scale\n    scale_fill_gradient(low = 'darkgreen',high = 'white') + # continuous (gradient) fill scale\n    labs(title = \"Twin Cities with Population &gt;= 10,000\") + \n    ggthemes::theme_map() + theme(legend.position = \"none\")  # remove legend\n\n\n\n\n\n\nTwin Cities Leaflet\nBelow we show how to make the MN counties map in the leaflet package.\n\nlibrary(leaflet)\n\nmn_counties_leaf &lt;- mn_counties %&gt;% st_transform(4326) # Leaflet expects this CRS for vectors\nmn_cities_leaf &lt;- mn_cities %&gt;% st_transform(4326) # Leaflet expects this CRS for vectors\n\nCities_per_County &lt;- st_join(mn_cities_leaf, mn_counties_leaf) %&gt;%\n  st_drop_geometry() %&gt;% #removes geometry - makes the following calculation more efficient \n  count(name) \n\nmn_counties_leaf %&gt;% \n    filter(name %in% c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\")) %&gt;%\n    left_join(Cities_per_County) %&gt;%\n    leaflet() %&gt;% \n    addProviderTiles(\"CartoDB.Positron\") %&gt;% \n    addPolygons(color = \"#444444\", weight = 1, smoothFactor = 0.5,\n    opacity = 1.0, fillOpacity = 0.5, fillColor = ~colorQuantile(\"YlOrRd\", n)(n), highlightOptions = highlightOptions(color = \"white\", weight = 2,\n      bringToFront = TRUE)) %&gt;%\n    addCircles(data = mn_cities_leaf %&gt;% filter(County %in% paste(c(\"Anoka\", \"Hennepin\", \"Ramsey\", \"Dakota\", \"Carver\", \"Washington\", \"Scott\"),'County')), color = \"#444444\")"
  },
  {
    "objectID": "03-adv-maps.html#open-ended-exercise-homework",
    "href": "03-adv-maps.html#open-ended-exercise-homework",
    "title": "Advanced Spatial Visualizations",
    "section": "Open-ended Exercise (Homework)",
    "text": "Open-ended Exercise (Homework)\nThe following exercises will use census tract tidycensus data for Ramsey and Hennepin county and Crash.csv (2019-2022) from the pedestrian/bike crash database for St. Paul within Ramsey county in the Twin Cities. We provide several variables that you can choose from in order to create maps that best fit your interest.\nLoad the data with the following code:\n\ncensus2020 &lt;- tidycensus::get_acs(year = 2020, state = \"MN\", geography = \"tract\", variables = c(    \n\"B01003_001\", \"B19013_001\", \"B23006_023\", \"B25058_001\", \"B25107_001\", \"B25003_001\", \"B25003_002\", \"B25003_003\", \"B25077_001\"), output = 'wide', geometry = TRUE) %&gt;%\n  filter(word(NAME, 4) %in% c(\"Ramsey\",\"Hennepin\"))%&gt;%\n               mutate(tract = word(NAME, 3),\n                      tract = str_remove(tract, \",\"),\n                      county = word(NAME, 4)) %&gt;%\n               select(-NAME) %&gt;%\n               rename(\"population\" = \"B01003_001E\", \n                      \"medianIncome\" = \"B19013_001E\", \n                      \"bachelors\" = \"B23006_023E\",\n                      \"medContractRent\" = \"B25058_001E\", \n                      \"tenureTotal\" = \"B25003_001E\", \n                      \"tenureOwned\" = \"B25003_002E\", \n                      \"tenureRented\" = \"B25003_003E\",\n                      \"medianHomeValue\"= \"B25077_001E\") %&gt;%\n  select(-contains(\"_\"))\n\ncrashes &lt;- read_csv(\"https://lmyint.github.io/212_fall_2023/data/Crash.csv\") %&gt;%\n    filter(!is.na(Latitude), !is.na(Longitude))\n\n\nExercise: Joining and aggregation\nCreate a map of crashes per census tract in Ramsey county.\nFirst, transform the crashes data frame to a sf object have a point geometry using the code below.\n\ncrashes &lt;- st_as_sf(crashes, coords = c(\"Longitude\", \"Latitude\"), crs = \"NAD83\")\n\nCheck the CRS are the same for census2020 and crashes using st_crs() and transform if needed.\n\n# code here\n\nJoin the crashes and census dataset together and count the number of crashes per census tract. The function st_join can join to spatial data sets according to whether the spatial geometries of the right table intersect with the spatial geometries of the left table.\n\ncrashes_per_tract &lt;- st_join(??,??) %&gt;%\n    st_drop_geometry() %&gt;% # removes geometry - makes the following calculation more efficient \n    filter(!is.na(Accident_Datetime)) %&gt;%\n    count(??) \n\nJoin the census data with crashes_per_tract and then use a filter of n &gt; 0 to only keep the census tracts where crashes were recorded instead of all of Ramsey and Hennepin County.\n\ncrashes_per_tract_geo &lt;- ??? %&gt;% # sf object with census geometry goes first\n    left_join(??, by = ??) %&gt;%\n    filter(n &gt; 0)\n\nCreate the plot!!\n\nggplot() +\n    geom_sf(???) +\n    scale_fill_gradientn(colours = c(\"lightcyan\", \"lightcyan2\", \"lightskyblue3\", \"lightskyblue4\"))+\n    labs(fill = \"Crashes\", color = \"\", title = \"Number of pedestrian/bike crashes per census tract\") +\n    ggthemes::theme_map() + theme(legend.position = \"bottom\")\n\n\n\nExercise: Adding layers\nPlot a variable of your choice for census tracts in Hennepin and Ramsey County and add roads to the map.\nStart by downloading a shape file. For example, you could search for “Minnesota roads shape file”. For this example, visit this site and download the Shapefile Zip File. Unzip the file and put the folder in the same location as this Rmd file.\nLoad in the shapefile using st_read() and transform roads to have the same CRS as census2020 if necessary.\n\nroads &lt;- sf::st_read(\"tl_2019_27_prisecroads\")\n\n# Check CRS of roads and transform if necessary\n\nStart by using st_crop() to crop the roads map to the area we are interested in (Hennepin and Ramsey County).\n\nroads_sub &lt;- st_crop(roads,st_bbox(census2020))\n\nCreate the map!!\n\nggplot() +\n    geom_sf(??)+ #put census tracts on map and fill by your variable of interest\n    geom_sf(?? ,fill = \"gray\", color = \"gray\", lwd = 0.2)+ #roads data here\n    labs(??)+ # add labels to fit your variables \n    scale_fill_gradientn(colours = c(\"lightcyan\", \"lightcyan2\", \"lightskyblue3\", \"lightskyblue4\"))+ # change to preferred color palette\n    theme_classic()+\n    theme(axis.line = element_blank(), \n        axis.text = element_blank(),\n        axis.ticks = element_blank(),\n        legend.position = \"bottom\", \n        plot.title.position = \"plot\", \n        plot.title = element_text(size = 8), \n        plot.subtitle = element_text(size = 8))\n\nHow to cite AI and other resources: If you use AI tools like ChatGPT or Google Bard, please copy and paste all prompts and output into an “Appendix” section of this assignment. If you use an AI tool, also list one environmentally-friendly action you could adopt (that you don’t already do) to offset the energy usage. Also list any websites used in this Appendix.\nSubmission details: Click the “Render” button to create an HTML report from your Quarto file. Open the HTML in your web browser and save the webpage as a PDF (Ctrl-P/Command P, choose “Save as PDF” as the Destination). Submit this PDF on Moodle AND the .qmd file by midnight on Wednesday, 9/20."
  },
  {
    "objectID": "03-adv-maps.html#additional-resources",
    "href": "03-adv-maps.html#additional-resources",
    "title": "Advanced Spatial Visualizations",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nSpatial Data Science https://r-spatial.org/book/\nLeaflet in R https://rstudio.github.io/leaflet/"
  },
  {
    "objectID": "04-interactive-viz.html",
    "href": "04-interactive-viz.html",
    "title": "Interactive visualization",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nEvaluate when it would be useful to use an interactive visualization or an animation and when it might not be necessary\nConstruct interactive visualizations and animations with plotly\nBuild a Shiny app that enables user to adjust visualization choices and explore linked visualizations\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)"
  },
  {
    "objectID": "04-interactive-viz.html#why-use-interactivity",
    "href": "04-interactive-viz.html#why-use-interactivity",
    "title": "Interactive visualization",
    "section": "Why use interactivity?",
    "text": "Why use interactivity?\nPros\n\nUsers can click, hover, zoom, and pan to get more detailed information\nUsers can get quickly and deeply explore the data via linked data representations\nAllows guided exploration of results without needing to share data\n\nCons\n\nTakes longer to design\nAnalyst might spend longer exploring an interactive visualization than a series of static visualizations\nPoor design could result in information overload"
  },
  {
    "objectID": "04-interactive-viz.html#common-features-of-interactive-visualizations",
    "href": "04-interactive-viz.html#common-features-of-interactive-visualizations",
    "title": "Interactive visualization",
    "section": "Common features of interactive visualizations",
    "text": "Common features of interactive visualizations\nCommon features of interactive visualizations include (reference):\n\nChanging data representation: providing options to change the type of plot displayed (e.g., allowing users to visualize temperature patterns over a month vs. over years)\nFocusing and getting details: mousing over part of a visualization to see an exact data value, zooming and panning\nData transformation: e.g., changing color scale, switching to/from log scale\nData selection and filtering: highlighting and brushing regions of a plot to focus the selected points; reordering and filtering data show in tables\nFinding corresponding information in multiple views: linked views that update dynamically based on interaction in another plot (often by zooming, panning, or selecting certain points)"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-0-app-planning",
    "href": "04-interactive-viz.html#exercise-0-app-planning",
    "title": "Interactive visualization",
    "section": "Exercise 0: App planning",
    "text": "Exercise 0: App planning\nCatalog the app’s layout and interactivity features as part of the app planning phase.\n\nNavigator: Open up the neighborhood diversity app for reference. The Navigator should explore the interactive features of the app and help the Driver sketch out a schematic of the app.\nDriver: Sketch the layout and general features of the app as the Navigator navigates. Draw arrows to indicate what parts of the app update in response to user input.\n\n\n\n\n\n\n\nReflect: App design\n\n\n\n\n\nIs the interactivity in this app needed? Does the interactivity actually help you gain more insight (and perhaps more efficiently) than a series of static visualizations? What static visualizations might be more useful?"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-1-setup-and-getting-acquainted",
    "href": "04-interactive-viz.html#exercise-1-setup-and-getting-acquainted",
    "title": "Interactive visualization",
    "section": "Exercise 1: Setup and getting acquainted",
    "text": "Exercise 1: Setup and getting acquainted\nSetup part 1: Load required packages at the top of app.R: shiny, tidyverse, sf, and plotly.\nSetup part 2: Data download and folder setup\nNavigate to the “Data for interactive viz activity” folder on Moodle and save the two files with the folder setup below:\n\n📂 YOUR_CLASS_FOLDER\n\n📂 interactive_viz\n\n📂 neighborhood_diversity\n\napp.R\n📂 data\n\ndata_by_dist.rds\ndata_by_year.csv\n\n\n\n\n\nSetup part 3: Below your library() calls, add the following commands to read in the data:\n\ndata_by_dist &lt;- read_rds(\"Enter the correct relative path to data_by_dist.rds\")\ndata_by_year &lt;- read_csv(\"Enter the correct relative path to data_by_year.csv\")\n\nGetting acquainted with the app and underlying code: Open this PDF or have the code printout distributed at the start of class in front of you. Also have the app running in your browser.\n\nDraw lines on the printout/PDF of what visual parts of the app correspond to which parts of code.\nWhat names/labels in the User Interface (ui) part of the app seem to be shared with the server part of the app? (Draw lines between the ui and server parts of the code.)\n\n\n\n\n\n\n\nStop to Share\n\n\n\n\n\nAs you work on the “Getting acquainted” part of this exercise, share with your partner some struggles you have with code and some strategies that you have tried."
  },
  {
    "objectID": "04-interactive-viz.html#input-functions",
    "href": "04-interactive-viz.html#input-functions",
    "title": "Interactive visualization",
    "section": "*Input() functions",
    "text": "*Input() functions\n\nBackground\nThe *Input() functions collect inputs from the user. The various types are listed on the right-hand side of the first page of the cheatsheet. You will list all the *Input() functions you want to use with their accompanying arguments inside the fluidPage() function in the ui portion. Separate the *Input() functions with commas.\nIn all the *Input() functions, the first two arguments are the same:\n\ninputId is how you will refer to this input in the server portion later\nlabel is how this will actually be labeled in your UI (what text shows up in the app)\n\nEach function has some additional arguments depending what you want to do.\n\n\nExercise 2: Add *Input()s\nAdd the following two user inputs to your app:\n\nDropdown to select the city name\nSlider to choose the span parameter for the scatterplot smooth\n\nUse the Shiny cheatsheet to find the *Input() functions that correspond to the two inputs above. Add them to the appropriate place within the ui object. Use commas to separate the inputs. You will have to look at the documentation for the *Input() functions to know how to use arguments beyond inputId and label. To view this documentation, type ?function_name in the Console.\nTo get the collection of city names from the data_by_dist dataset, you can use the pull() and unique() functions. Save the city names in an object called metro_names—this code can go just beneath where you read in the data.\nOnce you finish, run your app. Make sure you can select and move things around as expected. You won’t see any plots yet–we’ll work on those in the next exercises."
  },
  {
    "objectID": "04-interactive-viz.html#output-functions",
    "href": "04-interactive-viz.html#output-functions",
    "title": "Interactive visualization",
    "section": "*Output() functions",
    "text": "*Output() functions\n\nBackground\n*Output() functions in the ui portion work with the render*() functions in the server portion to to add R output to the UI. The *Output() functions are listed in the bottom center part of the first page of the cheatsheet.\nAll the *Output() functions have the same first argument, outputId, which is used how you will refer to this output in the server portion later (like the inputId in the *Input() functions).\n\n\nExercise 3: Add *Output()s\nAdd 3 plotOutput()s to the ui that will eventually be:\n\nA scatterplot of diversity score (entropy) versus distance to city hall (distmiles) with a smoothing line (smoothness controlled by the span parameter on your slider input)\nA map of diversity scores across the counties in the selected city\nA bar chart of the overall race distribution in the selected city (i.e., the total number of people in each race category in the city)\n\nFor now, don’t worry that the layout of the plots exactly matches the original neighborhood diversity app. (You will update this in your homework.)\nRun the app with the output. Notice that nothing really changes. Think of the outputs you just placed as placeholders—the app knows there will be a plot in the UI, but the details of what the plots will look like and the R code to create them will be in the server portion. Let’s talk about that now!"
  },
  {
    "objectID": "04-interactive-viz.html#render-functions",
    "href": "04-interactive-viz.html#render-functions",
    "title": "Interactive visualization",
    "section": "render*() functions",
    "text": "render*() functions\nThe render*() functions go in the server function of the app. The render*() functions use R code (i.e., standard ggplot code) to communicate with (“listen to”) the user inputs to create the desired output.\nThe render*() function you use will depend on the desired output. The bottom center of the cheatsheet shows how *Output() and render*() functions connect.\nIn general, the server section of code will look something like this:\n\nserver &lt;- function(input, output) {\n    output$outputId_of_interest &lt;- render*({ # Note the curly braces that enclose the R code below\n        # R code that creates the output and calls various input$InputId's\n    })\n}\n\nExample: Suppose that inside ui, we used plotOutput(outputId = \"timeplot\"):\n\nIn the server function, we would use output$timeplot &lt;- renderPlot({...}).\n\nThe ... would be replaced by detailed R plotting code.\nTo reference the inputs we create in the ui, we use input$inputID_name. e.g., if we had an *Input() with inputId = \"years\", we would use input$years in the server function.\n\n\n\nExercise 4: Add renderPlot()\nWhile our main goals is to make 3 plots, you will just make one of them in this exercise.\nAdd a renderPlot() functions inside the server portion of the code to make the scatterplot of diversity score (entropy) versus distance to city hall (distmiles) with a smoothing line. Reference the inputs you’ve already created in previous exercises by using filter() and ggplot() to render the desired interactive plot.\nNote: the geom_??? used to create the smoothing line has a span parameter. (Check out the documentation for that geom by entering ?geom_??? in the Console.)\nRun the app and check that the scatterplot displays and reacts to the chosen city and span parameter.\n\n\n\n\n\n\nStop to Reflect\n\n\n\n\n\nWhat challenges are you encountering as we go through this new material? What parts of your interactions with your partner have been helpful or less helpful for your learning today?"
  },
  {
    "objectID": "04-interactive-viz.html#exercise-5-turn-plots-into-plotlys",
    "href": "04-interactive-viz.html#exercise-5-turn-plots-into-plotlys",
    "title": "Interactive visualization",
    "section": "Exercise 5: Turn plots into plotlys",
    "text": "Exercise 5: Turn plots into plotlys\nIn a web application, having plots be plotly objects is just nice by default because of the great mouseover, zoom, and pan features.\nInside app.R, change all instances of plotOutput to plotlyOutput and all instances of renderPlot to renderPlotly. Make sure to add calls to ggplotly() too."
  },
  {
    "objectID": "05-data-types-1.html",
    "href": "05-data-types-1.html",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nDetermine the class of a given object and identify concerns to be wary of when manipulating an object of that class (numerics, logicals, factors, dates, strings, data.frames)\nExplain what vector recycling is, when it is used, when it can be a problem, and how to avoid those problems\nExplain the difference between implicit and explicit coercion\nExtract date-time information using the lubridate package\nWrite R code to wrangle data from these different types\nRecognize several new R errors and warnings related to data types\n\n\nSlides for today are available here. (For our main activity, we will be using the rest of the webpage below.)\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nwrangling_data_types\n\ncode\n\n05-data-types-1.qmd\n\ndata\n\nYou’ll download data from Moodle later today."
  },
  {
    "objectID": "05-data-types-1.html#numeric-and-integer-classes",
    "href": "05-data-types-1.html#numeric-and-integer-classes",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Numeric and integer classes",
    "text": "Numeric and integer classes\nNumbers that we see in R are generally of the numeric class, which are numbers with decimals. The c() function below is a way to create a vector of multiple numbers.\n\nnumbers &lt;- c(1, 2, 3)\nclass(numbers)\n\n[1] \"numeric\"\n\n\nR also has an integer class which will most often be formed when using the : operator to form regularly spaced sequences.\n\nintegers &lt;- 1:3\nclass(integers)\n\n[1] \"integer\"\n\n\nIt will be important to know how to check whether a number is a numeric or integer because we’ll be using the purrr package very shortly which checks types very strictly (e.g., 1 as an integer cannot be combined with 1 as a numeric)"
  },
  {
    "objectID": "05-data-types-1.html#vector-recycling",
    "href": "05-data-types-1.html#vector-recycling",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Vector recycling",
    "text": "Vector recycling\n\nhead(lakers %&gt;% select(date, opponent, team, points))\n\n      date opponent team points\n1 20081028      POR  OFF      0\n2 20081028      POR  LAL      0\n3 20081028      POR  LAL      0\n4 20081028      POR  LAL      0\n5 20081028      POR  LAL      0\n6 20081028      POR  LAL      2\n\n\nSuppose that we wanted to update just the first two points values (e.g., we learned of a typo).\n\npoint_update &lt;- c(2,3)\nlakers2 &lt;- lakers %&gt;%\n    mutate(points = points + point_update)\nhead(lakers$points)\n\n[1] 0 0 0 0 0 2\n\nhead(lakers2$points)\n\n[1] 2 3 2 3 2 5\n\n\nUh oh! It looks like the 2,3 point update vector got repeated multiple times. This is called vector recycling. If you are trying to combine or compare vectors of different lengths, R will repeat (recycle) the shorter one as many times as it takes to make them the same length. When the longer vector’s length isn’t a multiple of the smaller one, we’ll get a warning.\n\npoint_update &lt;- c(2,3,2)\nlakers2 &lt;- lakers %&gt;%\n    mutate(points = points + point_update)\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `points = points + point_update`.\nCaused by warning in `points + point_update`:\n! longer object length is not a multiple of shorter object length\n\n\nIn this case, the safest way to do the points update is to make sure that point_update has the same length as points:\n\nlakers2 &lt;- lakers %&gt;%\n    mutate(\n        play_id = 1:nrow(lakers),\n        point_update = case_when(\n            play_id==1 ~ 2,\n            play_id==2 ~ 3,\n            .default = 0\n        ),\n        points = points + point_update\n    )\n\nhead(lakers2 %&gt;% select(date, opponent, team, points))\n\n      date opponent team points\n1 20081028      POR  OFF      2\n2 20081028      POR  LAL      3\n3 20081028      POR  LAL      0\n4 20081028      POR  LAL      0\n5 20081028      POR  LAL      0\n6 20081028      POR  LAL      2\n\n\nRecycling will very often come up when working with logical objects (Booleans):\n\nclass(diamonds)==\"data.frame\"\n\n[1] FALSE FALSE  TRUE\n\nclass(diamonds)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\"data.frame\" %in% class(diamonds)\n\n[1] TRUE\n\nany(class(diamonds)==\"data.frame\")\n\n[1] TRUE"
  },
  {
    "objectID": "05-data-types-1.html#explicit-coercion",
    "href": "05-data-types-1.html#explicit-coercion",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Explicit coercion",
    "text": "Explicit coercion\nIn R there is a family of coercion functions that force a variable to be represented as a particular type. We have as.numeric() and as.integer() for numbers.\nMost commonly we will use these when numbers have accidentally been read in as a character or a factor. (More on factors later.)\nIn the example below we have a set of 4 points values, but the last entry was mistakenly typed as a space in the spreadsheet (instead of as an empty cell). We can see when we display points that all of the values have quotes around them and that the class of the points object is a character vector. (More on working with character objects next time.)\n\npoints &lt;- c(2, 3, 0, \" \")\npoints\n\n[1] \"2\" \"3\" \"0\" \" \"\n\nclass(points)\n\n[1] \"character\"\n\n\nMost commonly we will have numeric data that happens to be read in as a character. After cleaning up the strings, we can use as.numeric to coerce the vector to a numeric vector. (More on strings and regular expressions later.) Example:\n\nx &lt;- c(\"2.3\", \"3.4\", \"4.5\", \"5.6.\")\nas.numeric(x)\n\nWarning: NAs introduced by coercion\n\n\n[1] 2.3 3.4 4.5  NA\n\nx &lt;- str_remove(x, \"\\\\.$\")\nas.numeric(x)\n\n[1] 2.3 3.4 4.5 5.6"
  },
  {
    "objectID": "05-data-types-1.html#other-topics",
    "href": "05-data-types-1.html#other-topics",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Other topics",
    "text": "Other topics\nThe Numbers chapter in R4DS covers a lot of useful functions and ideas related to wrangling numbers. It would be very usefl to read this chapter. A glossary of the\n\nn(), n_distinct()\nsum(is.na())\npmin(), pmax() vs min(), max()\nInteger division: %/%. Remainder: %%\nround(), floor(), ceiling()\ncut()\ncumsum(), dplyr::cummean(), cummin(), cummax()\ndplyr::min_rank()\nlead(), lag(): shift a vector by padding with NAs\nNumerical summaries: mean, median, min, max, quantile, sd, IQR"
  },
  {
    "objectID": "06-data-types-2.html",
    "href": "06-data-types-2.html",
    "title": "Wrangling: strings",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nManipulate and explore strings using the stringr package\nConstruct regular expressions to find patterns in strings\n\n\nTo shape how we hold class today, go to my PollEverywhere page for some survey questions.\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nwrangling_data_types\n\ncode\n\n05-data-types-1.qmd\n06-data-types-2.qmd"
  },
  {
    "objectID": "06-data-types-2.html#creating-strings",
    "href": "06-data-types-2.html#creating-strings",
    "title": "Wrangling: strings",
    "section": "Creating strings",
    "text": "Creating strings\nCreating strings by hand is useful for testing out regular expressions.\nTo create a string, type any text in either double quotes (\") or single quotes '. Using double or single quotes doesn’t matter unless your string itself has single or double quotes.\n\nstring1 &lt;- \"This is a string\"\nstring2 &lt;- 'If I want to include a \"quote\" inside a string, I use single quotes'\n\nWe can view these strings “naturally” (without the opening and closing quotes) with str_view():\n\nstr_view(string1)\n\n[1] │ This is a string\n\nstr_view(string2)\n\n[1] │ If I want to include a \"quote\" inside a string, I use single quotes\n\n\nExercise: Create the string It's Thursday. What happens if you put the string inside single quotes? Double quotes?\n\n# Your code\n\n\n\nSolution\n\n\nx &lt;- \"It's Thursday\" # We need double quotes because of the apostrophe\nx\nx &lt;- 'It's Thursday'\n\nError: &lt;text&gt;:3:10: unexpected symbol\n2: x\n3: x &lt;- 'It's\n            ^\n\n\n\nBecause \" and ' are special characters in the creation of strings, R offers another way to put them inside a string. We can escape these special characters by putting a \\ in front of them:\n\nstring1 &lt;- \"This is a string with \\\"double quotes\\\"\"\nstring2 &lt;- \"This is a string with \\'single quotes\\'\"\nstr_view(string1)\n\n[1] │ This is a string with \"double quotes\"\n\nstr_view(string2)\n\n[1] │ This is a string with 'single quotes'\n\n\nGiven that \\ is a special character, how can we put the \\ character in strings? We have to escape it with \\\\.\nExercise: Create the string C:\\Users. What happens when you don’t escape the \\?\n\n# Your code\n\n\n\nSolution\n\n\nx &lt;- \"C:\\\\Users\"\nstr_view(x)\n\n# \\U is the start of special escape characters for Unicode characters\n# The \\U is expected to be followed by certain types of letters and numbers--like \\U0928\nx &lt;- \"C:\\Users\"\n\nError: '\\U' used without hex digits in character string (&lt;text&gt;:6:10)\n\n\n\nOther special characters include:\n\n\\t (Creates a tab)\n\\n (Creates a newline)\n\nBoth can be useful in plots to more neatly arrange text.\n\nstring1 &lt;- \"Record temp:\\t102\"\nstring2 &lt;- \"Record temp:\\n102\"\n\nstr_view(string1)\n\n[1] │ Record temp:{\\t}102\n\nstr_view(string2)\n\n[1] │ Record temp:\n    │ 102\n\n\nExercise (Exploring function documentation): Can we get str_view() to show the tab instead of {\\t}? Enter ?str_view in the Console to pull up the documentation for this function. Look through the arguments to see how we might do this.\n\n\nSolution\n\n\nstr_view(string1, html = TRUE)\n\n\nReflection: In your Process and Reflection Log, record any strategies that you learned about reading function documentation.\n\nOften we will want to create new strings within data frames. We can use str_c() or str_glue():\n\nWith str_c() the strings to be combined are all separate arguments separated by commas.\nWith str_glue() the desired string is written as a template with variable names inside curly braces {}.\n\n\ndf &lt;- tibble(\n    first_name = c(\"Arya\", \"Olenna\", \"Tyrion\", \"Melisandre\"),\n    last_name = c(\"Stark\", \"Tyrell\", \"Lannister\", NA)\n)\ndf\n\n# A tibble: 4 × 2\n  first_name last_name\n  &lt;chr&gt;      &lt;chr&gt;    \n1 Arya       Stark    \n2 Olenna     Tyrell   \n3 Tyrion     Lannister\n4 Melisandre &lt;NA&gt;     \n\ndf %&gt;%\n    mutate(\n        full_name1 = str_c(first_name, \" \", last_name),\n        full_name2 = str_glue(\"{first_name} {last_name}\")\n    )\n\n# A tibble: 4 × 4\n  first_name last_name full_name1       full_name2      \n  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt;            &lt;glue&gt;          \n1 Arya       Stark     Arya Stark       Arya Stark      \n2 Olenna     Tyrell    Olenna Tyrell    Olenna Tyrell   \n3 Tyrion     Lannister Tyrion Lannister Tyrion Lannister\n4 Melisandre &lt;NA&gt;      &lt;NA&gt;             Melisandre NA   \n\n\nExercise: In the following data frame, create a full date string in month-day-year format using both str_c() and str_glue().\n\ndf_dates &lt;- tibble(\n    year = c(2000, 2001, 2002),\n    month = c(\"Jan\", \"Feb\", \"Mar\"),\n    day = c(3, 4, 5)\n)\n\n\n\nSolution\n\n\ndf_dates %&gt;%\n    mutate(\n        date1 = str_c(month, \"-\", day, \"-\", year),\n        date2 = str_glue(\"{month}-{day}-{year}\")\n    )\n\n# A tibble: 3 × 5\n   year month   day date1      date2     \n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;glue&gt;    \n1  2000 Jan       3 Jan-3-2000 Jan-3-2000\n2  2001 Feb       4 Feb-4-2001 Feb-4-2001\n3  2002 Mar       5 Mar-5-2002 Mar-5-2002"
  },
  {
    "objectID": "06-data-types-2.html#extracting-information-from-strings",
    "href": "06-data-types-2.html#extracting-information-from-strings",
    "title": "Wrangling: strings",
    "section": "Extracting information from strings",
    "text": "Extracting information from strings\nThe str_length() counts the number of characters in a string.\n\ncomments &lt;- tibble(\n    name = c(\"Alice\", \"Bob\"),\n    comment = c(\"The essay was well organized around the core message and had good transitions.\", \"Good job!\")\n)\n\ncomments %&gt;%\n    mutate(\n        comment_length = str_length(comment)\n    )\n\n# A tibble: 2 × 3\n  name  comment                                                   comment_length\n  &lt;chr&gt; &lt;chr&gt;                                                              &lt;int&gt;\n1 Alice The essay was well organized around the core message and…             78\n2 Bob   Good job!                                                              9\n\n\nThe str_sub() function gets a substring of a string. The 2nd and 3rd arguments indicate the beginning and ending position to extract.\n\nNegative positions indicate the position from the end of the word. (e.g., -3 indicates “3rd letter from the end”)\nSpecifying a position that goes beyond the word won’t result in an error. str_sub() will just go as far as possible.\n\n\nx &lt;- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 1, 3)\n\n[1] \"App\" \"Ban\" \"Pea\"\n\nstr_sub(x, -3, -1)\n\n[1] \"ple\" \"ana\" \"ear\"\n\nstr_sub(\"a\", 1, 5)\n\n[1] \"a\"\n\n\nExercise: Find the middle letter of each word in the data frame below. (Challenge: How would you handle words with an even number of letters?)\n\ndf &lt;- tibble(\n    word_id = 1:3,\n    word = c(\"replace\", \"match\", \"pattern\")\n)\n\n\n\nSolution\n\n\ndf %&gt;%\n    mutate(\n        word_length = str_length(word),\n        middle_pos = ceiling(word_length/2),\n        middle_letter = str_sub(word, middle_pos, middle_pos)\n    )\n\n# A tibble: 3 × 5\n  word_id word    word_length middle_pos middle_letter\n    &lt;int&gt; &lt;chr&gt;         &lt;int&gt;      &lt;dbl&gt; &lt;chr&gt;        \n1       1 replace           7          4 l            \n2       2 match             5          3 t            \n3       3 pattern           7          4 t"
  },
  {
    "objectID": "06-data-types-2.html#finding-patterns-in-strings-with-regular-expressions",
    "href": "06-data-types-2.html#finding-patterns-in-strings-with-regular-expressions",
    "title": "Wrangling: strings",
    "section": "Finding patterns in strings with regular expressions",
    "text": "Finding patterns in strings with regular expressions\nSuppose that you’re exploring text data looking for places where people describe happiness. There are many ways to search. We could search for the word “happy” but that excludes “happiness” so we might search for “happi”.\nRegular expressions (regex) are a powerful language for describing patterns within strings.\n\ndata(fruit)\ndata(words)\ndata(sentences)\n\nWe can use str_view() with the pattern argument to see what parts of a string match the regex supplied in the pattern argument. (Matches are enclosed in &lt;&gt;.)\n\nstr_view(fruit, \"berry\")\n\n [6] │ bil&lt;berry&gt;\n [7] │ black&lt;berry&gt;\n[10] │ blue&lt;berry&gt;\n[11] │ boysen&lt;berry&gt;\n[19] │ cloud&lt;berry&gt;\n[21] │ cran&lt;berry&gt;\n[29] │ elder&lt;berry&gt;\n[32] │ goji &lt;berry&gt;\n[33] │ goose&lt;berry&gt;\n[38] │ huckle&lt;berry&gt;\n[50] │ mul&lt;berry&gt;\n[70] │ rasp&lt;berry&gt;\n[73] │ salal &lt;berry&gt;\n[76] │ straw&lt;berry&gt;\n\n\nEssentials of forming a regex\n\nLetters and numbers in a regex are matched exactly and are called literal characters.\nMost punctuation characters, like ., +, *, [, ], and ?, have special meanings and are called metacharacters.\nQuantifiers come after a regex and control how many times a pattern can match:\n\n?: match the preceding pattern 0 or 1 times\n+: match the preceding pattern at least once\n*: match the preceding pattern at least 0 times (any number of times)\n\n\nExercise: Before running the code below, predict what matches will be made. Run the code to check your guesses. Note that in all regex’s below the ?, +, * applies to the b only (not the a).\n\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;ab&gt;b\n\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\n\n\n\nSolution\n\n\n# This regex finds \"a\" then \"b\" at most once (can't have 2 or more b's in a row)\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab?\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;ab&gt;b\n\n\n\n# There has to be an \"a\" followed by at least one b\n# This is why the first string \"a\" isn't matched\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab+\")\n\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\n\n\n# There must be an \"a\" and then any number of b's (including zero)\nstr_view(c(\"a\", \"ab\", \"abb\"), \"ab*\")\n\n[1] │ &lt;a&gt;\n[2] │ &lt;ab&gt;\n[3] │ &lt;abb&gt;\n\n\n\n\nWe can match any of a set of characters with [] (called a character class), e.g., [abcd] matches “a”, “b”, “c”, or “d”.\n\nWe can invert the match by starting with ^: [^abcd] matches anything except “a”, “b”, “c”, or “d”.\n\n\n\n# Match words that have vowel-x-vowel\nstr_view(words, \"[aeiou]x[aeiou]\")\n\n[284] │ &lt;exa&gt;ct\n[285] │ &lt;exa&gt;mple\n[288] │ &lt;exe&gt;rcise\n[289] │ &lt;exi&gt;st\n\n# Match words that have not_vowel-y-not_vowel\nstr_view(words, \"[^aeiou]y[^aeiou]\")\n\n[836] │ &lt;sys&gt;tem\n[901] │ &lt;typ&gt;e\n\n\nExercise Using the words data, find words that have two vowels in a row followed by an “m”.\n\n# Your code\n\n\n\nSolution\n\n\nstr_view(words, \"[aeiou][aeiou]m\")\n\n[154] │ cl&lt;aim&gt;\n[714] │ r&lt;oom&gt;\n[735] │ s&lt;eem&gt;\n[844] │ t&lt;eam&gt;\n\n\n\n\nThe alternation operator | can be read just like the logical operator | (“OR”) to pick between one or more alternative patterns. e.g., apple|banana searches for “apple” or “banana”.\n\n\nstr_view(fruit, \"apple|melon|nut\")\n\n [1] │ &lt;apple&gt;\n[13] │ canary &lt;melon&gt;\n[20] │ coco&lt;nut&gt;\n[52] │ &lt;nut&gt;\n[62] │ pine&lt;apple&gt;\n[72] │ rock &lt;melon&gt;\n[80] │ water&lt;melon&gt;\n\n\nExercise: Using the fruit data, find fruits that have a repeated vowel (“aa”, “ee”, “ii”, “oo”, or “uu”.)\n\n# Your code\n\n\n\nSolution\n\n\nstr_view(fruit, \"aa|ee|ii|oo|uu\")\n\n [9] │ bl&lt;oo&gt;d orange\n[33] │ g&lt;oo&gt;seberry\n[47] │ lych&lt;ee&gt;\n[66] │ purple mangost&lt;ee&gt;n\n\n\n\n\nThe ^ operator indicates the beginning of a string, and the $ operator indicates the end of a string. e.g., ^a matches strings that start with “a”, and a$ matches words that end with “a”.\nParentheses group together parts of a regular expression that should be taken as a bundle. (Much like parentheses in arithmetic statements.)\n\ne.g., ab+ is a little confusing. Does it match “ab” one or more times? Or does it match “a” first, then just “b” one or more times? (The latter, as we saw in an earlier example.) We can be very explicit and use a(b)+.\n\n\nExercise: Using the words data, find (1) words that start with “y” and (2) words that don’t start with “y”.\n\n# Your code\n\n\n\nSolution\n\n\n# Words that start with y\nstr_view(words, \"^y\")\n\n[975] │ &lt;y&gt;ear\n[976] │ &lt;y&gt;es\n[977] │ &lt;y&gt;esterday\n[978] │ &lt;y&gt;et\n[979] │ &lt;y&gt;ou\n[980] │ &lt;y&gt;oung\n\n# Words that don't start with y\nstr_view(words, \"^[^y]\")\n\n [1] │ &lt;a&gt;\n [2] │ &lt;a&gt;ble\n [3] │ &lt;a&gt;bout\n [4] │ &lt;a&gt;bsolute\n [5] │ &lt;a&gt;ccept\n [6] │ &lt;a&gt;ccount\n [7] │ &lt;a&gt;chieve\n [8] │ &lt;a&gt;cross\n [9] │ &lt;a&gt;ct\n[10] │ &lt;a&gt;ctive\n[11] │ &lt;a&gt;ctual\n[12] │ &lt;a&gt;dd\n[13] │ &lt;a&gt;ddress\n[14] │ &lt;a&gt;dmit\n[15] │ &lt;a&gt;dvertise\n[16] │ &lt;a&gt;ffect\n[17] │ &lt;a&gt;fford\n[18] │ &lt;a&gt;fter\n[19] │ &lt;a&gt;fternoon\n[20] │ &lt;a&gt;gain\n... and 954 more\n\n\n\n\nThe following are core stringr functions that use regular expressions:\n\nstr_view() - View the first occurrence in a string that matches the regex\nstr_count() - Count the number of times a regex matches within a string\nstr_detect() - Determine if (TRUE/FALSE) the regex is found within string\nstr_subset() - Return subset of strings that match the regex\nstr_extract(), str_extract_all() - Return portion of each string that matches the regex. str_extract() extracts the first instance of the match. str_extract_all() extracts all matches.\nstr_replace(), str_replace_all() - Replace portion of string that matches the regex with something else. str_replace() replaces the first instance of the match. str_replace_all() replaces all instances of the match.\nstr_remove(), str_remove_all() - Removes the portion of the string that matches the pattern. Equivalent to str_replace(x, \"THE REGEX PATTERN\", \"\")\n\nExercise: Each person at your table should explore a different one of the functions (other than str_view()). Pull up the documentation page using ?function_name. Explore the arguments and create a small example that demonstrates its usage. Share with your group members."
  },
  {
    "objectID": "07-data-types-3.html",
    "href": "07-data-types-3.html",
    "title": "Wrangling: factors",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nRecode and manage factors using the forcats package\n\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nwrangling_data_types\n\ncode\n\n05-data-types-1.qmd\n06-data-types-2.qmd\n07-data-types-3.qmd"
  },
  {
    "objectID": "07-data-types-3.html#creating-factors",
    "href": "07-data-types-3.html#creating-factors",
    "title": "Wrangling: factors",
    "section": "Creating factors",
    "text": "Creating factors\nIn R, factors are made up of two components: the actual values of the data and the possible levels within the factor. Creating a factor requires supplying both pieces of information.\n\nmonths &lt;- c(\"Mar\", \"Dec\", \"Jan\",  \"Apr\", \"Jul\")\n\nHowever, if we were to sort this vector, R would sort this vector alphabetically.\n\n# alphabetical sort\nsort(months)\n\n[1] \"Apr\" \"Dec\" \"Jan\" \"Jul\" \"Mar\"\n\n\nWe can fix this sorting by creating a factor version of months. The levels argument is a character vector that specifies the unique values that the factor can take. The order of the values in levels defines the sorting of the factor.\n\nmonths_fct &lt;- factor(months, levels = month.abb) # month.abb is a built-in variable\nmonths_fct\n\n[1] Mar Dec Jan Apr Jul\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\nsort(months_fct)\n\n[1] Jan Mar Apr Jul Dec\nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nWhat if we try to create a factor with values that aren’t in the levels? (e.g., a typo in a month name)\n\nmonths2 &lt;- c(\"Jna\", \"Mar\")\nfactor(months2, levels = month.abb)\n\n[1] &lt;NA&gt; Mar \nLevels: Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n\n\nBecause the NA is introduced silently (without any error or warnings), this can be dangerous. It might be better to use the fct() function in the forcats package instead:\n\nfct(months2, levels = month.abb)\n\nError in `fct()`:\n! All values of `x` must appear in `levels` or `na`\nℹ Missing level: \"Jna\"\n\n\nExercise: Create a factor version of the following data with the levels in a sensible order.\n\nratings &lt;- c(\"High\", \"Medium\", \"Low\")\n\nIn the remainder of the exercises and examples, we’ll use a subset of the General Social Survey (GSS) dataset available in the forcats pacakges.\n\ndata(gss_cat)"
  },
  {
    "objectID": "07-data-types-3.html#reordering-factors",
    "href": "07-data-types-3.html#reordering-factors",
    "title": "Wrangling: factors",
    "section": "Reordering factors",
    "text": "Reordering factors\nReordering the levels of a factor can be useful in plotting when categories would benefit from being sorted in a particular way:\n\nrelig_summary &lt;- gss_cat %&gt;%\n    group_by(relig) %&gt;%\n    summarize(\n        tvhours = mean(tvhours, na.rm = TRUE),\n        n = n()\n    )\n\nggplot(relig_summary, aes(x = tvhours, y = relig)) + \n    geom_point() +\n    theme_classic()\n\n\n\n\nWe can use fct_reorder() in forcats.\n\nThe first argument is the factor that you want to reorder the levels of\nThe second argument determines how the factor is sorted (analogous to what you put inside arrange() when sorting the rows of a data frame.)\n\n\nggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) +\n    geom_point() +\n    theme_classic()\n\n\n\n\nFor bar plots, we can use fct_infreq() to reorder levels from most to least common. This can be combined with fct_rev() to reverse the order (least to most common):\n\ngss_cat %&gt;%\n    ggplot(aes(x = marital)) +\n    geom_bar() +\n    theme_classic()\n\n\n\ngss_cat %&gt;%\n    mutate(marital = marital %&gt;% fct_infreq() %&gt;% fct_rev()) %&gt;%\n    ggplot(aes(x = marital)) +\n    geom_bar() +\n    theme_classic()"
  },
  {
    "objectID": "07-data-types-3.html#modifying-factor-levels",
    "href": "07-data-types-3.html#modifying-factor-levels",
    "title": "Wrangling: factors",
    "section": "Modifying factor levels",
    "text": "Modifying factor levels\nWe talked about reordering the levels of a factor–what about changing the values of the levels themselves?\nFor example, the names of the political parties in the GSS could use elaboration (“str” isn’t a great label for “strong”) and clean up:\n\ngss_cat %&gt;% count(partyid)\n\n# A tibble: 10 × 2\n   partyid                n\n   &lt;fct&gt;              &lt;int&gt;\n 1 No answer            154\n 2 Don't know             1\n 3 Other party          393\n 4 Strong republican   2314\n 5 Not str republican  3032\n 6 Ind,near rep        1791\n 7 Independent         4119\n 8 Ind,near dem        2499\n 9 Not str democrat    3690\n10 Strong democrat     3490\n\n\nWe can use fct_recode() on partyid with the new level names going on the left and the old levels on the right. Any levels that aren’t mentioned explicitly (i.e., “Don’t know” and “Other party”) will be left as is:\n\ngss_cat %&gt;%\n    mutate(\n        partyid = fct_recode(partyid,\n            \"Republican, strong\"    = \"Strong republican\",\n            \"Republican, weak\"      = \"Not str republican\",\n            \"Independent, near rep\" = \"Ind,near rep\",\n            \"Independent, near dem\" = \"Ind,near dem\",\n            \"Democrat, weak\"        = \"Not str democrat\",\n            \"Democrat, strong\"      = \"Strong democrat\"\n        )\n    ) %&gt;%\n    count(partyid)\n\n# A tibble: 10 × 2\n   partyid                   n\n   &lt;fct&gt;                 &lt;int&gt;\n 1 No answer               154\n 2 Don't know                1\n 3 Other party             393\n 4 Republican, strong     2314\n 5 Republican, weak       3032\n 6 Independent, near rep  1791\n 7 Independent            4119\n 8 Independent, near dem  2499\n 9 Democrat, weak         3690\n10 Democrat, strong       3490\n\n\nTo combine groups, we can assign multiple old levels to the same new level (“Other” maps to “No answer”, “Don’t know”, and “Other party”):\n\ngss_cat %&gt;%\n    mutate(\n        partyid = fct_recode(partyid,\n            \"Republican, strong\"    = \"Strong republican\",\n            \"Republican, weak\"      = \"Not str republican\",\n            \"Independent, near rep\" = \"Ind,near rep\",\n            \"Independent, near dem\" = \"Ind,near dem\",\n            \"Democrat, weak\"        = \"Not str democrat\",\n            \"Democrat, strong\"      = \"Strong democrat\",\n            \"Other\"                 = \"No answer\",\n            \"Other\"                 = \"Don't know\",\n            \"Other\"                 = \"Other party\"\n        )\n    )\n\n# A tibble: 21,483 × 9\n    year marital         age race  rincome        partyid    relig denom tvhours\n   &lt;int&gt; &lt;fct&gt;         &lt;int&gt; &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;   &lt;int&gt;\n 1  2000 Never married    26 White $8000 to 9999  Independe… Prot… Sout…      12\n 2  2000 Divorced         48 White $8000 to 9999  Republica… Prot… Bapt…      NA\n 3  2000 Widowed          67 White Not applicable Independe… Prot… No d…       2\n 4  2000 Never married    39 White Not applicable Independe… Orth… Not …       4\n 5  2000 Divorced         25 White Not applicable Democrat,… None  Not …       1\n 6  2000 Married          25 White $20000 - 24999 Democrat,… Prot… Sout…      NA\n 7  2000 Never married    36 White $25000 or more Republica… Chri… Not …       3\n 8  2000 Divorced         44 White $7000 to 7999  Independe… Prot… Luth…      NA\n 9  2000 Married          44 White $25000 or more Democrat,… Prot… Other       0\n10  2000 Married          47 White $25000 or more Republica… Prot… Sout…       3\n# ℹ 21,473 more rows\n\n\nWe can use fct_collapse() to collapse many levels:\n\ngss_cat %&gt;%\n    mutate(\n        partyid = fct_collapse(partyid,\n            \"Other\" = c(\"No answer\", \"Don't know\", \"Other party\"),\n            \"Republican\" = c(\"Strong republican\", \"Not str republican\"),\n            \"Independent\" = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n            \"Democrat\" = c(\"Not str democrat\", \"Strong democrat\")\n        )\n    ) %&gt;%\n    count(partyid)\n\n# A tibble: 4 × 2\n  partyid         n\n  &lt;fct&gt;       &lt;int&gt;\n1 Other         548\n2 Republican   5346\n3 Independent  8409\n4 Democrat     7180\n\n\nExercises: Using the gss_cat dataset, try the following:\n\nMake a plot that shows the relationship between marital status (marital) and age in a way that makes a trend clear.\nMake a plot that shows the relationship between religion followed (relig) and income rincome. Combine income categories for better readability."
  },
  {
    "objectID": "08-functions-control-structs.html",
    "href": "08-functions-control-structs.html",
    "title": "Functions and control structures",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nRecognize when it would be useful to write a function\nIdentify the core components of a function definition and explain their role (the function() directive, arguments, argument defaults, function body, return value)\nDescribe the difference between argument matching by position and by name\nWrite if-else, if-else if-else statements to conditionally execute code\nWrite your own function to carry out a repeated task\nProvide feedback on functions written by others\n\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nfunctions\n\ncode\n\n08-functions-control-structs.qmd"
  },
  {
    "objectID": "08-functions-control-structs.html#why-functions",
    "href": "08-functions-control-structs.html#why-functions",
    "title": "Functions and control structures",
    "section": "Why functions?",
    "text": "Why functions?\nGetting really good at writing useful and reusable functions is one of the best ways to increase your expertise in data science. It requires a lot of practice.\nIf you’ve copied and pasted code 3 or more times, it’s time to write a function.\n\nReducing errors: Copy+paste+modify is prone to errors (e.g., forgetting to change a variable name)\nEfficiency: If you need to update code, you only need to do it one place. This allows reuse of code within and across projects.\nReadability: Encapsulating code within a function with a descriptive name makes code more readable."
  },
  {
    "objectID": "08-functions-control-structs.html#core-parts-of-a-function",
    "href": "08-functions-control-structs.html#core-parts-of-a-function",
    "title": "Functions and control structures",
    "section": "Core parts of a function",
    "text": "Core parts of a function\nWhat does a function look like?\n\naverage &lt;- function(x, remove_nas) {\n    sum(x, na.rm = remove_nas)/length(x)\n}\n\naverage2 &lt;- function(x, remove_nas) {\n    return(sum(x, na.rm = remove_nas)/length(x))\n}\n\naverage3 &lt;- function(x, remove_nas = TRUE) {\n    sum(x, na.rm = remove_nas)/length(x)\n}\n\nThe core parts of a function include:\n\nThe function() directive\n\nThis is what allows tells R to create a function.\n\nArguments: the x and remove_nas – these are function inputs\n\nIn average3, the remove_nas argument has a default value of TRUE.\n\nFunction body\n\nThe code inside the curly braces {} is where all the work happens. This code uses the function arguments to perform computations.\n\nReturn value\n\nThe first value that gets computed and isn’t stored as an object is what the function returns. (This is generally the first line without an assignment operator &lt;-.)\nAs in average3(), we can also explicitly return an object by putting it inside return().\n\n\nWhen a function has default values for arguments, they don’t have to be explicitly named if you want to use the default value:\n\n# Both give the same result\naverage3(c(1, 2, 3, NA))\n\n[1] 1.5\n\naverage3(c(1, 2, 3, NA), remove_nas = TRUE)\n\n[1] 1.5\n\n\nPair programming exercise: Pair up with the person next to you. There are two function writing exercises coming up. You’ll swap driver and navigator roles between exercises. (The driver writes the code. The navigator oversees and provides guidance.) For the first exercise, the person whose birthday is coming up sooner will be the driver first. Swap for the second exercise.\nExercise: Write a function that rescales a numeric vector to be between 0 and 1. Test out your function on the following inputs:\n\nx = 2:4\nx = c(-1, 0, 5)\nx = -3:-1\n\n\n\nSolution\n\n\nrescale01 &lt;- function(x) {\n    range_x &lt;- range(x, na.rm = TRUE)\n    # The [2] and [1] below extract the second and first element of a vector\n    (x - min(x, na.rm = TRUE)) / (range_x[2]-range_x[1])\n}\n\n\nExercise Write a function that replaces NAs in a character vector with a user-specified string (e.g., “missing”). Provide a default value for the user-specified string. Come up with some test inputs for your function. (Hint: the str_replace_na() function in stringr may be useful.)\n\n\nSolution\n\n\nreplace_na &lt;- function(x, na_replacement = \"Missing\") {\n    x_na &lt;- str_replace_na(x)\n    str_replace(x_na, \"NA\", na_replacement)\n}"
  },
  {
    "objectID": "08-functions-control-structs.html#argument-matching",
    "href": "08-functions-control-structs.html#argument-matching",
    "title": "Functions and control structures",
    "section": "Argument matching",
    "text": "Argument matching\nWhen you supply arguments to a function, they can be matched by position and/or by name.\nWhen you call a function without argument = value inside the parentheses, you are using positional matching.\n\nggplot(diamonds, aes(x = carat, y = price)) + geom_point()\n\nThe above works because the first argument of ggplot is data and the second is mapping. (Pull up the documentation on ggplot with ?ggplot in the Console.) So the following doesn’t work:\n\nggplot(aes(x = carat, y = price), diamonds) + geom_point()\n\nError in `ggplot()`:\n! `mapping` should be created with `aes()`.\n✖ You've supplied a &lt;tbl_df&gt; object\n\n\nBut if we named the arguments (name matching), we would be fine:\n\nggplot(mapping = aes(x = carat, y = price), data = diamonds) + geom_point()\n\nSomewhat confusingly, we can name some arguments and not others. Below, mapping is named, but data isn’t. This works because when an argument is matched by name, it is “removed” from the argument list, and the remaining unnamed arguments are matched in the order that they are listed in the function definition.\n\nggplot(mapping = aes(x = carat, y = price), diamonds) + geom_point()\n\n\n\n\n\n\n\nArgument matching\n\n\n\nIn general, it is safest to match arguments by name and position for your peace of mind. For functions that you are very familiar with (and know the argument order), it’s ok to just use positional matching.\n\n\nExercise: Diagnose the error message in the example below:\nggplot() %&gt;%\n    geom_sf(census_data, aes(fill = population))\n    \nError in `layer_sf()`:\n! `mapping` must be created by `aes()`\n\n\nSolution\n\nUse ?geom_sf to look up the function documentation. We see that the order of the arguments is first mapping and second data. The error is due to R thinking that census_data is supplying aesthetics. This is an example of positional matching gone wrong."
  },
  {
    "objectID": "08-functions-control-structs.html#the-if-else-if-else-control-structure",
    "href": "08-functions-control-structs.html#the-if-else-if-else-control-structure",
    "title": "Functions and control structures",
    "section": "The if-else if-else control structure",
    "text": "The if-else if-else control structure\nOften in functions, you will want to execute code conditionally. In a programming language, control structures are parts of the language that allow you to control what code is executed. By far the most common is the `if-else if-else structure.\n\nif (logical_condition) {\n    # some code\n} else if (other_logical_condition) {\n    # some code\n} else {\n    # some code\n}\n\nmiddle &lt;- function(x) {\n    mean_x &lt;- mean(x, na.rm = TRUE)\n    median_x &lt;- median(x, na.rm = TRUE)\n    seems_skewed &lt;- (mean_x &gt; 1.5*median_x) | (mean_x &lt; (1/1.5)*median_x)\n    if (seems_skewed) {\n        median_x\n    } else {\n        mean_x\n    }\n}\n\nPair programming exercise: Partner with the person next to you again. Whoever was driver most recently should start as navigator. Switch for the second exercise.\nExercise: Write a function for converting temperatures that takes as input a numeric value and a unit (either “C” for Celsius or “F” for Fahrenheit). The function should convert the temperature from one unit to the other based on the following formulas:\n\nTo convert Celsius to Fahrenheit: (Celsius * 9/5) + 32\nTo convert Fahrenheit to Celsius: (Fahrenheit - 32) * 5/9\n\n\n\nSolution\n\n\nconvert_temp &lt;- function(temp, unit) {\n    if (unit==\"F\") {\n        (temp - 32) * 5/9\n    } else if (unit==\"C\") {\n        (temp * 9/5) + 32\n    }\n}\n\nconvert_temp(0, unit = \"C\")\n\n[1] 32\n\nconvert_temp(32, unit = \"F\")\n\n[1] 0\n\n\n\nExercise: Write a function that extracts the domain name of a supplied email address. The function should return the domain name (e.g., “gmail.com”). If the input is not a valid email address, return “Invalid Email”.\n\n\nSolution\n\n\nextract_domain &lt;- function(email) {\n    is_valid &lt;- str_detect(email, \"@.+\\\\.\")\n    if (is_valid) {\n        str_extract(email, \"@.+$\") %&gt;%\n            str_remove(\"@\")\n    } else {\n        \"Invalid Email\"\n    }\n}\n\nextract_domain(email = \"les@mac.edu\")\n\n[1] \"mac.edu\""
  },
  {
    "objectID": "08-functions-control-structs.html#writing-functions-with-tidyverse-verbs",
    "href": "08-functions-control-structs.html#writing-functions-with-tidyverse-verbs",
    "title": "Functions and control structures",
    "section": "Writing functions with tidyverse verbs",
    "text": "Writing functions with tidyverse verbs\nPerhaps we are using group_by() and summarize() a lot to compute group means. We might write this function:\n\ngroup_means &lt;- function(df, group_var, mean_var) {\n    df %&gt;%\n        group_by(group_var) %&gt;%\n        summarize(mean = mean(mean_var))\n}\n\nLet’s use it on the diamonds dataset to compute the mean size (carat) by diamond cut:\n\ngroup_means(diamonds, group_var = cut, mean_var = carat)\n\nError in `group_by()`:\n! Must group by variables found in `.data`.\n✖ Column `group_var` is not found.\n\n\nWhat if the problem is that the variable names need to be in quotes?\n\ngroup_means(diamonds, group_var = \"cut\", mean_var = \"carat\")\n\nError in `group_by()`:\n! Must group by variables found in `.data`.\n✖ Column `group_var` is not found.\n\n\nWhat’s going on??? The tidyverse uses something called tidy evaluation: this allows you to refer to a variable by typing it directly (e.g., no need to put it in quotes). So group_by(group_var) is expecting a variable that is actually called group_var, and mean(mean_var) is expecting a variable that is actually called mean_var.\nTo fix this we need to embrace the variables inside the function with {{ var }}:\n\ngroup_means &lt;- function(df, group_var, mean_var) {\n    df %&gt;%\n        group_by({{ group_var }}) %&gt;%\n        summarize(mean = mean({{ mean_var }}))\n}\n\nThe {{ var }} tells R to look at what the value of the variable var rather than look for var literally.\n\ngroup_means(diamonds, group_var = cut, mean_var = carat)\n\n# A tibble: 5 × 2\n  cut        mean\n  &lt;ord&gt;     &lt;dbl&gt;\n1 Fair      1.05 \n2 Good      0.849\n3 Very Good 0.806\n4 Premium   0.892\n5 Ideal     0.703\n\n\nLet’s group by both cut and color:\n\ngroup_means(diamonds, group_var = c(cut, color), mean_var = carat)\n\nError in `group_by()`:\nℹ In argument: `c(cut, color)`.\nCaused by error:\n! `c(cut, color)` must be size 53940 or 1, not 107880.\n\n\nOh no! What now?! When c(cut, color) is put inside {{ c(cut, color) }} within the function, R is actually running the code inside {{ }}. This combines the columns for those 2 variables into one long vector. What we really meant by c(cut, color) is “group by both cut and color”.\nTo fix this, we need the pick() function to get R to see {{ group_var }} as a list of separate variables (like the way select() works).\n\ngroup_means &lt;- function(df, group_var, mean_var) {\n    df %&gt;%\n        group_by(pick({{ group_var }})) %&gt;%\n        summarize(mean = mean({{ mean_var }}))\n}\n\nPair programming exercise: Partner with the person next to you again. Whoever was driver most recently should start as navigator. Switch for the second exercise.\nExercise: Create a new version of dplyr::count() that also shows proportions instead of just sample sizes. The function should be able to handle counting by multiple variables. Test your function with two different sets of arguments using the diamonds dataset.\n\n\nSolution\n\n\ncount_prop &lt;- function(df, count_vars) {\n    df %&gt;%\n        count(pick({{ count_vars }})) %&gt;%\n        mutate(prop = n/sum(n))\n}\n\ncount_prop(diamonds, count_vars = cut)\n\n# A tibble: 5 × 3\n  cut           n   prop\n  &lt;ord&gt;     &lt;int&gt;  &lt;dbl&gt;\n1 Fair       1610 0.0298\n2 Good       4906 0.0910\n3 Very Good 12082 0.224 \n4 Premium   13791 0.256 \n5 Ideal     21551 0.400 \n\ncount_prop(diamonds, count_vars = c(cut, color))\n\n# A tibble: 35 × 4\n   cut   color     n    prop\n   &lt;ord&gt; &lt;ord&gt; &lt;int&gt;   &lt;dbl&gt;\n 1 Fair  D       163 0.00302\n 2 Fair  E       224 0.00415\n 3 Fair  F       312 0.00578\n 4 Fair  G       314 0.00582\n 5 Fair  H       303 0.00562\n 6 Fair  I       175 0.00324\n 7 Fair  J       119 0.00221\n 8 Good  D       662 0.0123 \n 9 Good  E       933 0.0173 \n10 Good  F       909 0.0169 \n# ℹ 25 more rows\n\n\n\nExercise: Create a function that creates a scatterplot from a user-supplied dataset with user-supplied x and y variables. The plot should also show a curvy smoothing line in blue, and a linear smoothing line in red. Test your function using the diamonds dataset.\n\n\nSolution\n\n\nscatter_with_smooths &lt;- function(df, x, y) {\n    ggplot(df, aes(x = {{ x }}, y = {{ y }})) +\n        geom_point() +\n        geom_smooth(color = \"blue\") +\n        geom_smooth(method = \"lm\", color = \"red\")\n}\n\nscatter_with_smooths(diamonds, x = carat, y = price)\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nStop to reflect\n\n\n\nIn your Process and Reflection Log write a few observations about pair programming today. In terms of learning and the community aspects of the paired work, what went well, and what could go better? Why?"
  },
  {
    "objectID": "09-iteration.html",
    "href": "09-iteration.html",
    "title": "Loops and iteration",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "09-iteration.html#for-loops",
    "href": "09-iteration.html#for-loops",
    "title": "Loops and iteration",
    "section": "for loops",
    "text": "for loops\n\nfor (i in 1:10) {\n    print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n[1] 7\n[1] 8\n[1] 9\n[1] 10\n\n\nThe following for loops all have the same behavior.\nWe don’t have to use a numerical indexing variable to iterate:\n\ngroups &lt;- c(\"group1\", \"group2\", \"group3\")\nfor (g in groups) {\n    print(g)\n}\n\n[1] \"group1\"\n[1] \"group2\"\n[1] \"group3\"\n\n\nThe single square brackets [i] get the ith element of a vector.\n\nfor (i in 1:3) {\n    print(groups[i])\n}\n\n[1] \"group1\"\n[1] \"group2\"\n[1] \"group3\"\n\n\nThe seq_along() function generates an integer sequence from 1 to the length of the vector supplied. A nice feature of seq_along() is that it generates an empty iteration vector if the vector you’re iterating over itself has length 0.\n\nseq_along(groups)\n\n[1] 1 2 3\n\nno_groups &lt;- c()\nseq_along(no_groups)\n\ninteger(0)\n\nfor (i in seq_along(groups)) {\n    print(groups[i])\n}\n\n[1] \"group1\"\n[1] \"group2\"\n[1] \"group3\"\n\n\nOften we’ll want to store output created during a for loop. Let’s see how we can fit linear regression models to subsets of data and store the results.\n\ndata(diamonds)\n\n# Fit models of price vs. carat separately for each value of cut\nunique_cuts &lt;- diamonds %&gt;% pull(cut) %&gt;% levels()\nlin_mod_results &lt;- vector(mode = \"list\", length = length(unique_cuts))\n\nfor (i in seq_along(unique_cuts)) {\n    this_cut &lt;- unique_cuts[i]\n    diamonds_sub &lt;- diamonds %&gt;%\n        filter(cut==this_cut)\n    # The double square brackets [[i]] accesses the ith element of a list\n    lin_mod_results[[i]] &lt;- lm(price ~ carat, data = diamonds_sub)\n}"
  },
  {
    "objectID": "09-iteration.html#purrr",
    "href": "09-iteration.html#purrr",
    "title": "Loops and iteration",
    "section": "purrr",
    "text": "purrr\nThe purrr package contains general purpose functions for iteration. Let’s take a look the function reference.\nThe map() family of functions applies a given function (f in the image below) to each of the elements of a vector or list. A data frame is a special type of list. (We’ll talk more about lists later.)\n\n\n\n\n\n\nmap() returns a list\nmap_chr() returns a character vector\nmap_lgl() returns a logical vector\nmap_int() returns an integer vector\nmap_dbl() returns a numeric vector\nmap_vec() returns a vector of a different (non-atomic) type (like dates)\n\nThe examples below show how map() iterates over each variable of a data frame to apply a function to that variable. In the picture above, we can view each of the horizontal rectangles as a variable in a data frame.\n\n# Because map_chr expects the supplied function to give a single string, we get an error\n# because the 3 factors (cut, color, and clarity) have both the \"factor\" and \"ordered\" class\nmap_chr(diamonds, class)\n\nError in `map_chr()`:\nℹ In index: 2.\nℹ With name: cut.\nCaused by error:\n! Result must be length 1, not 2.\n\n# But map() has no such expectations\nmap(diamonds, class)\n\n$carat\n[1] \"numeric\"\n\n$cut\n[1] \"ordered\" \"factor\" \n\n$color\n[1] \"ordered\" \"factor\" \n\n$clarity\n[1] \"ordered\" \"factor\" \n\n$depth\n[1] \"numeric\"\n\n$table\n[1] \"numeric\"\n\n$price\n[1] \"integer\"\n\n$x\n[1] \"numeric\"\n\n$y\n[1] \"numeric\"\n\n$z\n[1] \"numeric\"\n\nmap(diamonds %&gt;% select(where(is.numeric)), mean)\n\n$carat\n[1] 0.7979397\n\n$depth\n[1] 61.7494\n\n$table\n[1] 57.45718\n\n$price\n[1] 3932.8\n\n$x\n[1] 5.731157\n\n$y\n[1] 5.734526\n\n$z\n[1] 3.538734\n\nmap_int(diamonds %&gt;% select(where(is.numeric)), mean) # map_int gives an error because the result of mean() is a double (not an integer)\n\nError in `map_int()`:\nℹ In index: 1.\nℹ With name: carat.\nCaused by error:\n! Can't coerce from a number to an integer vector.\n\nmap_dbl(diamonds %&gt;% select(where(is.numeric)), mean)\n\n       carat        depth        table        price            x            y \n   0.7979397   61.7494049   57.4571839 3932.7997219    5.7311572    5.7345260 \n           z \n   3.5387338 \n\nmap(diamonds %&gt;% select(!where(is.numeric)), n_distinct)\n\n$cut\n[1] 5\n\n$color\n[1] 7\n\n$clarity\n[1] 8\n\nmap_int(diamonds %&gt;% select(!where(is.numeric)), n_distinct)\n\n    cut   color clarity \n      5       7       8 \n\n\npurrr also offers the pmap() family of functions that take multiple inputs and loops over them simultaneously:\n\n\n\n\n\n\ndf &lt;- tibble(\n    string = c(\"apple\", \"banana\", \"cherry\"),\n    pattern = c(\"p\", \"n\", \"h\"),\n    replacement = c(\"P\", \"N\", \"H\")\n)\n\npmap(df, str_replace_all)\n\n[[1]]\n[1] \"aPPle\"\n\n[[2]]\n[1] \"baNaNa\"\n\n[[3]]\n[1] \"cHerry\"\n\npmap_chr(df, str_replace_all)\n\n[1] \"aPPle\"  \"baNaNa\" \"cHerry\"\n\n\nExercise: Create your own small examples that show how pmap works with str_remove() and str_sub."
  },
  {
    "objectID": "09-iteration.html#application-exercise",
    "href": "09-iteration.html#application-exercise",
    "title": "Loops and iteration",
    "section": "Application exercise",
    "text": "Application exercise\n\n\n\n\n\n\nReminder to reflect\n\n\n\nAs you work through this application exercise, make note: what is challenging? What feels comfortable? What insights do you gain from collaborating with others? What ideas/strategies do you want to remember going forward?\n\n\nGoal: In the diamonds dataset, we want to understand the relationship between price and size (carat). We want to explore variation along two choices:\n\nThe variables included in the model. We’ll explore 3 sets of variables:\n\nNo further variables (just price and carat)\nAdjusting for cut\nAdjusting for cut and clarity\nAdjusting for cut, clarity, and color\n\nWhether or not to remove outliers in the carat variable. We’ll define outliers as cases whose carat is over 3 SDs away from the mean.\n\nExercise 1: Use crossing() to create the data frame of argument combinations for our analyses. Note that you can create a list of formula objects in R with c(y ~ x1, y ~ x1 + x2).\n\n\nSolution\n\n\ndf_arg_combos &lt;- crossing(\n    mod_formula = c(price ~ carat, price ~ carat + cut,  price ~ carat + cut + clarity,  price ~ carat + cut + clarity + color),\n    remove_outliers = c(TRUE, FALSE)\n)\ndf_arg_combos\n\n# A tibble: 8 × 2\n  mod_formula remove_outliers\n  &lt;list&gt;      &lt;lgl&gt;          \n1 &lt;formula&gt;   FALSE          \n2 &lt;formula&gt;   TRUE           \n3 &lt;formula&gt;   FALSE          \n4 &lt;formula&gt;   TRUE           \n5 &lt;formula&gt;   FALSE          \n6 &lt;formula&gt;   TRUE           \n7 &lt;formula&gt;   FALSE          \n8 &lt;formula&gt;   TRUE           \n\n\n\nExercise 2: Write a function that removes outliers in a dataset. The user should be able to supply the dataset, the variable to remove outliers in, and a threshold on the number of SDs away from the mean used to define outliers.\n\n\nSolution\n\n\nremove_outliers &lt;- function(df, what_var, sd_thresh) {\n    df %&gt;% \n        mutate(zscore = ({{ what_var }} - mean({{ what_var}}, na.rm = TRUE))/sd({{ what_var }}, na.rm = TRUE)) %&gt;%\n        filter(zscore &lt;= sd_thresh)\n}\n\n\nExercise 3: Write a function that implements the analysis versions specifically for the diamonds dataset. The user will not specify the dataset as an argument but will input the model formula and whether or not to remove outliers (cases whose carat is over 3 SDs away from the mean).\n\n\nSolution\n\n\nfit_model &lt;- function(mod_formula, remove_outliers) {\n    if (remove_outliers) {\n        diamonds_clean &lt;- remove_outliers(diamonds, what_var = carat, sd_thresh = 3)\n    } else {\n        diamonds_clean &lt;- diamonds\n    }\n    \n    lm(mod_formula, data = diamonds_clean)\n}\n\n\nExercise 4: Write a for loop that stores the fitted linear models from all versions of the analysis.\nNote that you can pull out the contents of a single data frame column in many ways. For a data frame df with a variable named x:\n\ndf$x\ndf %&gt;% pull(x)\ndf[[\"x\"]]\n\n\n\nSolution\n\n\nlin_mod_res_for &lt;- vector(mode = \"list\", length = nrow(df_arg_combos))\n\nfor (i in seq_along(lin_mod_res_for)) {\n    this_formula &lt;- df_arg_combos$mod_formula[[i]] # Double [[ for the **list** of formulas\n    this_remove_outliers &lt;- df_arg_combos$remove_outliers[i] # Single [ for the **atomic vector** of logicals\n    lin_mod_res_for[[i]] &lt;- fit_model(\n        mod_formula = this_formula,\n        remove_outliers = this_remove_outliers\n    )\n}\n\n\nExercise 5: Use pmap() from purrr to replicate what you did with the for loop.\n\n\nSolution\n\n\nlin_mod_res_pmap &lt;- pmap(df_arg_combos, fit_model)"
  },
  {
    "objectID": "10-apis.html",
    "href": "10-apis.html",
    "title": "Data acquisition: APIs",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nExplain what an API is\nSet up an API key for a public API\nDevelop comfort in using a wrapper package or URL-method of calling a web API\nRecognize the structure in a URL for a web API and adjust for your purposes\nExplore and subset complex nested lists\n\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\napis\n\ncode\n\n10-apis.qmd"
  },
  {
    "objectID": "10-apis.html#wrapper-packages",
    "href": "10-apis.html#wrapper-packages",
    "title": "Data acquisition: APIs",
    "section": "Wrapper packages",
    "text": "Wrapper packages\nExtra resources:\n\nNY Times API\nNY Times Blog post announcing the API\nWorking with the NY Times API in R\nnytimes pacakge for accessing the NY Times’ APIs from R\nVideo showing how to use the NY Times API\nrOpenSci has a good collection of wrapper packages\n\nIn R, it is easiest to use Web APIs through a wrapper package, an R package written specifically for a particular Web API. The R development community has already contributed wrapper packages for most large Web APIs. To find a wrapper package, search the web for “R Package” and the name of the website. For example, a search for “R Reddit Package” returns RedditExtractor and a search for “R Weather.com Package” surfaces weatherData.\nThis activity will build on the New York Times Web API, which provides access to news articles, movie reviews, book reviews, and many other data. Our activity will specifically focus on the Article Search API, which finds information about news articles that contain a particular word or phrase.\nWe will use the nytimes wrapper package that provides functions for some (but not all) of the NYTimes APIs. You can install the package by running the following in the Console:\n\ninstall.packages(\"devtools\")\ndevtools::install_github(\"mkearney/nytimes\")\n\nNext, take a look at the Article Search API example on the package website to get a sense of the syntax.\nExercise: What do you think the nyt_search() function below does? How does it communicate with the NY Times? Where is the data about articles stored?\n\nres &lt;- nyt_search(q = \"gamergate\", n = 20, end_date = \"20150101\")\n\nTo get started with the NY Times API, you must register and get an authentication key. Signup only takes a few seconds, and it lets the New York Times make sure nobody abuses their API for commercial purposes. It also rate limits their API and ensures programs don’t make too many requests per day. For the NY Times API, this limit is 1000 calls per day. Be aware that most APIs do have rate limits — especially for their free tiers.\nOnce you have signed up, verified your email, log back in to https://developer.nytimes.com. Under your email address, click on Apps and Create a new App (call it First API) and enable Article Search API, then press Save. This creates an authentication key, which is a 32 digit string with numbers and the letters a-e.\nStore this in a variable as follows (this is just an example ID, not an actual one):\n\n# Change value to your personal API key\ntimes_key &lt;- \"c935b213b2dc1218050eec976283dbbd\"\n\nNow, let’s use the key to issue our first API call. We’ll adapt the code we see in the vignette to do what we need.\n\nlibrary(nytimes)\n\n# Tell nytimes what our API key is\nSys.setenv(NYTIMES_KEY = times_key)\n\n# Issue our first API call\nres &lt;- nyt_search(q = \"gamergate\", n = 20, end_date = \"20150101\")\n\n# Convert response object to data frame\nres &lt;- as.data.frame(res)\n\nSomething magical just happened. Your computer sent a message to the New York Times and asked for information about 20 articles about Gamergate starting at January 1, 2015 and going backwards in time. Thousands of public Web APIs allow your computer to tap into almost any piece of public digital information on the web.\nLet’s take a peek at the structure of the results:\n\ncolnames(res)\n\n [1] \"id\"               \"abstract\"         \"byline\"           \"document_type\"   \n [5] \"headline\"         \"keywords\"         \"lead_paragraph\"   \"multimedia\"      \n [9] \"news_desk\"        \"print_page\"       \"print_section\"    \"pub_date\"        \n[13] \"section_name\"     \"snippet\"          \"source\"           \"subsection_name\" \n[17] \"type_of_material\" \"uri\"              \"web_url\"          \"word_count\"      \n\nhead(res)\n\n                                                      id\n1     nyt://article/08765e5b-8d12-54dd-be58-39c6d33125c1\n2     nyt://article/5e97a537-4e5d-51b4-9571-736913a6e5c4\n3     nyt://article/ebad4be5-8e52-5490-a3bb-f5d8f684b902\n4 nyt://interactive/26986d5d-2854-5484-86b8-04dbbfea0b27\n5     nyt://article/fe201e9b-ea3b-5e9c-bb5a-ef4b0bbd30c4\n6     nyt://article/7574b532-e51f-5695-80aa-a5b24ee4e7a2\n                                                                                                                                                                     abstract\n1                                                           A service lets a person monitor his or her Facebook or Twitter account, for more awareness of one’s online image.\n2 Get recommendations from New York Times reporters and editors, highlighting great stories from around the web. Today, great reads from Dean Baquet, Susan Chira and others.\n3                                                                                                                                The answers for our ninth annual Op-Ed quiz.\n4                                                                                                   Highlights from the year, as chosen by the editors of The New York Times.\n5                                                                                             The women’s-magazine editor on the Internet, feminism and reading the comments.\n6                                                               Social media companies are often reluctant to become arbiters of appropriate and inappropriate speech online.\n                      byline document_type\n1           By Farhad Manjoo       article\n2      By The New York Times       article\n3              By Ben Schott       article\n4                       &lt;NA&gt;    multimedia\n5 Interview by Susan Dominus       article\n6           By Jenna Wortham       article\n                                                            headline\n1          ThinkUp Helps the Social Network User See the Online Self\n2 What We’re Reading: Great Times Reads of 2014 From Our Top Editors\n3                         2014: The Year in Questions – Quiz Answers\n4                                                   The Best of 2014\n5           Jane Pratt on Why Writing for Young Women Never Gets Old\n6                  Trying to Swim in a Sea of Social Media Invective\n                                                                                                                                                                keywords\n1                                                                                                 Social Media+ThinkUp LLC+Facebook Inc+Twitter+Dash, Anil+Trapani, Gina\n2 News and News Media+Newspapers+Baquet, Dean+Barry, Ellen+Chira, Susan+Duenes, Steve+Fisher, Ian+Lacey, Marc+Slackman, Michael+New York Times+AFRICA+Delhi (India)+Iraq\n3                                                                                                                                                                   &lt;NA&gt;\n4                                                                                                                                                                   &lt;NA&gt;\n5                                                                                                                       Pratt, Jane+xoJane.com+Women and Girls+Magazines\n6                                                                               Computers and the Internet+Cyberharassment+Social Media+Facebook Inc+Twitter+Yik Yak Inc\n                                                                                                                                                                                                                                                                                                                                                                                                                       lead_paragraph\n1 Anil Dash, a longtime tech entrepreneur and blogger, was recently studying a list of the top words he had used on Twitter over the course of a month during the fall. Mr. Dash has half a million followers on Twitter, and like a lot of people in tech and media circles, he uses the social network to chat with colleagues, to pontificate about technology, politics and pop culture, and to participate in a lot of in-jokes.\n2                                                                                                                                                                                                                                                           Get recommendations from New York Times reporters and editors, highlighting great stories from around the web. What We’re Reading emails are sent twice a week. Sign up »\n3                                                                                                                                                                                                                                                                                                                                                                                                                         1. B – Uber\n4                                                                                                                                                                                                                                                                                                                                                           Highlights from the year, as chosen by the editors of The New York Times.\n5                                                                                                                                                                                                                                                                                                                                             The editor talks with Susan Dominus about navigating the pitfalls of online publishing.\n6                                                                                                                                     Over the last few months, I’ve watched friends and colleagues endure endless harassment on Twitter. Strangers have hurled offensive, racist names and gendered insults, relentlessly and with little fear of consequence. I’ve come across blog posts that capture similarly awful experiences.\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       multimedia\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          images/2015/01/01/technology/personaltech/01state-illo/01state-illo-thumbWide.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoThumb.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-mediumThreeByTwo210.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-mediumThreeByTwo225.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-mediumThreeByTwo440.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-facebookJumbo.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-miniMoth.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-articleLarge.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-blog480.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-blog427.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-tmagArticle.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-jumbo.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-blog225.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-master180.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-popup.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-blog533.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-tmagSF.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-slide.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-superJumbo.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-master495.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-master315.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-square320.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-filmstrip.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-moth.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-mediumSquare149.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-articleInline.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-hpSmall.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-blogSmallInline.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-mediumFlexible177.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-sfSpan.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-largeHorizontal375.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-hpLarge.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-largeWidescreen573.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSmall.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoHpMedium.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine600.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine540.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine495.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine390.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine480.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine310.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine225.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine96.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-videoSixteenByNine150.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-thumbStandard.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-thumbLarge.jpg+images/2015/01/01/technology/personaltech/01state-illo/01state-illo-blogSmallThumb.jpg\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          images/2014/12/31/business/wwrn-ebola/wwrn-ebola-thumbWide.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoThumb.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoLarge.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-mediumThreeByTwo210.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-mediumThreeByTwo225.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-mediumThreeByTwo440.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-facebookJumbo.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoFifteenBySeven1305.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoFifteenBySeven2610.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-miniMoth.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-windowsTile336H.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-articleLarge.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-blog480.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-blog427.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-tmagArticle.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-jumbo.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-blog225.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-master675.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-master180.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-popup.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-blog533.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-tmagSF.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-slide.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-superJumbo.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-master1050.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-master495.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-master315.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-square320.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-filmstrip.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-square640.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-moth.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-mediumSquare149.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-articleInline.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-hpSmall.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-blogSmallInline.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-mediumFlexible177.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-sfSpan.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-largeHorizontal375.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-hpLarge.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-largeWidescreen573.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-largeWidescreen1050.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSmall.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoHpMedium.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine600.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine540.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine495.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine390.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine480.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine310.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine225.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine96.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine768.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine150.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-videoSixteenByNine1050.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-thumbStandard.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-thumbLarge.jpg+images/2014/12/31/business/wwrn-ebola/wwrn-ebola-blogSmallThumb.jpg\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               images/2014/12/30/opinion/30schott/30schott-thumbWide.jpg+images/2014/12/30/opinion/30schott/30schott-videoThumb.jpg+images/2014/12/30/opinion/30schott/30schott-videoLarge.jpg+images/2014/12/30/opinion/30schott/30schott-mediumThreeByTwo210.jpg+images/2014/12/30/opinion/30schott/30schott-mediumThreeByTwo225.jpg+images/2014/12/30/opinion/30schott/30schott-mediumThreeByTwo440.jpg+images/2014/12/30/opinion/30schott/30schott-facebookJumbo.jpg+images/2014/12/30/opinion/30schott/30schott-videoFifteenBySeven1305.jpg+images/2014/12/30/opinion/30schott/30schott-miniMoth.jpg+images/2014/12/30/opinion/30schott/30schott-windowsTile336H.jpg+images/2014/12/30/opinion/30schott/30schott-articleLarge.jpg+images/2014/12/30/opinion/30schott/30schott-blog480.jpg+images/2014/12/30/opinion/30schott/30schott-blog427.jpg+images/2014/12/30/opinion/30schott/30schott-tmagArticle.jpg+images/2014/12/30/opinion/30schott/30schott-jumbo.jpg+images/2014/12/30/opinion/30schott/30schott-blog225.jpg+images/2014/12/30/opinion/30schott/30schott-master675.jpg+images/2014/12/30/opinion/30schott/30schott-master180.jpg+images/2014/12/30/opinion/30schott/30schott-popup.jpg+images/2014/12/30/opinion/30schott/30schott-blog533.jpg+images/2014/12/30/opinion/30schott/30schott-tmagSF.jpg+images/2014/12/30/opinion/30schott/30schott-slide.jpg+images/2014/12/30/opinion/30schott/30schott-superJumbo.jpg+images/2014/12/30/opinion/30schott/30schott-master1050.jpg+images/2014/12/30/opinion/30schott/30schott-master495.jpg+images/2014/12/30/opinion/30schott/30schott-master315.jpg+images/2014/12/30/opinion/30schott/30schott-square320.jpg+images/2014/12/30/opinion/30schott/30schott-filmstrip.jpg+images/2014/12/30/opinion/30schott/30schott-square640.jpg+images/2014/12/30/opinion/30schott/30schott-moth.jpg+images/2014/12/30/opinion/30schott/30schott-mediumSquare149.jpg+images/2014/12/30/opinion/30schott/30schott-articleInline.jpg+images/2014/12/30/opinion/30schott/30schott-hpSmall.jpg+images/2014/12/30/opinion/30schott/30schott-blogSmallInline.jpg+images/2014/12/30/opinion/30schott/30schott-mediumFlexible177.jpg+images/2014/12/30/opinion/30schott/30schott-sfSpan.jpg+images/2014/12/30/opinion/30schott/30schott-largeHorizontal375.jpg+images/2014/12/30/opinion/30schott/30schott-hpLarge.jpg+images/2014/12/30/opinion/30schott/30schott-largeWidescreen573.jpg+images/2014/12/30/opinion/30schott/30schott-largeWidescreen1050.jpg+images/2014/12/30/opinion/30schott/30schott-videoSmall.jpg+images/2014/12/30/opinion/30schott/30schott-videoHpMedium.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine600.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine540.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine495.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine390.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine480.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine310.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine225.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine96.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine768.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine150.jpg+images/2014/12/30/opinion/30schott/30schott-videoSixteenByNine1050.jpg+images/2014/12/30/opinion/30schott/30schott-thumbStandard.jpg+images/2014/12/30/opinion/30schott/30schott-thumbLarge.jpg+images/2014/12/30/opinion/30schott/30schott-blogSmallThumb.jpg\n4 images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-thumbWide.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoThumb.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoLarge.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-mediumThreeByTwo210.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-mediumThreeByTwo225.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-mediumThreeByTwo440.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-facebookJumbo.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-miniMoth.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-windowsTile336H.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-articleLarge.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-blog480.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-blog427.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-tmagArticle.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-jumbo.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-blog225.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-master675.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-master180.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-popup.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-blog533.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-tmagSF.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-slide.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-superJumbo.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-master495.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-master315.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-square320.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-filmstrip.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-square640.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-moth.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-mediumSquare149.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-articleInline.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-hpSmall.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-blogSmallInline.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-mediumFlexible177.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-sfSpan.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-largeHorizontal375.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-hpLarge.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-largeWidescreen573.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSmall.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoHpMedium.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine600.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine540.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine495.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine390.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine480.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine310.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine225.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine96.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine768.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-videoSixteenByNine150.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-thumbStandard.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-thumbLarge.jpg+images/2014/12/22/multimedia/the-best-of-2014-1419258019643/the-best-of-2014-1419258019643-blogSmallThumb.jpg\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     images/2014/12/21/magazine/21talk/21talk-videoSmall-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoHpMedium-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine600-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine540-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine495-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine390-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine480-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine310-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine225-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine96-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine768-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine150-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoSixteenByNine1050-v3.jpg+images/2014/12/21/magazine/21talk/21talk-hpLarge-v3.jpg+images/2014/12/21/magazine/21talk/21talk-largeWidescreen573-v3.jpg+images/2014/12/21/magazine/21talk/21talk-largeWidescreen1050-v3.jpg+images/2014/12/21/magazine/21talk/21talk-articleLarge-v2.jpg+images/2014/12/21/magazine/21talk/21talk-blog480-v2.jpg+images/2014/12/21/magazine/21talk/21talk-blog427-v2.jpg+images/2014/12/21/magazine/21talk/21talk-tmagArticle-v2.jpg+images/2014/12/21/magazine/21talk/21talk-jumbo-v2.jpg+images/2014/12/21/magazine/21talk/21talk-blog225-v2.jpg+images/2014/12/21/magazine/21talk/21talk-master675-v2.jpg+images/2014/12/21/magazine/21talk/21talk-master180-v2.jpg+images/2014/12/21/magazine/21talk/21talk-popup-v2.jpg+images/2014/12/21/magazine/21talk/21talk-blog533-v2.jpg+images/2014/12/21/magazine/21talk/21talk-tmagSF-v2.jpg+images/2014/12/21/magazine/21talk/21talk-slide-v2.jpg+images/2014/12/21/magazine/21talk/21talk-superJumbo-v2.jpg+images/2014/12/21/magazine/21talk/21talk-master1050-v2.jpg+images/2014/12/21/magazine/21talk/21talk-master495-v2.jpg+images/2014/12/21/magazine/21talk/21talk-master315-v2.jpg+images/2014/12/21/magazine/21talk/21talk-miniMoth-v3.jpg+images/2014/12/21/magazine/21talk/21talk-windowsTile336H-v3.jpg+images/2014/12/21/magazine/21talk/21talk-sfSpan.jpg+images/2014/12/21/magazine/21talk/21talk-largeHorizontal375.jpg+images/2014/12/21/magazine/21talk/21talk-verticalTwoByThree735-v2.jpg+images/2014/12/21/magazine/21talk/21talk-square320.jpg+images/2014/12/21/magazine/21talk/21talk-filmstrip.jpg+images/2014/12/21/magazine/21talk/21talk-square640.jpg+images/2014/12/21/magazine/21talk/21talk-moth.jpg+images/2014/12/21/magazine/21talk/21talk-mediumSquare149.jpg+images/2014/12/21/magazine/21talk/21talk-articleInline-v2.jpg+images/2014/12/21/magazine/21talk/21talk-hpSmall-v2.jpg+images/2014/12/21/magazine/21talk/21talk-blogSmallInline-v2.jpg+images/2014/12/21/magazine/21talk/21talk-mediumFlexible177-v2.jpg+images/2014/12/21/magazine/21talk/21talk-facebookJumbo-v2.jpg+images/2014/12/21/magazine/21talk/21talk-thumbStandard.jpg+images/2014/12/21/magazine/21talk/21talk-thumbLarge.jpg+images/2014/12/21/magazine/21talk/21talk-blogSmallThumb.jpg+images/2014/12/21/magazine/21talk/21talk-thumbWide-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoThumb-v3.jpg+images/2014/12/21/magazine/21talk/21talk-videoLarge-v3.jpg+images/2014/12/21/magazine/21talk/21talk-mediumThreeByTwo210-v3.jpg+images/2014/12/21/magazine/21talk/21talk-mediumThreeByTwo225-v3.jpg+images/2014/12/21/magazine/21talk/21talk-mediumThreeByTwo440-v3.jpg+images/2014/12/21/magazine/21talk/21talk-mediumThreeByTwo252-v2.jpg+images/2014/12/21/magazine/21talk/21talk-mediumThreeByTwo378-v2.jpg+images/2014/12/21/magazine/21talk/21talk-watch308-v2.jpg+images/2014/12/21/magazine/21talk/21talk-watch268-v2.jpg\n6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    images/2014/12/14/business/14-BITS/14-BITS-thumbWide.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoThumb.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoLarge.jpg+images/2014/12/14/business/14-BITS/14-BITS-mediumThreeByTwo210.jpg+images/2014/12/14/business/14-BITS/14-BITS-mediumThreeByTwo225.jpg+images/2014/12/14/business/14-BITS/14-BITS-mediumThreeByTwo440.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoFifteenBySeven1305.jpg+images/2014/12/14/business/14-BITS/14-BITS-miniMoth.jpg+images/2014/12/14/business/14-BITS/14-BITS-windowsTile336H.jpg+images/2014/12/14/business/14-BITS/14-BITS-articleLarge.jpg+images/2014/12/14/business/14-BITS/14-BITS-blog480.jpg+images/2014/12/14/business/14-BITS/14-BITS-blog427.jpg+images/2014/12/14/business/14-BITS/14-BITS-tmagArticle.jpg+images/2014/12/14/business/14-BITS/14-BITS-jumbo.jpg+images/2014/12/14/business/14-BITS/14-BITS-blog225.jpg+images/2014/12/14/business/14-BITS/14-BITS-master675.jpg+images/2014/12/14/business/14-BITS/14-BITS-master180.jpg+images/2014/12/14/business/14-BITS/14-BITS-popup.jpg+images/2014/12/14/business/14-BITS/14-BITS-blog533.jpg+images/2014/12/14/business/14-BITS/14-BITS-tmagSF.jpg+images/2014/12/14/business/14-BITS/14-BITS-slide.jpg+images/2014/12/14/business/14-BITS/14-BITS-superJumbo.jpg+images/2014/12/14/business/14-BITS/14-BITS-master1050.jpg+images/2014/12/14/business/14-BITS/14-BITS-master495.jpg+images/2014/12/14/business/14-BITS/14-BITS-master315.jpg+images/2014/12/14/business/14-BITS/14-BITS-square320.jpg+images/2014/12/14/business/14-BITS/14-BITS-filmstrip.jpg+images/2014/12/14/business/14-BITS/14-BITS-square640.jpg+images/2014/12/14/business/14-BITS/14-BITS-moth.jpg+images/2014/12/14/business/14-BITS/14-BITS-mediumSquare149.jpg+images/2014/12/14/business/14-BITS/14-BITS-articleInline.jpg+images/2014/12/14/business/14-BITS/14-BITS-hpSmall.jpg+images/2014/12/14/business/14-BITS/14-BITS-blogSmallInline.jpg+images/2014/12/14/business/14-BITS/14-BITS-mediumFlexible177.jpg+images/2014/12/14/business/14-BITS/14-BITS-sfSpan.jpg+images/2014/12/14/business/14-BITS/14-BITS-largeHorizontal375.jpg+images/2014/12/14/business/14-BITS/14-BITS-hpLarge.jpg+images/2014/12/14/business/14-BITS/14-BITS-largeWidescreen573.jpg+images/2014/12/14/business/14-BITS/14-BITS-largeWidescreen1050.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSmall.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoHpMedium.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine600.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine540.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine495.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine390.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine480.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine310.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine225.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine96.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine768.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine150.jpg+images/2014/12/14/business/14-BITS/14-BITS-videoSixteenByNine1050.jpg+images/2014/12/14/business/14-BITS/14-BITS-thumbStandard.jpg+images/2014/12/14/business/14-BITS/14-BITS-thumbLarge.jpg+images/2014/12/14/business/14-BITS/14-BITS-blogSmallThumb.jpg\n          news_desk print_page print_section            pub_date\n1          Business          1             B 2014-12-31 22:31:54\n2                         &lt;NA&gt;          &lt;NA&gt; 2014-12-30 22:06:27\n3              OpEd         19             A 2014-12-29 23:20:06\n4 Multimedia/Photos       &lt;NA&gt;          &lt;NA&gt; 2014-12-22 18:25:37\n5          Magazine         14            MM 2014-12-19 15:24:37\n6          Business          4            BU 2014-12-13 17:37:26\n       section_name\n1        Technology\n2             Blogs\n3           Opinion\n4 Multimedia/Photos\n5          Magazine\n6        Technology\n                                                                                                                                                                      snippet\n1                                                           A service lets a person monitor his or her Facebook or Twitter account, for more awareness of one’s online image.\n2 Get recommendations from New York Times reporters and editors, highlighting great stories from around the web. Today, great reads from Dean Baquet, Susan Chira and others.\n3                                                                                                                                The answers for our ninth annual Op-Ed quiz.\n4                                                                                                   Highlights from the year, as chosen by the editors of The New York Times.\n5                                                                                             The women’s-magazine editor on the Internet, feminism and reading the comments.\n6                                                               Social media companies are often reluctant to become arbiters of appropriate and inappropriate speech online.\n              source subsection_name    type_of_material\n1 The New York Times   Personal Tech                News\n2 The New York Times            &lt;NA&gt;                News\n3 The New York Times            &lt;NA&gt;               Op-Ed\n4 The New York Times            &lt;NA&gt; Interactive Feature\n5 The New York Times            &lt;NA&gt;                News\n6 The New York Times            &lt;NA&gt;                News\n                                                     uri\n1     nyt://article/08765e5b-8d12-54dd-be58-39c6d33125c1\n2     nyt://article/5e97a537-4e5d-51b4-9571-736913a6e5c4\n3     nyt://article/ebad4be5-8e52-5490-a3bb-f5d8f684b902\n4 nyt://interactive/26986d5d-2854-5484-86b8-04dbbfea0b27\n5     nyt://article/fe201e9b-ea3b-5e9c-bb5a-ef4b0bbd30c4\n6     nyt://article/7574b532-e51f-5695-80aa-a5b24ee4e7a2\n                                                                                                                    web_url\n1 https://www.nytimes.com/2015/01/01/technology/personaltech/thinkup-helps-the-social-network-user-see-the-online-self.html\n2               https://news.blogs.nytimes.com/2014/12/30/what-were-reading-great-times-reads-of-2014-from-our-top-editors/\n3                                   https://www.nytimes.com/2014/12/30/opinion/2014-the-year-in-questions-quiz-answers.html\n4                                                 https://www.nytimes.com/interactive/2014/multimedia/the-best-of-2014.html\n5                 https://www.nytimes.com/2014/12/21/magazine/jane-pratt-on-why-writing-for-young-women-never-gets-old.html\n6                              https://bits.blogs.nytimes.com/2014/12/13/trying-to-swim-in-a-sea-of-social-media-invective/\n  word_count\n1       1211\n2        429\n3        588\n4          0\n5        716\n6       1236"
  },
  {
    "objectID": "10-apis.html#accessing-web-apis-directly",
    "href": "10-apis.html#accessing-web-apis-directly",
    "title": "Data acquisition: APIs",
    "section": "Accessing web APIs directly",
    "text": "Accessing web APIs directly\nWrapper packages such as nytimes provide a convenient way to interact with Web APIs. However, many Web APIs have incomplete wrapper packages, or no wrapper package at all. Fortunately, most Web APIs share a common structure that R can access relatively easily. There are two parts to each Web API:\n\nThe request: this amounts to calling a function that gets sent to a web server\n\nIn our nyt_search(q = \"gamergate\", n = 20, end_date = \"20150101\") example, the q, n, and end_date are arguments to an article search function.\n\nThe response: the web server computes the result to the function call and returns the response\n\nThe web server uses runs a search with the q, n, and end_date arguments to get the search results.\n\n\nAs mentioned earlier, a Web API call differs from a regular function call in that the request is sent over the Internet to a web server, which performs the computation and calculates the return result, which is sent back over the Internet to the original computer.\n\nWeb API requests\nFor a deeper dive, consult the following readings:\n\nUnderstanding URLs\nurltools Vignette\n\nThe request for a Web API call is usually encoded through the URL (short for uniform resource locator), the web address associated with the API’s web server. Let’s look at the URL associated with the first nytimes nyt_search example we did. Open the following URL in your browser (you should replace MY_KEY with the API key you were given earlier).\nhttp://api.nytimes.com/svc/search/v2/articlesearch.json?q=gamergate&api-key=MY_KEY\nThe text you see in the browser is the response data. We’ll talk more about that in a bit. Right now, let’s focus on the structure of the URL. You can see that it has a few parts:\n\nhttp:// — The scheme, which tells your browser or program how to communicate with the web server. This will typically be either http: or https:.\napi.nytimes.com — The hostname, which is a name that identifies the web server that will process the request.\n/svc/search/v2/articlesearch.json — The path, which tells the web server what function you would like to call.\n?q=gamergate&api-key=MY_KEY — The query parameters, which provide the parameters for the function you would like to call. Note that the query can be thought of as a table, where each row has a key and a value (known as a key-value pair). In this case, the first row has key q and value gamergate and the second row has value MY_KEY. The query parameters are preceded by a ?. Rows in the key-value table are separated by &, and individual key-value pairs are separated by an =.\n\n\n\n\nkey\nvalue\n\n\n\n\nq\ngamergate\n\n\napi-key\nMY_KEY\n\n\n\nTypically, each of these URL components will be specified in the API documentation. Sometimes, the scheme, hostname, and path (http://api.nytimes.com/svc/search/v2/articlesearch.json) will be referred to as the endpoint for the API call.\nWe will use the urltools package to build up a full URL from its parts. Start by creating a string with the endpoint. Then add the parameters one by one using param_set and url_encode:\n\nlibrary(urltools)\n\nurl &lt;- \"http://api.nytimes.com/svc/search/v2/articlesearch.json\"\nurl &lt;- param_set(url, \"q\", url_encode(\"gamergate\"))\nurl &lt;- param_set(url, \"api-key\", url_encode(times_key))\nurl\n\n[1] \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=gamergate&api-key=xy9oy1eczTOTGAFjAfnrmZJO2mpSPvXQ\"\n\n\nCopy and paste the resulting URL into your browser to see what the NY Times response looks like!\nYou may be wondering why we need to use param_set() and url_encode() instead of writing the full URL by hand. The following exercise will illustrate why we need to be careful.\nPair programming exercise: Work through the two exercises below in pairs (or triples as needed). Whoever has visited more countries in their lifetime will be driver first.\nExercise: Write a function that generalizes our URL construction steps above so that the user can input any search query (q).\n\nUse your function to create a URL that finds articles related to Ferris Bueller's Day Off (note the apostrophe). What is interesting about how the title appears in the URL?\nRepeat for the query Penn & Teller (make sure you use the punctuation mark &). What do you notice?\n\nTake a look at the Wikipedia page describing percent encoding. Explain how the process works in your own words.\n\n\nSolution\n\n\n# Note that this function uses a times_key object that has already been created\n# Another choice is to allow input of the API key as an additional argument\ncreate_url &lt;- function(query) {\n    url &lt;- \"http://api.nytimes.com/svc/search/v2/articlesearch.json\"\n    url &lt;- param_set(url, \"q\", url_encode(query))\n    url &lt;- param_set(url, \"api-key\", url_encode(times_key))\n    url\n}\n\ncreate_url(query = \"Ferris Bueller's Day Off\")\n\n[1] \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Ferris%20Bueller%27s%20Day%20Off&api-key=xy9oy1eczTOTGAFjAfnrmZJO2mpSPvXQ\"\n\ncreate_url(query = \"Penn & Teller\")\n\n[1] \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Penn%20%26%20Teller&api-key=xy9oy1eczTOTGAFjAfnrmZJO2mpSPvXQ\"\n\n\n\nExercise: Write out the pseudocode for a function that takes a data frame of arbitrarily many key-value pairs and constructs the URL. Then write the function itself. Example data frame of key-value pairs:\n\nkey_val_pairs &lt;- tibble(\n    key = c(\"q\", \"api-key\", \"begin_date\", \"end_date\"),\n    value = c(\"economy\", \"API_KEY\", \"20230101\", \"20231001\")\n)\nkey_val_pairs\n\n# A tibble: 4 × 2\n  key        value   \n  &lt;chr&gt;      &lt;chr&gt;   \n1 q          economy \n2 api-key    API_KEY \n3 begin_date 20230101\n4 end_date   20231001\n\n\n\n\nSolution\n\n\ncreate_url_from_df &lt;- function(df) {\n    url &lt;- \"http://api.nytimes.com/svc/search/v2/articlesearch.json\"\n    for (i in 1:nrow(df)) {\n        # get the key in the ith row...and the value\n        this_key &lt;- df$key[i]\n        this_value &lt;- df$value[i]\n        url &lt;- param_set(url, this_key, url_encode(this_value))\n    }\n    url\n}\n\ncreate_url_from_df(df = key_val_pairs)\n\n[1] \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=economy&api-key=API_KEY&begin_date=20230101&end_date=20231001\"\n\n\n\n\n\nWeb API responses\nFor a deeper dive, consult the following readings:\n\nA Non-Programmer’s Introduction to JSON\nGetting Started With JSON and jsonlite\nFetching JSON data from REST APIs\n\nLet’s discuss the structure of the web response, the return value of the Web API function. Web APIs generate string responses. If you visited the earlier New York Times API link in your browser, you would be shown the string response from the New York Times web server:\n{\"status\":\"OK\",\"copyright\":\"Copyright (c) 2023 The New York Times Company. All Rights Reserved.\",\"response\":{\"docs\":[{\"abstract\":\"Who would have guessed that magic’s most recognizable buddy pair would produce the classiest reality show on television?\",\"web_url\":\"https://www.nytimes.com/2019/11/26/magazine/letter-of-recommendation-penn-teller-fool-us.html\",\"snippet\":\"Who would have guessed that magic’s most recognizable buddy pair would produce the classiest reality show on television?\",\"lead_paragraph\":\"“Penn & Teller: Fool Us” is a reality-TV competition shown on the CW, which is a broadcast network, which is something like a streaming service that’s always on. The show was recently renewed for its seventh season. The only other person I know who watches it is a skilled amateur magician and general magic geek who lives in Chicago. For him, the show is a chance to be exposed to some of the world’s greatest magicians and get an insight into their arcane techniques. For me, who doesn’t particularly like magic and has no intention of trying to do it, the show has a different appeal: It makes me a better person.\",\"print_section\":\"MM\",\"print_page\":\"24\",\"source\":\"The New York Times\",\"multimedia\":\nIf you stared very hard at the above response, you may be able to interpret it. However, it would be much easier to interact with the response in some more structured, programmatic way. The vast majority of Web APIs, including the New York Times, use a standard called JSON (Javascript Object Notation) to take data and encode it as a string.\nTo understand the structure of JSON, take the NY Times web response in your browser, and copy and paste it into this online JSON formatter. The formatter will add newlines and tabs to make the data more human-readable. You’ll see the following:\n{\n   \"status\":\"OK\",\n   \"copyright\":\"Copyright (c) 2023 The New York Times Company. All Rights Reserved.\",\n   \"response\":{  \n      \"docs\":[  \n      \n        # A HUGE piece of data, with one object for each of the result articles\n        \n      ],\n      \"meta\":{\n         \"hits\":1755,\n         \"offset\":0,\n         \"time\":51\n      }\n   }\n}     \nYou’ll notice a few things in the JSON above:\n\nStrings are enclosed in double quotes, for example \"status\" and \"OK\".\nNumbers are written plainly, like 2350 or 72.\nSome data is enclosed in square brackets [ and ]. These data containers can be thought of as R lists.\nSome data is enclosed in curly braces { and }. These data containers are called Objects. An object can be thought of as a single case or observation in a table.\n\nThe columns or variables for the observation appear as keys on the left (hits, offset, etc.).\nThe values appear after the specific key separated by a colon (2350, and 0, respectively).\n\n\nThus, we can think of the meta object above as:\n\n\n\nhits\noffset\ntime\n\n\n\n\n1755\n0\n51\n\n\n\nLet’s repeat the NY Times search for “gamergate”, but this time we will perform the Web API call by hand instead of using the nytimes wrapper package. We will use the jsonlite package to retrieve the response from the web server and turn the string response into an R object. The fromJson function sends our request out over and across the web to the NY Times web server, retrieves it, and turns it from a JSON-formatted string into R data.\n\nlibrary(jsonlite)\n\n\nAttaching package: 'jsonlite'\n\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n# Rebuild the URL\nurl &lt;- \"http://api.nytimes.com/svc/search/v2/articlesearch.json\"\nurl &lt;- param_set(url, \"q\", url_encode(\"gamergate\"))\nurl &lt;- param_set(url, \"api-key\", url_encode(times_key))\n\n# Send the request to the webserver over the Internet and\n# retrieve the JSON response. Turn the JSON response into an\n# R Object.\ngamergate_json &lt;- fromJSON(url)\n\ngamergate_json is a list. A list is a useful structure for storing elements of different types. Data frames are special cases of lists where each list element has the same length (but where the list elements have different classes).\nLists are a very flexible data structure but can be very confusing because list elements can be lists themselves!\nWe can explore the structure of a list in two ways:\n\nEntering View(list_object) in the Console. The triangle buttons on the left allow you to toggle dropdowns to explore list elements.\nUsing the str() (structure) function.\n\nExercise: Explore the information in the gamergate_json using both View() and str(). When using str(), look up the documentation and experiment with the max.level and vec.len arguments to control how the output is displayed. Look back and forth between the View() and str() output to find correspondences in how object structure is displayed.\n\nWe can access elements of a list in three ways:\n\nBy position with double square brackets [[:\n\n\n# This gets the first element of the list\ngamergate_json[[1]]\n\n[1] \"OK\"\n\n\n\nBy name with double square brackets [[: (note that list elements are not always named, so this won’t always be possible)\n\n\n# Accessing by name directly\ngamergate_json[[\"status\"]]\n\n[1] \"OK\"\n\n# Accessing via a variable\nwhich_element &lt;- \"status\"\ngamergate_json[[which_element]]\n\n[1] \"OK\"\n\n\n\nBy name with a dollar sign $: (Helpful tip: For this mode of access, RStudio allows tab completion to fill in the full name)\n\n\ngamergate_json$status\n\n[1] \"OK\"\n\n\nWe can retrieve these nested attributes by sequentially accessing the object keys from the outside in. For example, the meta element would be accessed as follows:\n\ngamergate_json$response$meta\n\n$hits\n[1] 142\n\n$offset\n[1] 0\n\n$time\n[1] 20\n\n\nExercise: In the gamergate_json object, retrieve the data associated with:\n\nthe copyright key\nthe number of hits (number of search results) within the meta object\nthe abstracts and leading paragraphs of the articles found in the search\n\n\n\nSolution\n\n\ngamergate_json$copyright\n\n[1] \"Copyright (c) 2023 The New York Times Company. All Rights Reserved.\"\n\ngamergate_json$response$meta$hits\n\n[1] 142\n\ngamergate_json$response$docs$abstract\n\n [1] \"Here’s what you need to know.\"                                                                                                                                                                                   \n [2] \"Intel’s decision added to a controversy that has focused attention on the treatment of women in the games business and the power of online mobs.\"                                                                \n [3] \"The atmosphere has become so toxic that critics and developers are urging big companies in the $70-billion-a-year video game industry to do more to stop it.\"                                                    \n [4] \"The precursors to Gamergate were disinformation campaigns targeting women of color.\"                                                                                                                             \n [5] \"How online mobs harassed the targets of Gamergate, Christine Blasey Ford and me.\"                                                                                                                                \n [6] \"The legacy of Gamergate.\"                                                                                                                                                                                        \n [7] \"The powerful lesson of a 5-year-old harassment campaign: How to wage a post-truth information war.\"                                                                                                              \n [8] \"If their bids at motherhood fail, they can then regrow their brains.\"                                                                                                                                            \n [9] \"A day after SXSW Interactive canceled two video game panels related to the so-called GamerGate movement over threats of violence, two digital media organizations threatened to pull out of the tech conference.\"\n[10] \"The future of video games is threatened by the ugly culture around them.\"                                                                                                                                        \n\ngamergate_json$response$docs$lead_paragraph\n\n [1] \"(Want to get this briefing by email? Here’s the sign-up.)\"                                                                                                                                                                                                                                                                                \n [2] \"For a little more than a month, a firestorm over sexism and journalistic ethics has roiled the video game community, culminating in an orchestrated campaign to pressure companies into pulling their advertisements from game sites. \"                                                                                                   \n [3] \"Anita Sarkeesian, a feminist cultural critic, has for months received death and rape threats from opponents of her recent work challenging the stereotypes of women in video games. Bomb threats for her public talks are now routine. One detractor created a game in which players can click their mouse to punch an image of her face.\"\n [4] \"The precursors to Gamergate were disinformation campaigns targeting women of color.\"                                                                                                                                                                                                                                                      \n [5] \"How online mobs harassed the targets of Gamergate, Christine Blasey Ford and me.\"                                                                                                                                                                                                                                                         \n [6] \"The legacy of Gamergate.\"                                                                                                                                                                                                                                                                                                                 \n [7] \"The powerful lesson of a 5-year-old harassment campaign: How to wage a post-truth information war.\"                                                                                                                                                                                                                                       \n [8] \"The Indian jumping ant, Harpegnathos saltator, has many talents. This inch-long arthropod, found in flood plains across India, has a four-inch vertical leap and the ability to take down prey nearly twice its size. If that wasn’t enough, these amazing ants can also adjust the size of their own brains.\"                            \n [9] \"SXSW Interactive, the annual gathering of technology tastemakers and thought leaders in Austin, Tex., is facing a growing backlash over a decision to cancel two panels on video game culture, with two digital media organizations threatening to pull out of the event.\"                                                                \n[10] \"FOR more than five years, almost every word that I’ve written professionally has been about video games. I used to cover things like presidential campaigns and prison reform. But at some point, video games began to seem as consequential as those subjects, if not more so.\"                                                          \n\n# Both (abstract and leading paragraph) at once\ngamergate_json$response$docs[c(\"abstract\", \"lead_paragraph\")]\n\n                                                                                                                                                                                                           abstract\n1                                                                                                                                                                                     Here’s what you need to know.\n2                                                                  Intel’s decision added to a controversy that has focused attention on the treatment of women in the games business and the power of online mobs.\n3                                                      The atmosphere has become so toxic that critics and developers are urging big companies in the $70-billion-a-year video game industry to do more to stop it.\n4                                                                                                                               The precursors to Gamergate were disinformation campaigns targeting women of color.\n5                                                                                                                                  How online mobs harassed the targets of Gamergate, Christine Blasey Ford and me.\n6                                                                                                                                                                                          The legacy of Gamergate.\n7                                                                                                                The powerful lesson of a 5-year-old harassment campaign: How to wage a post-truth information war.\n8                                                                                                                                              If their bids at motherhood fail, they can then regrow their brains.\n9  A day after SXSW Interactive canceled two video game panels related to the so-called GamerGate movement over threats of violence, two digital media organizations threatened to pull out of the tech conference.\n10                                                                                                                                         The future of video games is threatened by the ugly culture around them.\n                                                                                                                                                                                                                                                                                                                              lead_paragraph\n1                                                                                                                                                                                                                                                                                  (Want to get this briefing by email? Here’s the sign-up.)\n2                                                                                                     For a little more than a month, a firestorm over sexism and journalistic ethics has roiled the video game community, culminating in an orchestrated campaign to pressure companies into pulling their advertisements from game sites. \n3  Anita Sarkeesian, a feminist cultural critic, has for months received death and rape threats from opponents of her recent work challenging the stereotypes of women in video games. Bomb threats for her public talks are now routine. One detractor created a game in which players can click their mouse to punch an image of her face.\n4                                                                                                                                                                                                                                                        The precursors to Gamergate were disinformation campaigns targeting women of color.\n5                                                                                                                                                                                                                                                           How online mobs harassed the targets of Gamergate, Christine Blasey Ford and me.\n6                                                                                                                                                                                                                                                                                                                   The legacy of Gamergate.\n7                                                                                                                                                                                                                                         The powerful lesson of a 5-year-old harassment campaign: How to wage a post-truth information war.\n8                              The Indian jumping ant, Harpegnathos saltator, has many talents. This inch-long arthropod, found in flood plains across India, has a four-inch vertical leap and the ability to take down prey nearly twice its size. If that wasn’t enough, these amazing ants can also adjust the size of their own brains.\n9                                                                  SXSW Interactive, the annual gathering of technology tastemakers and thought leaders in Austin, Tex., is facing a growing backlash over a decision to cancel two panels on video game culture, with two digital media organizations threatening to pull out of the event.\n10                                                           FOR more than five years, almost every word that I’ve written professionally has been about video games. I used to cover things like presidential campaigns and prison reform. But at some point, video games began to seem as consequential as those subjects, if not more so.\n\ngamergate_json$response$docs %&gt;%\n    select(abstract, lead_paragraph)\n\n                                                                                                                                                                                                           abstract\n1                                                                                                                                                                                     Here’s what you need to know.\n2                                                                  Intel’s decision added to a controversy that has focused attention on the treatment of women in the games business and the power of online mobs.\n3                                                      The atmosphere has become so toxic that critics and developers are urging big companies in the $70-billion-a-year video game industry to do more to stop it.\n4                                                                                                                               The precursors to Gamergate were disinformation campaigns targeting women of color.\n5                                                                                                                                  How online mobs harassed the targets of Gamergate, Christine Blasey Ford and me.\n6                                                                                                                                                                                          The legacy of Gamergate.\n7                                                                                                                The powerful lesson of a 5-year-old harassment campaign: How to wage a post-truth information war.\n8                                                                                                                                              If their bids at motherhood fail, they can then regrow their brains.\n9  A day after SXSW Interactive canceled two video game panels related to the so-called GamerGate movement over threats of violence, two digital media organizations threatened to pull out of the tech conference.\n10                                                                                                                                         The future of video games is threatened by the ugly culture around them.\n                                                                                                                                                                                                                                                                                                                              lead_paragraph\n1                                                                                                                                                                                                                                                                                  (Want to get this briefing by email? Here’s the sign-up.)\n2                                                                                                     For a little more than a month, a firestorm over sexism and journalistic ethics has roiled the video game community, culminating in an orchestrated campaign to pressure companies into pulling their advertisements from game sites. \n3  Anita Sarkeesian, a feminist cultural critic, has for months received death and rape threats from opponents of her recent work challenging the stereotypes of women in video games. Bomb threats for her public talks are now routine. One detractor created a game in which players can click their mouse to punch an image of her face.\n4                                                                                                                                                                                                                                                        The precursors to Gamergate were disinformation campaigns targeting women of color.\n5                                                                                                                                                                                                                                                           How online mobs harassed the targets of Gamergate, Christine Blasey Ford and me.\n6                                                                                                                                                                                                                                                                                                                   The legacy of Gamergate.\n7                                                                                                                                                                                                                                         The powerful lesson of a 5-year-old harassment campaign: How to wage a post-truth information war.\n8                              The Indian jumping ant, Harpegnathos saltator, has many talents. This inch-long arthropod, found in flood plains across India, has a four-inch vertical leap and the ability to take down prey nearly twice its size. If that wasn’t enough, these amazing ants can also adjust the size of their own brains.\n9                                                                  SXSW Interactive, the annual gathering of technology tastemakers and thought leaders in Austin, Tex., is facing a growing backlash over a decision to cancel two panels on video game culture, with two digital media organizations threatening to pull out of the event.\n10                                                           FOR more than five years, almost every word that I’ve written professionally has been about video games. I used to cover things like presidential campaigns and prison reform. But at some point, video games began to seem as consequential as those subjects, if not more so.\n\n\n\nExercise: Your own article search\n\nSelect your own article search query (any topic of interest to you). You may want to play with NY Times online search or the API web search console to find a query that is interesting, but not overly popular. You can change any part of the query you would like. Your query should have at least 30 matches.\nRetrieve data for the first three pages of search results from the article search API, and create a data frame that joins together the docs data frames for the three pages of results. (Read the “Multiple pages of search results” section below to see how to combine multiple pages of results with bind_rows().)\nMake a plot of the number of search results over time in your result set (likely by day or month). This will involve some data wrangling. It will be helpful to have the lubridate reference page open.\n\n\n\nMultiple pages of search results\nHere is some code to generate queries on NY Times articles about the Red Sox. It fetches the first thirty entries in batches of 10.\n\nurl &lt;- \"http://api.nytimes.com/svc/search/v2/articlesearch.json\"\nurl &lt;- param_set(url, \"q\", url_encode(\"Red Sox\"))\nurl &lt;- param_set(url, \"api-key\", url_encode(times_key))\nurl &lt;- param_set(url, \"page\", 0)\nSys.sleep(1)\nres1 &lt;- fromJSON(url)\n\n# This pauses for 1 second.\n# It is required when knitting to prevent R from issuing too many requests to\n# The NYT API at a time. If you don't have it you will get an error that\n# says \"Too Many Requests (429)\"\nSys.sleep(1)\nurl &lt;- param_set(url, \"page\", 1)\nres2 &lt;- fromJSON(url)\n\nSys.sleep(1)\nurl &lt;- param_set(url, \"page\", 2)\nres3 &lt;- fromJSON(url)\n\ndocs1 &lt;- res1$response$docs\ndocs2 &lt;- res2$response$docs\ndocs3 &lt;- res3$response$docs\n\nEach of these docs variables is a table with ten entries (articles) and the same 18 variables:\n\ncolnames(docs1)\ncolnames(docs2)\ncolnames(docs3)\n\nNow we want to stack the tables on top of each other to get a single table with 30 rows and 18 variables. We can use:\n\nbind_rows(docs1,docs2,docs3)"
  },
  {
    "objectID": "11-scraping.html",
    "href": "11-scraping.html",
    "title": "Data acquisition: Web scraping",
    "section": "",
    "text": "After this lesson, you should be able to:\n\nUse CSS Selectors and the Selector Gadget tool to locate data of interest within a webpage\nUse the html_elements() and html_text() functions within the rvest packages to scrape data from webpage using CSS selectors\n\n\nYou can download a template Quarto file to start from here. Save this template within the following directory structure:\n\nyour_course_folder\n\nscraping\n\ncode\n\n11-scraping.qmd"
  },
  {
    "objectID": "11-scraping.html#finding-css-selectors",
    "href": "11-scraping.html#finding-css-selectors",
    "title": "Data acquisition: Web scraping",
    "section": "Finding CSS Selectors",
    "text": "Finding CSS Selectors\nIn order to gather information from a webpage, we must learn the language used to identify patterns of specific information. For example, on the NIH News Releases page, we can see that the data is represented in a consistent pattern of image + title + abstract.\nWe will identify data in a web page using a pattern matching language called CSS Selectors that can refer to specific patterns in HTML, the language used to write web pages.\nFor example:\n\nthe CSS selector “a” selects all hyperlinks in a webpage (“a” represents “anchor” links in HTML)\nthe CSS selector “p” selects all paragraph elements\n\nWarning: Websites change often! So if you are going to scrape a lot of data, it is probably worthwhile to save and date a copy of the website. Otherwise, you may return after some time and your scraping code will include all of the wrong CSS selectors.\nAlthough you can learn how to use CSS Selectors by hand, we will use a shortcut by installing the Selector Gadget tool.\n\nThere is a version available for Chrome–add it to Chrome via the Chome Web Store.\n\nMake sure to pin the extension to the menu bar. (Click the 3 dots &gt; Extensions &gt; Manage extensions. Click the “Details” button under SelectorGadget and toggle the “Pin to toolbar” option.)\n\nThere is also a version that can be saved as a bookmark in the browser–see here.\n\nLet’s watch the Selector Gadget tutorial video before proceeding.\n\nHead over to the NIH News Releases page. Click the Selector Gadget extension icon or bookmark button. As you mouse over the webpage, different parts will be highlighted in orange. Click on the title of the first news release. You’ll notice that the Selector Gadget information in the lower right describes what you clicked on.\nScroll through the page to verify that only the information you intend (the description paragraph) is selected. The selector panel shows the CSS selector (.teaser-title) and the number of matches for that CSS selector (10). (You may have to be careful with your clicking–there are two overlapping boxes, and clicking on the link of the title can lead to the CSS selector of “a”.)\nRepeat the process above to find the correct selectors for the following fields. Make sure that each matches 10 results:\n\nThe publication date\nThe article abstract paragraph (which will also include the publication date)"
  },
  {
    "objectID": "11-scraping.html#retrieving-data-using-rvest-and-css-selectors",
    "href": "11-scraping.html#retrieving-data-using-rvest-and-css-selectors",
    "title": "Data acquisition: Web scraping",
    "section": "Retrieving Data Using rvest and CSS Selectors",
    "text": "Retrieving Data Using rvest and CSS Selectors\nNow that we have identified CSS selectors for the information we need, let’s fetch the data using the rvest package.\n\nnih &lt;- read_html(\"https://www.nih.gov/news-events/news-releases\")\n\nOnce the webpage is loaded, we can retrieve data using the CSS selectors we specified earlier. The following code retrieves the article titles:\n\n# Retrieve and inspect course numbers\narticle_titles &lt;- nih %&gt;%\n    html_elements(\".teaser-title\") %&gt;%\n    html_text()\nhead(article_titles)\n\n[1] \"NIH researchers develop approach that could help supercharge T-cell therapies against solid tumors\"     \n[2] \"Extreme heat projected to increase cardiovascular deaths\"                                               \n[3] \"Higher income and longer working years are linked to better mobility\"                                   \n[4] \"NIH immunotherapy pioneer Steven Rosenberg awarded nation’s highest honor for technology and innovation\"\n[5] \"New smartphone app quickly analyzes human motion to aid physical rehabilitation \"                       \n[6] \"NIH revises grant review process to improve focus on scientific merit, reduce reputational bias\"        \n\n\nPair programming exercise: Whoever can write down more stringr functions in 10 seconds will drive first and do the first exercise. Switch driver for the second exercise.\nExercise: Write a function that puts the article title, publication date, and abstract text from a single page of news results into a data frame.\n\nThe only argument to the function should be the URL to a page of news results. (Mouse over the page buttons at the very bottom of the news home page to see what the URLs look like.)\nThe abstract should not have the publication date–use string processing to remove the publication date.\n\n\n\nSolution\n\n\nget_text_from_page &lt;- function(css_selector) {\n    page %&gt;%\n        html_elements(css_selector) %&gt;%\n        html_text()\n}\n\nscrape_page &lt;- function(url) {\n    page &lt;- read_html(url)\n    article_titles &lt;- get_text_from_page(\".teaser-title\")\n    article_dates &lt;- get_text_from_page(\".date-display-single\")\n    article_abstracts &lt;- get_text_from_page(\".teaser-description\")\n    article_abstracts &lt;- str_remove(article_abstracts, \"^.+—\") %&gt;% trimws()\n    \n    tibble(\n        title = article_titles,\n        date = article_dates,\n        abstract = article_abstracts\n    )\n}\n\n\n\n\n\n\n\n\nStop to reflect\n\n\n\nIn your Process and Reflection Log write a few observations about your experience writing the function for this first exercise. What is starting to get easier about function writing? What is still challenging? What practices or strategies would you like to try out next?\n\n\nExercise: Use iteration to get article information for the first 5 pages of news results. You can use either a for-loop or purrr::map(). For a challenge, do both.\n\n\nSolution\n\nUsing a for-loop:\n\npages &lt;- vector(\"list\", length = 5)\n\nfor (i in 1:5) {\n    base_url &lt;- \"https://www.nih.gov/news-events/news-releases\"\n    if (i==1) {\n        url &lt;- base_url\n    } else {\n        url &lt;- str_c(base_url, \"?page=\", i-1)\n    }\n    pages[[i]] &lt;- scrape_page(url)\n}\n\ndf_articles &lt;- bind_rows(pages)\nhead(df_articles)\n\nUsing purrr::map():\n\n# Create a character vector of URLs for the first 5 pages\nbase_url &lt;- \"https://www.nih.gov/news-events/news-releases\"\nurls_all_pages &lt;- c(base_url, str_c(base_url, \"?page=\", 1:4))\n\npages2 &lt;- purrr::map(urls_all_pages, scrape_page)\ndf_articles2 &lt;- bind_rows(pages2)\nhead(df_articles2)\n\n\n\n\n\n\n\n\nStop to reflect\n\n\n\nIn your Process and Reflection Log write a few observations about your experience working on this second exercise. What is starting to get easier about wrting code for iteration? What is still challenging? What practices or strategies would you like to try out next?\n\n\n\nA more complex example with the NIH STEM Teaching Resources Webpage.\nSelecting the resource titles ends up being tricky. Using Selector Gadget, we can only get one resource title at a time. In Chrome, you can right click part of a web page and click “Inspect”. This opens up Chrome’s Developer Tools. Mousing over the HTML in the top right panel highlights the corresponding part of the web page.\n\nFor non-Chrome browsers, use the Help menu to search for Developer Tools.\n\nThe underlying HTML used to create a web page is also called the page source code or page source. We learn from this that the resource titles are &lt;h4&gt; headings that have the class resource-title. We can infer from this that .resource-title would be the CSS selector for the resouce titles."
  },
  {
    "objectID": "12-practice-review.html",
    "href": "12-practice-review.html",
    "title": "Practicing our tools so-far; mini-project",
    "section": "",
    "text": "Based on your observations in Reflection 1, use these exercises/explorations to practice what will be most beneficial to you.\nAs part of Homework 6 (due next Wed 10/8), the only required part of these activities is the “Improving your data visualizations” section. You are welcome to submit anything you work on this week for feedback."
  },
  {
    "objectID": "12-practice-review.html#resources-for-sparking-creativity-and-imagination-in-your-plots",
    "href": "12-practice-review.html#resources-for-sparking-creativity-and-imagination-in-your-plots",
    "title": "Practicing our tools so-far; mini-project",
    "section": "Resources for sparking creativity and imagination in your plots",
    "text": "Resources for sparking creativity and imagination in your plots\nExercise: Explore at least one of these resources, and keep an eye out for the use of the 6 guidelines for great plots. Write a few sentences describing what you observe.\n\nBlog post: The 30 Best Data Visualizations of 2023\nThe Pudding is a great data journalism site. Examples of articles with unique visualizations:\n\nPockets: On the sizes of men’s and women’s pockets\nMaking it Big: Exploring the trajectory of bands\nThe Differences in How CNN, MSNBC, & FOX Cover the News\nThe Physical Traits that Define Men and Women in Literature\nHow News Media Covers Trump and Clinton: An analysis of images in news media\nWhere Slang Comes From: Exploring the emergence of slang over time\n\nVisualizations from the New York Times:\n\nThe Best NYT Visualizations of 2015\n2022: The Year in Visual Stories and Graphics"
  },
  {
    "objectID": "12-practice-review.html#applying-the-guidelines-to-your-project",
    "href": "12-practice-review.html#applying-the-guidelines-to-your-project",
    "title": "Practicing our tools so-far; mini-project",
    "section": "Applying the guidelines to your project",
    "text": "Applying the guidelines to your project\nPart 1: Identify a key visualization from your project–one that communicates a finding that you really want your audience to remember. Display this original plot in the code chunk below. If you pick the same plot as your teammates, that’s fine. But please work on improvements to the visualization on your own so that you can best develop your own skills.\n\n# Code for your original project visualization\n\nPart 2: Evaluate your original visualization in terms of the 6 guidelines. Write a paragraph in the space below explaining which guidelines you want to use to improve your plot and why.\n\nWrite your evaluation here.\n\nPart 3: Implement the changes that you described in Part 2, and display your improved plot below.\n\n# Code for improved project visualization"
  },
  {
    "objectID": "activities.html",
    "href": "activities.html",
    "title": "Activities",
    "section": "",
    "text": "In-class activities"
  },
  {
    "objectID": "homework.html",
    "href": "homework.html",
    "title": "Homework",
    "section": "",
    "text": "General instructions for homework:\n\nProcess section:\n\nOn getting help\n\nThings I Googled or asked on ChatGPT: There is no shame in having items here! But making note of this is important for noticing what you’re not “fluent” in yet. (e.g., when learning a new language, it would be helpful to write down words that you frequently have to look up to translate)\nThings I consulted with peers about\nOther resources that I consulted\n\nWhat was easy, medium, hard? Why?\n\n\nCommon elements of weekly homework:\n\nFirst part will always be to work on the most recent Tidy Tuesday."
  },
  {
    "objectID": "homework0.html",
    "href": "homework0.html",
    "title": "Homework 0",
    "section": "",
    "text": "A note from your instructor\n\n\n\nWhen I started college, the main thinking I did about my capital-F Future (that nebulous thing way out in the distance) was about what I would be doing after college. It made me very anxious.\nThrough the many years since my college experience, I have come to see that what allows me to be more at peace with my capital-F Future now is a deeper understanding of who I am and what my values are.\nI want to give you a chance to do this kind of thinking now with this “assignment”.\n\n\nI invite you to write an essay (tentatively) titled “My past, present and future and the values they express”. (Change the title if you wish!)\nThis essay does not need to be submitted and is not due at any point. If you ever wish to talk to me about what you wrote, the process of writing it, or what you’ve thought about after writing it, I’d love to do that over a walk or a cup of hot chocolate.\nI do hope that by writing it you are able to move forward with your college experience this semester with more peace and clarity. For that reason alone, I suggest that you write this essay by the end of the first week of class (Sunday, September 10).\nIt might be helpful to do/think about the following as you write:\n\nVisit this Values Exercise page to read a very short bit about core values and their role in a fulfilling life. Click the “Start the Exercise” button to complete a ~15 minute exercise to identify your core values.\nWhat events brought you to Macalester, and what core values do you think led you to choose Mac?\nWhere do you see yourself in 10 years? How do you see yourself living? What would it take to get to that point? To think through that process in steps, think about:\n\n10-year vision (what’s going on in 2033 and why?)\n5-year vision (what’s going on in 2028 and why?)\n2-year vision (what’s going on in 2025 and why?)\n1-year vision (what’s going on in 2024 and why?)\n6-month vision (what’s going on in Spring 2024 and why?)\nThinking about the “why” for these visions can help affirm and clarify the core values you ended up with from the Values Exercise above. For example, if part of your 5-year vision wasn’t happening, how would you feel and why?\n\n\nIf it helps at all to look at someone else’s vision as you craft your own, I tried to write my own 10-year vision earlier this summer."
  },
  {
    "objectID": "homework1.html",
    "href": "homework1.html",
    "title": "Homework 1",
    "section": "",
    "text": "Required parts\nFinish the plot that we started in our Advanced Data Visualization in ggplot2 class activity up to the minimum requirements.\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework2.html",
    "href": "homework2.html",
    "title": "Homework 2",
    "section": "",
    "text": "Required parts\n\nFinish the Open-ended Exercise in our Advanced Map Visualization class activity.\n\nSubmission details: Click the “Render” button to create an HTML report from your Quarto file. Open the HTML in your web browser and save the webpage as a PDF (Ctrl-P/Command P, choose “Save as PDF” as the Destination). Submit this PDF on Moodle AND the .qmd file by midnight on Wednesday, 9/20.\n\nComplete Milestone 1 of the course project. (Brainstorming ideas and data sources). Put this information in a # Project section that you add to the end of your 03-adv-maps.qmd.\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework3.html",
    "href": "homework3.html",
    "title": "Homework 3",
    "section": "",
    "text": "Required parts\n\nFinish the Shiny app from the interactive viz class activity up to the minimum requirements.\n\nSubmission details: Submit the app.R file on Moodle by midnight on Wednesday, 9/27.\n\nWork towards Milestone 2 of the course project. (Nothing to turn in for Homework 3, but you should be making progress.)\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework4.html",
    "href": "homework4.html",
    "title": "Homework 4",
    "section": "",
    "text": "Required parts\nDue Wednesday, October 4 by midnight on Moodle.\nComplete Milestone 2 of the course project.\n\nEach team member will submit their own .Rmd file and knitted HTML containing their own “rough draft” visualization to answer the team’s initial research question.\n\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework5.html",
    "href": "homework5.html",
    "title": "Homework 5",
    "section": "",
    "text": "Required parts\nDue Wednesday, October 18 by midnight on Moodle.\nComplete the first exercise in Section 26.3.5 of R for Data Science. (The exercise that begins with “Using the datasets from nycflights13…” This first exercise has 5 functions to write.)\n\nYou will need to install the nycflights13 package to access the datasets that the exercise is referring to.\nNote that the |&gt; that appears in the exercises is effectively the same as our familiar pipe %&gt;%. (The |&gt; is a pipe operator that the base R functionality now comes with.)\n\nFor each function that has arguments (sub-exercises 3 to 5), test your function two times by running it with two different sets of arguments. Show this output.\nPut this work in a new homework5.qmd document. Update the header information in your .qmd to look like this:\ntitle: \"Homework 5: Functions\"\nauthor: \"YOUR NAME\"\nformat: \n  html:\n    self-contained: true\nWhen you render this .qmd, this will create an HTML file in which images are embedded. Submit this HTML file on Moodle.\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "homework6.html",
    "href": "homework6.html",
    "title": "Homework 6",
    "section": "",
    "text": "Required parts\nDue Wednesday, November 8 by midnight on Moodle.\n\nComplete all exercises in the “Improving your data visualizations” section of our review activity.\nIf you would like feedback on any other part of our review activity, you can also submit this work. Please write 1-2 sentences in each section of additional work describing what specifically you would like feedback on.\n\nPut this work in a new .qmd document. Update the header information in your .qmd to look like this:\ntitle: \"Homework 6\"\nauthor: \"YOUR NAME\"\nformat: \n  html:\n    self-contained: true\nWhen you render this .qmd, this will create an HTML file in which images are embedded. Submit this HTML file on Moodle.\nIf you decided to write a Shiny app for the mini-project and want feedback, you can also submit your app.R file.\n\n\nOptional\nParticipate in the most recent Tidy Tuesday challenge."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "",
    "text": "This is the course website for STAT/COMP 212: Intermediate Data Science at Macalester College for the Fall 2023 semester taught by Professor Leslie Myint. Materials were developed by Leslie Myint and Brianna Heggeseth."
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "10/17",
    "text": "10/17\n\nHomework 5 is a set of practice exercises on writing functions. This is due Wednesday 10/18.\nMake note of the first project progress presentation on 10/24. Your homework this week is to work on your progress presentation. (Presentation requirements can be found under Milestone 3 on the Project page.)"
  },
  {
    "objectID": "index.html#section-1",
    "href": "index.html#section-1",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "10/12",
    "text": "10/12\n\nHomework 5 is a set of practice exercises on writing functions. This is due next Wednesday, 10/18.\nMake note of the first project progress presentation on 10/24.\nBefore class on Tuesday, install the following packages:\n\n\ninstall.packages(c(\"jsonlite\", \"urltools\"))\n# install.packages(\"devtools\") # Install devtools if you haven't already\ndevtools::install_github(\"mkearney/nytimes\")"
  },
  {
    "objectID": "index.html#section-2",
    "href": "index.html#section-2",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "10/3",
    "text": "10/3\n\nProject Milestone 2 can be turned in this Wednesday 10/4 or next Wednesday 10/11\nReflection 1 is due next Wednesday 10/11. (I’m still finishing writing out the prompts–I’ll send a Moodle message later today when it’s ready.)\nCheck out our Schedule.\n\nOn Thursday we’ll talk about writing functions.\nNext week we’ll talk about loops and iteration.\nMake note of Project progress presentations on 10/24 and 11/16."
  },
  {
    "objectID": "index.html#section-3",
    "href": "index.html#section-3",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/28",
    "text": "9/28\n\nI thought we might be able to cover wrangling factors today, but we’ll save that for next Tuesday.\nLook at the updated Schedule page. The readings there are excellent references and can be read before or after class on Tuesday."
  },
  {
    "objectID": "index.html#section-4",
    "href": "index.html#section-4",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/26",
    "text": "9/26\n\nIf you haven’t already found an initial dataset, peruse the Tidy Tuesday repository for ideas.\n\nHomework 4 (due next Wednesday 10/4) is to complete Project Milestone 2.\n\nThursday topics: wrangling strings (with regular expressions) and factors\nIn place of a standard Homework 5, we will have the first of 3 substantive reflections."
  },
  {
    "objectID": "index.html#section-5",
    "href": "index.html#section-5",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/19",
    "text": "9/19\n\nOn Thursday:\n\nWe will spend the first 30 moving our course projects moving forward.\nIn the last hour of class, facilitators will come in to run an activity for the Classroom Community and Connectedness Survey. (I will be leaving.) A reminder of why this activity is important to me from our syllabus:\n“A sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).”"
  },
  {
    "objectID": "index.html#section-6",
    "href": "index.html#section-6",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/14",
    "text": "9/14\n\nBefore next Tuesday’s class\n\nCheck the Schedule page. There is a short podcast segment (~7 min) to listen to and one guiding question to answer. This podcast segment shares a bit of wisdom about when it is/isn’t useful to make fancy visualizations.\nInstall the shiny and plotly packages. Post on the #questions channel on Slack if you run into problems. (Share your commands and error messages.)\n\nNext Thursday we will be having facilitators come in for the last hour of class for the Classroom Community and Connectedness Survey. (I will be leaving.)\n\nWe will use the first 30 to get our course projects moving forward."
  },
  {
    "objectID": "index.html#section-7",
    "href": "index.html#section-7",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/12",
    "text": "9/12\n\nHomework 1 due Wednesday at midnight (Finishing up the temperature + precipitation plots from last Tuesday)\n\nUpdated submission instructions can be found here. (Also in the most recent Moodle announcement.)\n\nHomework 2 due next Wednesday, 9/20 has two parts:\n\nFinish Open-ended Exercise from today’s Advanced Map Visualization activity.\nComplete Milestone 1 of the course project\n\nThere is a final version of our syllabus that incorporates the learning goals and grading option that we discussed on our first day."
  },
  {
    "objectID": "index.html#section-8",
    "href": "index.html#section-8",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/7",
    "text": "9/7\n\nI’ll be adding a new version of the syllabus to our course website that incorporates our final choice for grading system and the learning goals that you contributed.\nComplete the pre-course survey by 3pm today to shape when I hold drop-in hours (office hours).\nLook at the updated Schedule page. We have Guiding Questions for next Tuesday’s class: advanced map visualization.\n\nNote that Guiding Questions never have to be turned in. Do answer them to the best of your ability before class. We’ll spend time at the start of class checking in on these."
  },
  {
    "objectID": "index.html#section-9",
    "href": "index.html#section-9",
    "title": "STAT/COMP 212: Intermediate Data Science (Fall 2023)",
    "section": "9/5",
    "text": "9/5\nTo do before class on Thursday:\n\nSet up R and RStudio using these instructions.\nJoin our Slack workspace.\n\nUpdate your Slack profile with preferred name, pronouns, name pronunciation. (To find your profile, click on your name under Direct Messages on the left menu, and click “Edit Profile”.)\nIntroduce yourself in the #general channel.\n\nComplete the pre-course survey.\nLook at the Guiding Questions for Thursday’s class on advanced ggplot2.\nTake a look at Homework 0.\n\nThis is a personal essay that doesn’t need to be turned in.\nTopic: Your 10-year vision\nMy hope is that writing this allows gives you more clarity on how to align what you do this semester (and beyond) with who/what/how you want to be.\n\nFinish writing your 12 favorite problems and post them in the #12-favorite-problems channel on Slack.\n\nWhen you connect with peers from Thursday onward, you’ll be using your 12FPs to get to know each other a bit first before working on activities together."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Project",
    "section": "",
    "text": "The goal of the project is to build something awesome that you can showcase on your digital portfolio (your personal website)."
  },
  {
    "objectID": "project.html#milestone-1",
    "href": "project.html#milestone-1",
    "title": "Project",
    "section": "Milestone 1",
    "text": "Milestone 1\nIdentify a data context that interests you. (Your 12 favorite problems might serve as a good source of inspiration.) Identify 3 different data sources that relate to that context. Think beyond a spreadsheet; the most interesting projects may involve collecting and aggregating data from multiple sources and formats. We might not have covered all of the tools needed to acquire that data at this point, so check in with the instructor about the sources that you’ve found to make sure that they’re workable.\n\nExample non-spreadsheet data sources: search results on a webpage, text of an article, Tweets, other social media posts.\n\nBrainstorm 3 questions about your data context and sources that pique your curiosity.\nDue date: Wednesday, 9/20 as part of HW2."
  },
  {
    "objectID": "project.html#milestone-2",
    "href": "project.html#milestone-2",
    "title": "Project",
    "section": "Milestone 2",
    "text": "Milestone 2\n\nForm project teams.\nFinalize one initial data source and questions related to that source.\nEach team member should create 1 “ugly” (not fully polished) visualization to demonstrate viability of the research questions. (Think of this as visualization “prototyping”.)\n\nDue date: Wednesday, 10/11 as part of HW4. (You can submit early on 10/4 if you’d like.)"
  },
  {
    "objectID": "project.html#milestone-3",
    "href": "project.html#milestone-3",
    "title": "Project",
    "section": "Milestone 3",
    "text": "Milestone 3\nPerform the data acquisition, wrangling, visualization, and modeling needed to address one of your research questions. Note that your question might not be amenable to modeling (or to modeling that you’ve learned about so far). For that reason, modeling is not required, but visualization is.\nDeliverable: Project progress presentation #1–to be presented in class on Tuesday 10/24.\n\nHow long? Prepare a 5-7 minute presentation.\nWhat should be in your presentation?\n\nAn introduction to your project domain/focus: What questions are you hoping to answer? What question are you focusing on right now? Why is this important to you?\nAn introduction to your data sources\nWho is impacted (whether positive or negatively) by your analysis? How are you addressing this?\nPresent a few polished visualizations and interpretations that address your current research question\n\nWhy am I asking you to do this?\n\nOrganizing your work for a short presentation is a good way to stay on track and guarantee some useful intermediate work\nBased on the Classroom Community and Connectedness survey results, there was a desire for more authentic collaboration. I feel that this type of class activity is fertile ground for true collaboration.\n\nWhat feedback will you receive?\n\nBased on the context you present, the instructor and your classmates will give feedback on any suggestions for ethical considerations in your analysis.\nWe will also give feedback on the clarity of your visualizations and your interpretations of them."
  },
  {
    "objectID": "project.html#milestone-4",
    "href": "project.html#milestone-4",
    "title": "Project",
    "section": "Milestone 4",
    "text": "Milestone 4\n(NOT FINALIZED YET)\nAdjust data sources and research questions as needed based on the results of explorations so far. Perform the data acquisition, wrangling, visualization, and modeling needed to address another one of your research questions.\nDeliverable: Project progress presentation #2–to be presented in class on Thursday 11/16.\n\nHow long? Prepare a 7 minute presentation.\nWhat should be in your presentation?\n\n\n\nWhy am I asking you to do this?\n\n\n\nWhat feedback will you receive?"
  },
  {
    "objectID": "project.html#milestone-5",
    "href": "project.html#milestone-5",
    "title": "Project",
    "section": "Milestone 5",
    "text": "Milestone 5\n(NOT FINALIZED YET)\nAdjust data sources and research questions as needed based on the results of explorations so far. Perform the data acquisition, wrangling, visualization, and modeling needed to address another one of your research questions. Submit “Final Draft”.\nDue date: TBD"
  },
  {
    "objectID": "reflection1.html",
    "href": "reflection1.html",
    "title": "Reflection 1",
    "section": "",
    "text": "Purpose\nThe goal of this reflection is to check in on your learning as related to the learning goals that we have addressed so far. Most importantly, it is a space for honest conversation between you and me.\n\n\nTask\nMake your own copy of this Google Doc, and follow the reflection prompts in that document.\nYou will submit a link to this Google Doc on Moodle by Wednesday 10/11 at midnight. Make sure that Leslie is an Editor or Commenter on this document."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Readings in the schedule below refer to the following textbooks (freely available online):\n\nR for Data Science (2e) by Wickham, Cetinkaya-Rundel, and Grolemund (Abbreviated as R4DS)\nR Programming for Data Science (Abbreviated as RPDS)\nModern Data Science with R (3e) by Baumer, Kaplan, and Horton (Abbreviated as MDSR)\n\nGuiding questions for the readings are available at the bottom of this page.\n\n\n\n  \n    Week\n    Tuesday\n    Thursday\n    Announcements\n  \n\n\n\n  \n    1\n    \n    \n      9/5: Welcome! Meeting each other and designing our learning community \n      Before class: Review the syllabus and think about the questions posed in the green \"Reflect\" blocks.\n    \n    \n      9/7: Advanced visualization in ggplot \n      Before class: Review the construction of plots from STAT 112 and STAT 155. Answer the Guiding Questions at the bottom of this page. \n    \n    \n    \n      Work on HW0 (your 10-year vision, doesn't need to be turned in).Look ahead to HW1\n    \n  \n  \n  \n  \n  \n    2\n    \n      9/12: Advanced map visualization \n      Before class: Watch this video on Coordinate Reference Systems, and answer the Guiding Questions at the bottom of this page.\n    \n    \n    \n      9/14: Advanced map visualization (continued) \n    \n    \n    Turn in HW1 by midnight on Wed 9/13. Look ahead to HW2 due Wednesday 9/20 at midnight.\n  \n  \n  \n  \n  \n    3\n    \n      9/19: Interactive visualization \n      Before class: Listen to this podcast from Chapter 7 (timestamp 18:09) through Chapter 8 (ending at timestamp 25:27). Answer the Guiding Question at the bottom of this page. Install the \"shiny\" and \"plotly\" R packages.\n    \n    \n    \n      9/21: Classroom Community and Connectedness (CC&C) Survey \n      For the first 30 minutes, we will move our course projects forward. In the last hour of class, CC&C facilitators will come in to run an activity on how community-building is going in our course.\n    \n    \n    Turn in HW2 by midnight on Wednesday 9/20. Look ahead to HW3.\n  \n  \n  \n  \n  \n    4\n    \n      9/26: Data wrangling: numbers, logicals, and dates\n      Helpful readings (read before or after class): (All from R4DS) Chapter 13 (Logicals), Chapter 14 (Numbers), and Chapter 18 (Dates/Times)\n    \n    \n    \n      9/28: Data wrangling: strings \n      Helpful readings (read before or after class): (All from R4DS) Chapter 15 (Strings) and Chapter 16 (Regular Expressions)\n    \n    \n    Turn in HW3. Look ahead to HW4 (Project Miletone 2).\n  \n  \n  \n  \n  \n    5\n    \n      10/3: Data wrangling: factors \n      Helpful readings (read before or after class): Chapter 17 (Factors) (R4DS).\n    \n    \n    \n      10/5: Writing functions \n      Helpful readings (read before or after class): R4DS Chapter 26 (Functions) and RPDS Section 13.1 (if-else). \n    \n    \n    Turn in Project Milestone 2 by either Wed 10/4 or Wed 10/11 at midnight. Start looking at Reflection 1.\n  \n  \n  \n  \n  \n    6\n    \n      10/10: Loops and iteration \n      Helpful readings (read before or after class): Chapter 27 (Iteration) and this tutorial. \n    \n    \n    \n      10/12: Loops and iteration\n    \n    \n    Turn in HW4 (Project Milestone 2) by Wed 10/11 if you haven't already. Turn in Reflection 1 by Wed 10/11.\n  \n  \n  \n  \n  \n    7\n    \n      10/17: Data acquisition: APIs \n      Helpful readings (read before or after class):\n    \n    \n    \n      10/19: Data acquisition: Scraping \n      Helpful readings (read before or after class): rvest vignette \n    \n    \n    Turn in HW5.\n  \n  \n  \n  \n  \n    8\n    \n      10/24: Project feedback \n      Project progress presentation #1: Your team will present a 5-7 minute progress report and plan for next steps\n    \n    \n    \n      10/26: No class - Fall Break 🍁\n    \n    \n    \n  \n  \n  \n  \n  \n    9\n    \n      10/31: Review and practice (Day 1)\n    \n    \n    \n      11/2: Review and practice (Day 2)\n    \n    \n    Work on review activities as part of HW6.\n  \n  \n  \n  \n  \n    10\n    \n      11/7: Data acquisition: databases \n      Required reading before class: R4DS Chapter 22 (Databases).\n    \n    \n    \n      11/9: Data acquisition: databases (continued)\n    \n    \n    \n  \n  \n  \n  \n  \n    11\n    \n      11/14: Missing data: wrangling and missingness mechanisms \n      Required reading before class: TBD\n    \n    \n    \n      11/16: Missing data: imputation \n      Required reading before class: TBD\n    \n    \n    \n  \n  \n  \n  \n  \n    12\n    \n      11/21: Project presentations \n      Project progress presentation #2: Your team will give a 10 minute presentation with intermediate results for 2 research questions.\n    \n    \n    \n      11/23: No class - Thanksgiving Break 🦃\n    \n    \n    \n  \n  \n  \n  \n  \n    13\n    \n      11/28: Topics of your choosing from this point onwards (e.g., Python, GitHub, text analysis)\n    \n    \n    \n      11/30: Topics of your choosing"
  },
  {
    "objectID": "schedule.html#databases",
    "href": "schedule.html#databases",
    "title": "Schedule",
    "section": "11/7: Databases",
    "text": "11/7: Databases\nBefore class on Tuesday, install the DBI and duckdb packages. Post in the #questions channel on Slack if you run into issues.\nAs you read the Databases chapter of R4DS, answer the following questions:\n\nWhat are the differences between client-server, cloud, and in-process database management systems (DBMSs)?\nMake note of how the following functions are used in a database workflow. What does each function do? What inputs/arguments does each function require? Create a set of notes that shows the sequence of these functions in a database workflow.\n\nDBI::dbConnect()\nDBI::dbReadTable()\nDBI::dbGetQuery()\ntbl()\ncollect()\n\nMake note of how the showQuery() function can help you learn SQL (structured query language) by translating dplyr code into SQL.\n\nAs you read Section 22.5 (SQL), create notes that relate parts of SQL queries to dplyr functions."
  },
  {
    "objectID": "schedule.html#web-scraping",
    "href": "schedule.html#web-scraping",
    "title": "Schedule",
    "section": "10/19: Web scraping",
    "text": "10/19: Web scraping\nAs you read the rvest package vignette, answer the following questions:\n\nThe first step of getting (scraping) data from an arbitrary web page is to read in the webpage. What rvest function(s) are relevant for this step?\nNext we need to select the HTML elements that contain the information that we want. What function(s) are relevant here?\n\nHow would we select all elements that have the class “author”?\nHow would we select all level 1 headers (tag &lt;h1&gt;)?\n\nNext we extract information from the selected HTML elements.\n\nWhat is the difference between selecting the text contents of an HTML element and selecting an attribute of the HTML element? What functions are used for these two tasks?\nHow would we get all URLs for links that appear on a webpage?"
  },
  {
    "objectID": "schedule.html#interactive-visualization",
    "href": "schedule.html#interactive-visualization",
    "title": "Schedule",
    "section": "9/19: Interactive visualization",
    "text": "9/19: Interactive visualization\nAfter listening to this podcast from Chapter 7 (timestamp 18:09) through Chapter 8 (ending at timestamp 25:27), reflect on the following question:\n\nWhat was new, unexpected, or interesting in the discussion about animations, interactivity, and dashboards?"
  },
  {
    "objectID": "schedule.html#advanced-map-visualization",
    "href": "schedule.html#advanced-map-visualization",
    "title": "Schedule",
    "section": "9/12: Advanced map visualization",
    "text": "9/12: Advanced map visualization\nAfter/while watching this video on Coordinate Reference Systems (CRS), answer the following questions:\n\nWhat is the shape of the Earth?\nWhy is GDA94 a great datum name?\nWhat are the two components of a CRS/GCS?\nWhy do we use many different local CRSs rather than just one CRS for the whole earth?\nWhy is it insufficient to identify a location by its latitude and longitude?\nWhy do we need to be mindful about CRSs when working with different spatial datasets?"
  },
  {
    "objectID": "schedule.html#advanced-visualization-in-ggplot",
    "href": "schedule.html#advanced-visualization-in-ggplot",
    "title": "Schedule",
    "section": "9/7: Advanced visualization in ggplot",
    "text": "9/7: Advanced visualization in ggplot\nTo review plot creation skills from STAT/COMP 112 and STAT 155, use the diamonds dataset in the ggplot2 package to recreate the following visualizations:\n\nlibrary(ggplot2)\ndata(diamonds)"
  },
  {
    "objectID": "slides/02-adv-ggplot.html#welcome-back",
    "href": "slides/02-adv-ggplot.html#welcome-back",
    "title": "Day 2",
    "section": "Welcome back!",
    "text": "Welcome back!\nAs we prepare to gather as a class, think about the following:\n\nWhat themes emerge in your 12 favorite problems? (You’ll be sharing with partner(s) today.)\n\nRandom\n\nHow do you pronounce the name Sean Bean? 😆\n\nQuote of the day\n\nYou don’t rise to the level of your goals. You fall to the level of your systems.\n\nJames Clear, Atomic Habits"
  },
  {
    "objectID": "slides/03-adv-maps.html#as-we-gather",
    "href": "slides/03-adv-maps.html#as-we-gather",
    "title": "Advanced Spatial Visualizations",
    "section": "As we gather…",
    "text": "As we gather…\nCheck in with those around you–how is the semester going so far?\nOpen up your Process and Reflection Log (Google Doc)."
  },
  {
    "objectID": "slides/03-adv-maps.html#as-we-gather-1",
    "href": "slides/03-adv-maps.html#as-we-gather-1",
    "title": "Advanced Spatial Visualizations",
    "section": "As we gather…",
    "text": "As we gather…\nSit next to someone new. Share a favorite problem that helps you feel curious this week. In talking with your partner, what connections do you see to your own FPs?\nQuote of the day:\n\nThe more stuff you love the happier you will be.\n― Ross Gay, The Book of Delights\n\nOpen up your Process and Reflection Log (Google Doc).\n\nReshare it with me so that I can be a Commenter, and check the “Notify people” box.\nLeave it open. We are going to stop and reflect a few times today."
  },
  {
    "objectID": "slides/04-interactive-viz.html#as-we-gather",
    "href": "slides/04-interactive-viz.html#as-we-gather",
    "title": "Interactive visualization",
    "section": "As we gather…",
    "text": "As we gather…\nThink about what makes learning new code challenging for you and what strategies tend to work well or less well. You will work with someone random (and possibly new)–how can you best support your own and their learning?\nQuote of the day:\n\nIn fact, in addition to the fact that we all die, the most salient or unifying feature of we the living is that we cannot survive without help.\n― Ross Gay, Inciting Joy\n\nOpen up your Process and Reflection Log (Google Doc).\n\nLeave it open. We are going to stop and reflect a few times today."
  },
  {
    "objectID": "slides/04-interactive-viz.html#reflecting-on-our-shiny-activity",
    "href": "slides/04-interactive-viz.html#reflecting-on-our-shiny-activity",
    "title": "Interactive visualization",
    "section": "Reflecting on our Shiny activity",
    "text": "Reflecting on our Shiny activity\nComment/uncomment the selected lines—super useful for debugging!!\n\nMac: Command-Shift-C\nWindows: Ctrl-Shift-C\n\nWrite a few observations in your Process and Reflection Log (Google Doc):\n\nWhat was challenging about learning Shiny? (When) did things start to click?\nWe’ve worked with a few different partners now–in general what has been helpful/less helpful about working with others? What would you like to change in the future?"
  },
  {
    "objectID": "slides/05-data-types-1.html#as-we-gather",
    "href": "slides/05-data-types-1.html#as-we-gather",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "As we gather…",
    "text": "As we gather…\nNavigate to our course page and activity: “Wrangling: numerics, logicals, dates”. Open the slides linked under the Learning Goals\nImage of the day:\n\nElderly woman, drinking in the momentOpen up your Process and Reflection Log (Google Doc)."
  },
  {
    "objectID": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief",
    "href": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Classroom Community and Connectedness debrief",
    "text": "Classroom Community and Connectedness debrief\nSection 1\n\nWhile working in groups on activities was seen as a strength, it was also something that has challenges\n\nMeeting and getting to know new people is hard–especially in a classroom environment\n\nThings that I can do\n\nChange groups regularly\nCreate spaces for more authentic and collaborative group work\nOut-of class opportunities for hanging out (with food!?)\n\nThings that you can do\n\nA number of you mentioned that you yourselves wanted to better at fostering community\n\n\nNote: reflection regarding group work is one of my top learning goals not because I want to judge/evaluate you on it but because I value it. Across your 3 substantive reflections, I just want to give feedback. I won’t give mandates that you have to follow “or else”."
  },
  {
    "objectID": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief-1",
    "href": "slides/05-data-types-1.html#classroom-community-and-connectedness-debrief-1",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Classroom Community and Connectedness debrief",
    "text": "Classroom Community and Connectedness debrief\nSection 2\n\nWhile working in groups on activities was seen as a strength, it was also something that has challenges\n\n“Clicking” with others is not always easy\n\nThings that I can do\n\nBe mindful of class dynamics and energy\nCreate spaces for more authentic and collaborative group work\nOut-of class opportunities for hanging out (with food!?)\n\nThings that you can do\n\nA number of you mentioned trying to be more compassionate and collaborative\n\n\nNote: reflection regarding group work is one of my top learning goals not because I want to judge/evaluate you on it but because I value it. Across your 3 substantive reflections, I just want to give feedback. I won’t give mandates that you have to follow “or else”."
  },
  {
    "objectID": "slides/05-data-types-1.html#project-team-formation-activity",
    "href": "slides/05-data-types-1.html#project-team-formation-activity",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Project team formation activity",
    "text": "Project team formation activity\nOpen up this Google Jamboard.\n\nOn a sticky note (left menu), write down the general domain of your ideal project (e.g., environmental/climate issues) and your name.\nOnce everyone is done, work together to group the sticky notes into clusters such that an even number is in each group.\nWithin these groups, re-introduce yourselves and share more specific details about your desired project (e.g., specific research ?s and possible data sources).\nForm teams (pairs) for your project and decide on a contact/communication strategy outside of class."
  },
  {
    "objectID": "slides/05-data-types-1.html#about-project-teams-and-pods",
    "href": "slides/05-data-types-1.html#about-project-teams-and-pods",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "About project teams and “pods”",
    "text": "About project teams and “pods”\nWe’ll try out sitting in project pairs to better facilitate community and connection. We’ll do a little bit of project work each class period.\nOn feedback days, pairs will sit with other pairs with similar project domains and different domains. Having this variety of feedback will be important for the quality of your project."
  },
  {
    "objectID": "slides/05-data-types-1.html#thursday-project-work",
    "href": "slides/05-data-types-1.html#thursday-project-work",
    "title": "Wrangling: numerics, logicals, dates",
    "section": "Thursday: project work",
    "text": "Thursday: project work\nMilestone 2 is about finding an initial dataset and each team member creating one “rough draft” visualization to answer one of your research questions.\nI highly recommend using the Tidy Tuesday repository to locate an initial dataset if you don’t already have one. (The dataset doesn’t have to be a perfect match for your questions.)"
  },
  {
    "objectID": "slides/day1.html#plan-for-today",
    "href": "slides/day1.html#plan-for-today",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Plan for today",
    "text": "Plan for today\n\nWhat is this course about?\nGet to know your classmates\nShaping our syllabus together\nCreate your personal website!\n\nWebsite content building + connecting with classmates"
  },
  {
    "objectID": "slides/day1.html#what-is-this-course-about",
    "href": "slides/day1.html#what-is-this-course-about",
    "title": "Welcome to Intermediate Data Science!",
    "section": "What is this course about?",
    "text": "What is this course about?\n\nExpanding your abilities for self-reflection in service of:\n\nYour lifelong independent learning\nOur course community\n\nExpanding your data science toolbox:\n\nVisualization\nWrangling\nData acquisition\nData storytelling\n\n\nI’ve intentionally put reflection first and data science skills second not necessarily in order of importance but because cultivating data science skills will come automatically—reflection and community-building won’t."
  },
  {
    "objectID": "slides/day1.html#get-to-know-your-classmates",
    "href": "slides/day1.html#get-to-know-your-classmates",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Get to know your classmates",
    "text": "Get to know your classmates\nIn groups, introduce yourselves with the following prompts: (~2 minutes/person)\n\nName, preferred pronouns\nMacalester connections (e.g., majors/minors/concentrations, clubs, teams, events regularly attended)\nHow are you feeling about starting the academic year?\nWhat is one thing you wish came up more in conversation?\nIf you could use data to investigate anything, what would it be?\n\nWhen we come back together, you will introduce someone else from your group briefly with:\n\nTheir name and preferred pronouns\n1 memorable thing you learned about them from your conversation"
  },
  {
    "objectID": "slides/day1.html#syllabus-shaping-learning-goals",
    "href": "slides/day1.html#syllabus-shaping-learning-goals",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Syllabus shaping: learning goals",
    "text": "Syllabus shaping: learning goals\nNavigate to the Course learning goals section of our syllabus.\nPart 1: Reflect (~3 min)\nWrite a few sentences responding to the following questions:\n\nWhat are your goals in taking this class?\nDo you see your goals reflected in the course learning goals? If not, how would you like to see the course goals amended to see your goals reflected in them?\n\nPart 2: Share (~5 min)\nAt your tables, take turns sharing your responses to the above questions. As a group, summarize your discussion in this Google Doc. Elect 1 person to present this summary when we come together as a class to share."
  },
  {
    "objectID": "slides/day1.html#my-qualms-with-grades",
    "href": "slides/day1.html#my-qualms-with-grades",
    "title": "Welcome to Intermediate Data Science!",
    "section": "My qualms with grades",
    "text": "My qualms with grades\nGrades (final and intermediate letter grades/points) make me uncomfortable because they:\n\nTend to distract from learning (due to a greater focus on the grade than on qualitative feedback)\nCreate anxiety that hinders risk-taking and exploration\nCreate a power dynamic between me and you that I am uncomfortable with. (I feel like a gatekeeper.)\n\nIf I had my way, I would never assign letter grades and only give qualitative comments all semester. Unfortunately, I am required to submit a letter grade at the end of the course.\n\nI need your input: which of the following two grading systems should we use for the semester?"
  },
  {
    "objectID": "slides/day1.html#option-1",
    "href": "slides/day1.html#option-1",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Option 1",
    "text": "Option 1\nSummary: evaluation of learning is done by instructor\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nPass all homework assignments\nPass all but 1 homework assignment\nPass all but 2 homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects"
  },
  {
    "objectID": "slides/day1.html#option-2",
    "href": "slides/day1.html#option-2",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Option 2",
    "text": "Option 2\nSummary: evaluation of learning is done by students in conversation with instructor\nMain difference: The standards below are the basis for your self-evaluation. I will join in on the conversation after reviewing your work and your self-evaluation. We will assign grades through conversation.\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects"
  },
  {
    "objectID": "slides/day1.html#syllabus-shaping-grading-system",
    "href": "slides/day1.html#syllabus-shaping-grading-system",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Syllabus shaping: grading system",
    "text": "Syllabus shaping: grading system\nNavigate to the Grading and feedback section of our syllabus to refer to details of the two grading options as needed.\nPart 1: Reflect (~5 min)\nWrite a few sentences responding to the following questions:\n\nWhich of the two options would be better for motivating you to learn as much as possible, and why? For reducing stress?\nWith regards to motivation and stress, are there any other parts of the course (not directly related to the grading system) that you think would benefit from changing?\n\nPart 2: Share (~10-15 min)\nAt your tables, take turns sharing your responses to the above questions. As a group, summarize your discussion in this Google Doc. Elect 1 person to present this summary when we come together as a class to share."
  },
  {
    "objectID": "slides/day1.html#start-your-personal-website-quarto",
    "href": "slides/day1.html#start-your-personal-website-quarto",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Start your personal website: Quarto",
    "text": "Start your personal website: Quarto\nFile &gt; New Project &gt; New Directory &gt; Quarto Website\n\nName the directory personal_website.\nPut this directory in a place you’ll access beyond this course (and beyond Mac)\n\nSome files will get created in the directory, and your newly created website will open in your browser."
  },
  {
    "objectID": "slides/day1.html#your-quarto-site-what-are-these-files",
    "href": "slides/day1.html#your-quarto-site-what-are-these-files",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Your Quarto site: what are these files?",
    "text": "Your Quarto site: what are these files?\nQuarto markdown files: The formatting in these files is almost identical to RMarkdown files (e.g., * for italics, ** for bold, # for headers).\n\nindex.qmd: This generates the content on the Home page.\nabout.qmd: This generates the content on the About page.\n\nOther files:\n\n_quarto.yml: Controls metadata about the website and how it should be built\nstyles.css: Controls the visual appearance of the site (e.g., color themes, fonts, spacing)\n\nWARNING: The more you know about CSS, the more addicting it is! It is very easy to unintentionally spend hours playing with colors and site appearance. 😆"
  },
  {
    "objectID": "slides/day1.html#todays-goal-the-about-page",
    "href": "slides/day1.html#todays-goal-the-about-page",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Today’s goal: the “About” page",
    "text": "Today’s goal: the “About” page\nOne of the first questions that comes up in every job interview is a question about yourself: “Tell me about yourself. How did you get to this point? What type of work do you want to do?”\nCrafting your homepage and About page can help you prepare for this question and have benefits even before the interview.\nLet’s take a look at an approach for crafting a thoughtful about page."
  },
  {
    "objectID": "slides/day1.html#some-context",
    "href": "slides/day1.html#some-context",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Some context",
    "text": "Some context\nRichard Feynman was a Nobel prize-winning physicist whose contributions fundamentally reshaped our understanding of the physical world.\nA major part of his success was a method for viewing the world: a mindset of viewing the world through the lens of several open-ended questions. Feynman called these his “favorite problems.” He said of these problems:\n\nYou have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did [they] do it? [They] must be a genius!”\nQuote source: Forte Labs"
  },
  {
    "objectID": "slides/day1.html#the-12-favorite-problems-framework",
    "href": "slides/day1.html#the-12-favorite-problems-framework",
    "title": "Welcome to Intermediate Data Science!",
    "section": "The 12 Favorite Problems framework",
    "text": "The 12 Favorite Problems framework\nEveryone can generate a list of their own 12 favorite problems - a set of meaningful open-ended questions that allow you to learn, explore, and act with intention on your biggest interests in life. Their benefits:\n\n\nDedicate your time and attention to ideas that truly spark your curiosity\nSee how a piece of information might be useful and why it’s worth keeping\nSee insightful patterns across multiple subjects that seem unrelated, but might share a common thread\nFocus the impact of your work on problems where you can make a real difference\nPrime your subconscious to notice helpful solutions to your biggest challenges in the world around you\nAttract like-minded people who have the same interests and goals as you\n\nSource: Forte Labs"
  },
  {
    "objectID": "slides/day1.html#brainstorming-our-12-favorite-problems-fps",
    "href": "slides/day1.html#brainstorming-our-12-favorite-problems-fps",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Brainstorming our 12 favorite problems (FPs)",
    "text": "Brainstorming our 12 favorite problems (FPs)\nNavigate to this article by Tiago Forte, and scroll down to the first step “Get started with these prompts.”\nWe’ll take 15-20 minutes to brainstorm our 12 FPs in the about.qmd file of your new website project.\nTiago Forte provides examples of his 12 FPs in his post. Feel free to also look at my own for more examples. (I’m working on updating my 12 FPs today alongside you!)\nWhat does this have to do with data science?? The 12 FP framework is a way of filtering the deluge of information thrown at us to the precious subset that matter most to our deepest questions. In other words, using data of all forms most effectively in our day-to-day lives. I truly believe that adopting this approach will help you become the kinds of data scientists who will be invaluable wherever you go."
  },
  {
    "objectID": "slides/day1.html#sharing-our-12-fps",
    "href": "slides/day1.html#sharing-our-12-fps",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Sharing our 12 FPs",
    "text": "Sharing our 12 FPs\nIn groups, each person will have ~2 minutes to share their top 2 FPs and get some feedback from the group. The group should give feedback to help make the FPs more specific, counterintuitive, and interdiscipinary:\n\nSpecific:\n\nOriginal: “How can I be a better leader?” is a little broad.\nPossible improvement: “How can I be a better leader as an introvert?”\n\nCounterintuitive:\n\nOriginal: “How can I improve the standard of living in the global south?”\nPossible improvement: “How can I improve the standard of living in the global south without further contributing to the climate change that threatens those regions the most?”\n\nInterdisciplinary:\n\nOriginal: How can I improve education?”\nPossible improvement: “How can I improve education by borrowing ideas from video games?”\n\n\n(Examples from Forte Labs)"
  },
  {
    "objectID": "slides/day1.html#free-time",
    "href": "slides/day1.html#free-time",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Free time",
    "text": "Free time\nThe remainder of the class period is free time. Some suggestions for spending the time:\n\nGet up and sit with new people. Share your 12 FPs with each other and get further feedback.\nKeep working on your website. Google to learn more about CSS and play with the appearance of your page in the styles.css file.\nClarify anything about the course with me."
  },
  {
    "objectID": "slides/day1.html#announcements",
    "href": "slides/day1.html#announcements",
    "title": "Welcome to Intermediate Data Science!",
    "section": "Announcements",
    "text": "Announcements\nTo do before class on Thursday:\n\nSet up R and RStudio using these instructions.\nJoin our Slack workspace.\n\nUpdate your Slack profile with preferred name, pronouns, name pronunciation. (To find your profile, click on your name under Direct Messages on the left menu, and click “Edit Profile”.)\nIntroduce yourself in the #general channel.\n\nComplete the pre-course survey.\nLook at the Guiding Questions for Thursday’s class on advanced ggplot2.\nTake a look at Homework 0.\n\nThis is a personal essay that doesn’t need to be turned in.\nTopic: Your 10-year vision\nMy hope is that writing this allows gives you more clarity on how to align what you do this semester (and beyond) with who/what/how you want to be.\n\nFinish writing your 12 favorite problems and post them in the #12-favorite-problems channel on Slack.\n\nWhen you connect with peers from Thursday onward, you’ll be using your 12FPs to get to know each other a bit first before working on activities together."
  },
  {
    "objectID": "syllabus_final.html",
    "href": "syllabus_final.html",
    "title": "Final Syllabus",
    "section": "",
    "text": "Nature doesn’t reveal its secrets easily. - Thomas Kempa\n\nNor do data.\nBut that is exactly what can make data science so thrilling!\nThis course is about empowering you with the wisdom to ask the best questions of data–ones that are meaningful, adaptive, and equity-minded–and the technical savvy to answer them.\nBecause your careers (whether in data science or not), will all involve further learning and working with others, my other primary goal is for you to cultivate self-reflection skills with regards to your own learning and your collaboration with others. In this way, I hope that you feel confident learning new skills on your own in the future and contributing to a welcoming work community.\n\n\n\n\n\n\nCourse catalog description\n\n\n\n\n\nThis second course in the data science curriculum emphasizes advanced data wrangling and manipulation, interactive visualization, writing functions, working with data in databases, version control, and data ethics. Through open-ended and interdisciplinary projects, students practice the constant feedback loop of asking questions of the data, manipulating the data to help answer the question, and then returning to more questions. Prerequisite(s): COMP 112 and COMP 123 and STAT 155; STAT 253 recommended but not required.\n\n\n\n\n\nBy the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(+) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases (*)\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python (*)\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\n\n(+) Collect data ethically in a way that doesn’t undermine communities and people\n\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nYour feedback\n\n\n\nBased on our first day of class discussions, I’ve indicated with a (+) clarifications/details that you added to our existing learning goals and put a (*) next to existing goals that were underscored as desired ones."
  },
  {
    "objectID": "syllabus_final.html#course-learning-goals",
    "href": "syllabus_final.html#course-learning-goals",
    "title": "Final Syllabus",
    "section": "",
    "text": "By the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\n\n(+) Skills to be more self sufficient and resourceful when learning new code\n\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases (*)\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python (*)\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\n\n(+) Collect data ethically in a way that doesn’t undermine communities and people\n\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nYour feedback\n\n\n\nBased on our first day of class discussions, I’ve indicated with a (+) clarifications/details that you added to our existing learning goals and put a (*) next to existing goals that were underscored as desired ones."
  },
  {
    "objectID": "syllabus_final.html#how-to-contact-me",
    "href": "syllabus_final.html#how-to-contact-me",
    "title": "Final Syllabus",
    "section": "How to contact me",
    "text": "How to contact me\n\n\n\n\n\n\nCall me “Leslie”\n\n\n\nStudents sometimes wonder what to call their professors. I prefer to be called Leslie (lez-lee), but if you prefer to be more formal, I am also ok with Professor Myint (pronounced “mee-int”). My preferred gender pronouns are she/her/hers.\nPlease help me make sure that I call you by your preferred name and pronouns too!\n\n\nI love getting to talk to students outside of class time—whether about class-related topics or anything else. Come chat with me!\nI’ll be setting times for drop-in hours based on feedback from the pre-course survey. I’ll update my drop-in hours on our course homepage and Moodle when they’re finalized.\nI’m also happy to meet one-on-one if my normal drop-in hours don’t work. You can schedule a time to meet with me via Calendly.\nI’ll also often be in the Leonard Center weight room from about 4:30-5:10 some weekdays. Feel free to say hello!"
  },
  {
    "objectID": "syllabus_final.html#discussion-board-slack",
    "href": "syllabus_final.html#discussion-board-slack",
    "title": "Final Syllabus",
    "section": "Discussion board (Slack)",
    "text": "Discussion board (Slack)\nSlack is a commonly used communication tool in industry and is useful to be familiar with, so we’ll be using it as our discussion board.\n\nIf you’re new to Slack, this video provides a quick overview.\nFirst join our STAT/COMP 212: Fall 2023 workspace here.\nAfter joining, you can access our workspace here. (You might want to bookmark this if you have Slack open in your web broswer.)"
  },
  {
    "objectID": "syllabus_final.html#community-is-key",
    "href": "syllabus_final.html#community-is-key",
    "title": "Final Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nOur class is participating in the Classroom Community & Connectedness Project this semester. On Thursday, September 21 our class sessions will be a facilitated class activity (peers and facilitators only; I will not be present) to collectively reflect on strengthening our classroom community, with the intent of improving the learning environment for all of us.\nYour participation is voluntary, but very much appreciated. The project is co-sponsored by Macalester’s Serie Center for Scholarship and Teaching and our Office of Institutional Research & Assessment."
  },
  {
    "objectID": "syllabus_final.html#reflection-is-paramount",
    "href": "syllabus_final.html#reflection-is-paramount",
    "title": "Final Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that as technology evolves, some part of it will become out of date during your careers. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content–it’s fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection as a goal for our course in both content learning and collaborative activities. (Note that these reflection goals are the first two course learning goals.)"
  },
  {
    "objectID": "syllabus_final.html#mistakes-are-essential",
    "href": "syllabus_final.html#mistakes-are-essential",
    "title": "Final Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field. - Niels Bohr, Nobel Prize-winning physicist\n\nI don’t feel comfortable working with a new R package until I’ve seen the same errors over and over again. Seeing new errors helps me understand the constraints of the code and the assumptions that I was making about my data.\nWe’re going to be seeking out mistakes like my cats hunt for leftover food scraps.\n\n\n\nMy cat Potato attempting to eat my daughter’s dinner"
  },
  {
    "objectID": "syllabus_final.html#communication-is-a-superpower",
    "href": "syllabus_final.html#communication-is-a-superpower",
    "title": "Final Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas–whether through writing, visuals, or oral presentation–I want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What’s more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n— David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus_final.html#outside-of-class",
    "href": "syllabus_final.html#outside-of-class",
    "title": "Final Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class reading: Most class periods will have a required reading to review ideas from previous courses or to familiarize yourself with new concepts before seeing them again in class. My goal for these readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. I will provide Guiding Questions for each reading to focus your attention.\n\n\n\n\n\n\nSuggestion\n\n\n\nScan the Guiding Questions before reading to preview the main ideas. Fill in answers to these questions as you read. Ask (and answer!) questions in the #questions channel in our Slack workspace.\n\n\nPodcast discussions: About every other week, we will discuss a podcast for the first ~20 minutes of class. These podcasts are meant to expose you aspects of data science in industry. Record anything that you’re curious about, and come prepared to discuss.\n\n\n\n\n\n\nYour own media contributions\n\n\n\nThroughout the semester, if you come across any media that is relevant to the course, feel free to suggest it as a discussion piece by emailing the instructor or posting it in the #general channel in our Slack workspace.\n\n\n\n\n\n\n\n\nOther suggestions for out-of-class time\n\n\n\n\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the weekly homework.\nCome to instructor drop-in hours to chat about the course or anything else 😃"
  },
  {
    "objectID": "syllabus_final.html#during-class",
    "href": "syllabus_final.html#during-class",
    "title": "Final Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.) I’ll always leave a few minutes at the end of class for synthesis. Use this time to update your reflections and summarize the key takeaways from class."
  },
  {
    "objectID": "syllabus_final.html#instructors-philosophy",
    "href": "syllabus_final.html#instructors-philosophy",
    "title": "Final Syllabus",
    "section": "Instructor’s philosophy",
    "text": "Instructor’s philosophy\nFor a long time, I have been uncomfortable with the outsized role that letter grades play in education. The article Teaching More by Grading Less (Or Differently) by Schinske and Tanner (source) shaped many of my viewpoints and may be an interesting read for you.\nIn short, grades tend to distract from learning (due to a greater focus on the grade than on qualitative feedback), create anxiety that hinders risk-taking and exploration, and create a power dynamic between the instructor and students that I am uncomfortable with.\nIf I had my way, I would never assign letter grades and only give qualitative comments all semester. Unfortunately, I am required to submit a letter grade at the end of the course.\n\nThere were two grading options presented in the preliminary syllabus. The consensus of both course sections was Option 2, which is detailed below."
  },
  {
    "objectID": "syllabus_final.html#grading-system",
    "href": "syllabus_final.html#grading-system",
    "title": "Final Syllabus",
    "section": "Grading system",
    "text": "Grading system\n\nOverview\nIn the grading system chosen, evaluation (assigning of letter grades) occurs as a conversation between you and me–a conversation that you start. Using the qualities of A, B, and C letter grades (section below), you will self-assess your work using more detailed evaluation guidelines provided in reflection prompts and comments on your work. As part of this assessment you will propose your letter grade. I will also do this evaluation on my own and read your self-assessment afterwards. We will use all of this information to have a conversation about your progress. If we agree on the letter grade, that will be the grade you receive. If we disagree, we will use our conversation to come to a consensus. As part of consensus-building, we may discuss reframing both of our perspectives or additional work/revisions.\nI recognize that no single grading system can be ideal for everyone, but I do hope that the reflection, honesty, and conversation that are central to this system support your learning. Please reach out to me if something could be going better for you. I am always willing to talk. It’s your education–I want you to have a voice in it.\n\n\nWhat kind of work characterizes A, B, and C grades?\nThe table below describes the qualities of A, B, and C grades in terms of the 3 core course components: reflections, homework, and the final project.\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\nDetails about the course components are given below:\n\nSelf-reflection:\n\nWe will look at the growth in your reflection process over the course of 3 substantive reflections. These will roughly come a month into the course, mid-course, and the end of the semester.\n\nMy expectation is that your mid-course and end-of-course reflections show that your are using feedback from previous reflections.\n\nWe will look at the consistency in your reflection process by monitoring your Process and Reflection Google Doc.\n\nMy expectation is that you are filling this in regularly throughout class activities and through work outside of class.\n\n\nHomework: We will have weekly homework in which you will complete activities that we start in class. The requirements for passing the assignment will be clearly stated in the homework directions.\n\nIf you do not pass an assignment and wish to revise your work, you may resubmit the assignment the following week. This revision needs to be submitted by 2 weeks after the original homework due date. (See my policy on late work.)\n\nFinal project: For this semester-long project, you will receive regular feedback on the quality of the different project aspects and will have the opportunity to improve the quality of the different aspects as you continue working.\n\n\n\nHow will course components be evaluated?\nIn each of the 3 substantive reflections (month, mid-semester, end-of-semester), you will evaluate yourselves using self-assessment prompts and qualitative feedback from me on your reflections, homework, and project work.\nFor each of the 3 substantive reflections, you will receive a prompt that guides you through how to look at your work, my comments, solutions, and prior reflections to craft your self-assessment on your reflection process, homework, and project work. I will use the same prompts/process to assess your work before we come together for conversation.\nNote: Your self-assessments need to be based on demonstrated evidence in the work that you submit. For example, if you have struggled with the data wrangling homework assignments and say in your self-evaluation that your understanding is now strong after reviewing feedback, this is not sufficient evidence. You would need to demonstrate your stronger understanding of data wrangling by submitting a revision of the data wrangling homework. (See policy on late work.)"
  },
  {
    "objectID": "syllabus_final.html#late-work",
    "href": "syllabus_final.html#late-work",
    "title": "Final Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will be due weekly on Wednesdays at midnight. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. Limited extensions will always be granted:\n\nMy ideal extension: Turn in the homework by the following Monday morning at 9am. (A 4 day, 9 hour extension)\n\nWhy is this ideal for me? I want to return feedback on homework to everyone before the following Tuesday’s class because we will be briefly reviewing homework feedback in small groups.\n\nFirm limit on extensions: You must turn in the homework by 2 weeks after the due date (Wednesdays at 9am).\n\nWhy is this my firm limit? I post solutions to the homework at this point.\nWhat if it’s past the 2-week limit and you still want to turn in the homework in some form? If this is the case, you need to create your own equivalent homework. This involves mapping the original homework’s exercises to a new dataset and completing those exercises. Note that I can’t make any guarantees about when I can get you feedback on this late submission. (Only guarantee = by the end of the semester)"
  },
  {
    "objectID": "syllabus_final.html#academic-integrity",
    "href": "syllabus_final.html#academic-integrity",
    "title": "Final Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus_final.html#artificial-intelligence-ai-use",
    "href": "syllabus_final.html#artificial-intelligence-ai-use",
    "title": "Final Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nLearning to use AI tools is an emerging skill that we will explore together in this course. I expect you to use AI (ChatGPT, Google Bard)—in fact, some assignments may require it.\nHowever, you should be aware of the limits of AI:\n\nAI is a tool, but one that you need to acknowledge using. Any ideas, language, or code that is produced by AI must be cited, just like any other resource. [sample suggestion: Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you used to get the results.] Failure to do so is in violation of the academic integrity policy at Macalester College.\nDon’t trust anything AI says. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you understand.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nHow to cite usage of AI: Please copy and paste all prompts and output into an Appendix section accompanying each problem of an assignment.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "syllabus_prelim.html",
    "href": "syllabus_prelim.html",
    "title": "Preliminary Syllabus",
    "section": "",
    "text": "Nature doesn’t reveal its secrets easily. - Thomas Kempa\n\nNor do data.\nBut that is exactly what can make data science so thrilling!\nThis course is about empowering you with the wisdom to ask the best questions of data–ones that are meaningful, adaptive, and equity-minded–and the technical savvy to answer them.\nBecause your careers (whether in data science or not), will all involve further learning and working with others, my other primary goal is for you to cultivate self-reflection skills with regards to your own learning and your collaboration with others. In this way, I hope that you feel confident learning new skills on your own in the future and contributing to a welcoming work community.\n\n\n\n\n\n\nCourse catalog description\n\n\n\n\n\nThis second course in the data science curriculum emphasizes advanced data wrangling and manipulation, interactive visualization, writing functions, working with data in databases, version control, and data ethics. Through open-ended and interdisciplinary projects, students practice the constant feedback loop of asking questions of the data, manipulating the data to help answer the question, and then returning to more questions. Prerequisite(s): COMP 112 and COMP 123 and STAT 155; STAT 253 recommended but not required.\n\n\n\n\n\nBy the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nReflect\n\n\n\n\nWhich of the learning goals above do you disagree with or want more clarity on?\nDo you have any goals that you’d like to include on this list?"
  },
  {
    "objectID": "syllabus_prelim.html#course-learning-goals",
    "href": "syllabus_prelim.html#course-learning-goals",
    "title": "Preliminary Syllabus",
    "section": "",
    "text": "By the end of this course you should be able to:\n\nSustain a habit of self-reflection in your learning process so that you are equipped for independent learning\nSustain a habit of self-reflection in your collaborative work so that you can form community no matter where you go\nCreate a variety of visualizations in ggplot2 that go beyond the plot types that you learned in STAT/COMP 112\nWrangle and visualize spatial data\nCreate interactive web applications and visualizations that adapt to user input\nWrangle arbitrarily messy data using functional programming tools in R\nAcquire data from a variety of sources\n\nWrite statements in structured query language (SQL) to access data from databases\nWrite code to access data from application programming interfaces (APIs)\nWrite code to scrape data from websites and evaluate the ethics of collecting such data\n\nUse appropriate methods when working with missing data\nTranslate code between R and Python\nArticulate the role of machine learning and causal inference in data science work\nIterate on the question-explore-question cycle to craft compelling data stories with attention to ethical considerations\nMaintain a digital portfolio of your data science projects\n\n\n\n\n\n\n\nReflect\n\n\n\n\nWhich of the learning goals above do you disagree with or want more clarity on?\nDo you have any goals that you’d like to include on this list?"
  },
  {
    "objectID": "syllabus_prelim.html#how-to-contact-me",
    "href": "syllabus_prelim.html#how-to-contact-me",
    "title": "Preliminary Syllabus",
    "section": "How to contact me",
    "text": "How to contact me\n\n\n\n\n\n\nCall me “Leslie”\n\n\n\nStudents sometimes wonder what to call their professors. I prefer to be called Leslie (lez-lee), but if you prefer to be more formal, I am also ok with Professor Myint (pronounced “mee-int”). My preferred gender pronouns are she/her/hers.\nPlease help me make sure that I call you by your preferred name and pronouns too!\n\n\nI love getting to talk to students outside of class time—whether about class-related topics or anything else. Come chat with me!\nI’ll be setting times for drop-in hours based on feedback from the pre-course survey. I’ll update my drop-in hours on our course homepage and Moodle when they’re finalized.\nI’m also happy to meet one-on-one if my normal drop-in hours don’t work. You can schedule a time to meet with me via Calendly.\nI’ll also often be in the Leonard Center weight room from about 4:30-5:10 some weekdays. Feel free to say hello!"
  },
  {
    "objectID": "syllabus_prelim.html#discussion-board-slack",
    "href": "syllabus_prelim.html#discussion-board-slack",
    "title": "Preliminary Syllabus",
    "section": "Discussion board (Slack)",
    "text": "Discussion board (Slack)\nSlack is a commonly used communication tool in industry and is useful to be familiar with, so we’ll be using it as our discussion board.\n\nIf you’re new to Slack, this video provides a quick overview.\nFirst join our STAT/COMP 212: Fall 2023 workspace here.\nAfter joining, you can access our workspace here. (You might want to bookmark this if you have Slack open in your web broswer.)"
  },
  {
    "objectID": "syllabus_prelim.html#community-is-key",
    "href": "syllabus_prelim.html#community-is-key",
    "title": "Preliminary Syllabus",
    "section": "Community is key",
    "text": "Community is key\nA sense of community and connectedness can provide a powerful environment for learning: Research shows that learning is maximized when students feel a sense of belonging in the educational environment (e.g., Booker, 2016). A negative climate may create barriers to learning, while a positive climate can energize students’ learning (e.g., Pascarella & Terenzini, cited in How Learning Works, 2012).\nOur class is participating in the Classroom Community & Connectedness Project this semester. On Thursday, September 21 our class sessions will be a facilitated class activity (peers and facilitators only; I will not be present) to collectively reflect on strengthening our classroom community, with the intent of improving the learning environment for all of us.\nYour participation is voluntary, but very much appreciated. The project is co-sponsored by Macalester’s Serie Center for Scholarship and Teaching and our Office of Institutional Research & Assessment."
  },
  {
    "objectID": "syllabus_prelim.html#reflection-is-paramount",
    "href": "syllabus_prelim.html#reflection-is-paramount",
    "title": "Preliminary Syllabus",
    "section": "Reflection is paramount",
    "text": "Reflection is paramount\nThe content you learn will be cool (unbiased opinion!), but it is a guarantee that as technology evolves, some part of it will become out of date during your careers. What you will need to rely on when you leave Macalester is what I want to ensure you cultivate now: a good learning process. And the cornerstone of a good learning process is reflection.\nReflection is not just fundamental to learning content–it’s fundamental to learning any sort of intellectual, emotional, or physical skill. For this reason, I will be prioritizing reflection as a goal for our course in both content learning and collaborative activities. (Note that these reflection goals are the first two course learning goals.)"
  },
  {
    "objectID": "syllabus_prelim.html#mistakes-are-essential",
    "href": "syllabus_prelim.html#mistakes-are-essential",
    "title": "Preliminary Syllabus",
    "section": "Mistakes are essential",
    "text": "Mistakes are essential\n\nAn expert is a person who has made all the mistakes which can be made in a narrow field. - Niels Bohr, Nobel Prize-winning physicist\n\nI don’t feel comfortable working with a new R package until I’ve seen the same errors over and over again. Seeing new errors helps me understand the constraints of the code and the assumptions that I was making about my data.\nWe’re going to be seeking out mistakes like my cats hunt for leftover food scraps.\n\n\n\nMy cat Potato attempting to eat my daughter’s dinner"
  },
  {
    "objectID": "syllabus_prelim.html#communication-is-a-superpower",
    "href": "syllabus_prelim.html#communication-is-a-superpower",
    "title": "Preliminary Syllabus",
    "section": "Communication is a superpower",
    "text": "Communication is a superpower\nEvery time I go to a conference talk on a technical topic, it is striking how quickly laptops or phones come out because of the inability to follow. Academics notoriously struggle to make ideas accessible to others.\nI want communication to be very different for you.\nEvery time you communicate ideas–whether through writing, visuals, or oral presentation–I want you to be a total boss. The end product of strong communication is a better experience for all those who have given you their attention. What’s more, the process of crafting effective communication is invaluable for deepening your own understanding:\n\n\n\nRead to collect the dots, write to connect them pic.twitter.com/YbgnKKFUNn\n\n— David Perell (@david_perell) July 5, 2021"
  },
  {
    "objectID": "syllabus_prelim.html#outside-of-class",
    "href": "syllabus_prelim.html#outside-of-class",
    "title": "Preliminary Syllabus",
    "section": "Outside of class",
    "text": "Outside of class\nPre-class reading: Most class periods will have a required reading to review ideas from previous courses or to familiarize yourself with new concepts before seeing them again in class. My goal for these readings is for you to get the most out of class time by being able to more easily follow explanations in class and to engage most fully in class activities. I will provide Guiding Questions for each reading to focus your attention.\n\n\n\n\n\n\nSuggestion\n\n\n\nScan the Guiding Questions before reading to preview the main ideas. Fill in answers to these questions as you read. Ask (and answer!) questions in the #questions channel in our Slack workspace.\n\n\nPodcast discussions: About every other week, we will discuss a podcast for the first ~20 minutes of class. These podcasts are meant to expose you aspects of data science in industry. Record anything that you’re curious about, and come prepared to discuss.\n\n\n\n\n\n\nYour own media contributions\n\n\n\nThroughout the semester, if you come across any media that is relevant to the course, feel free to suggest it as a discussion piece by emailing the instructor or posting it in the #general channel in our Slack workspace.\n\n\n\n\n\n\n\n\nOther suggestions for out-of-class time\n\n\n\n\nRecord any reflections from in-class time about your learning process or interactions with peers while they are still fresh.\nAfter learning a new topic in class, it is helpful to immediately attempt the related exercises on the weekly homework.\nCome to instructor drop-in hours to chat about the course or anything else 😃"
  },
  {
    "objectID": "syllabus_prelim.html#during-class",
    "href": "syllabus_prelim.html#during-class",
    "title": "Preliminary Syllabus",
    "section": "During class",
    "text": "During class\nClass time will be a mix of interactive lecture and longer stretches of group work. During the lecture portion, I will pause explanation frequently to prompt a short exercise or ask questions that you’ll reflect on individually or together.\n\n\n\n\n\n\nSuggestion\n\n\n\nReview your learning process and group work reflections just before class to frame how you want to engage in class. (Perhaps you’ve noted a struggle and want to try a new strategy.) I’ll always leave a few minutes at the end of class for synthesis. Use this time to update your reflections and summarize the key takeaways from class."
  },
  {
    "objectID": "syllabus_prelim.html#option-1-evaluation-of-learning-is-done-by-instructor",
    "href": "syllabus_prelim.html#option-1-evaluation-of-learning-is-done-by-instructor",
    "title": "Preliminary Syllabus",
    "section": "Option 1: evaluation of learning is done by instructor",
    "text": "Option 1: evaluation of learning is done by instructor\nThe table below describes the qualities of A, B, and C grades in terms of the 3 core course components: reflections, homework, and the final project.\nIn order to earn a given letter grade, ALL of the requirements in the column must be met. (e.g., In order to earn an A, everything in the first column must be true.)\nThere is a possibility that by the end of the semester, work for the different course components falls under different letter grades. (e.g., A-level for reflections and homework, but B-level for project).\n\nIf this happens, towards the end of the semester I will ask you to submit a written justification for the grade that you think you deserve. We will have a conference in which we discuss your justification.\nIf we agree, your proposed grade will be your final grade.\nIf we disagree, we will discuss what needs to be done next to come to an agreement. (This may involve being doing extra work or revisions.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nPass all homework assignments\nPass all but 1 homework assignment\nPass all but 2 homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\nDetails about the course components are given below:\n\nSelf-reflection:\n\nI will look at the growth in your reflection process over the course of 3 substantive reflections. These will roughly come a month into the course, mid-course, and the end of the semester.\n\nMy expectation is that your mid-course and end-of-course reflections show that your are using feedback from previous reflections.\n\nI will look at the consistency in your reflection process by monitoring your Process and Reflection Google Doc.\n\nMy expectation is that you are filling this in regularly throughout class activities and through work outside of class.\n\n\nHomework: We will have weekly homework in which you will complete activities that we start in class. The requirements for passing the assignment will be clearly stated in the homework directions.\n\nIf you do not pass an assignment and wish to revise your work, you may resubmit the assignment the following week. This revision needs to be submitted by 2 weeks after the original homework due date. (See my policy on late work.)\n\nFinal project: For this semester-long project, you will receive regular feedback on the quality of the different project aspects and will have the opportunity to improve the quality of the different aspects as you continue working."
  },
  {
    "objectID": "syllabus_prelim.html#option-2-evaluation-of-learning-is-done-by-students-in-conversation-with-instructor",
    "href": "syllabus_prelim.html#option-2-evaluation-of-learning-is-done-by-students-in-conversation-with-instructor",
    "title": "Preliminary Syllabus",
    "section": "Option 2: evaluation of learning is done by students in conversation with instructor",
    "text": "Option 2: evaluation of learning is done by students in conversation with instructor\nWhat constitutes A, B, and C-level work is essentially identical in Options 1 and 2 (see table below). That is, my standards for high quality work are the same between the two.\nWhat’s different is how (who) participates in the evaluation process. In Option 1, I am making the final judgment on the quality of your work for all course components. In Option 2, you will start the assessment of quality by evaluating yourselves using qualitative feedback on all of your work.\nIn Option 2, the qualitative comments that you receive on all your work (reflections, homework, project) will form the basis of your self-evaluation. That is, you will review all comments from me and use this to gauge the degree to which you are meeting the course learning goals. (On homework, you will not receive a pass/not passing designation—you’ll just receive comments.) You will write self-evaluations ~1 month into the semester, in the middle of the semester (before midterm grades are due), and a final one at the end of the semester. In all of these self-evaluations, you will propose the grade that you think deserve. I will also evaluate your work, and if we disagree on the grade, we will meet to discuss what needs to be done next to come to an agreement. (This may involve being doing extra work or revisions.)\nNote: Your self-evaluations need to be based on demonstrated evidence in the work that you submit. For example, if you have struggled with the data wrangling homework assignments and say in your self-evaluation that your understanding is now strong after reviewing feedback, this is not sufficient evidence. You would need to demonstrate your stronger understanding of data wrangling by submitting a revision of the data wrangling homework. (See policy on late work.)\n\n\n\n\n\n\n\n\n\nCourse component\nLetter grade: A\nLetter grade: B\nLetter grade: C\n\n\n\n\nSelf-reflection in learning process\nShow clear growth and consistent thoughtfulness throughout the semester\nShow some growth and some thoughtfulness throughout the semester\nShow little to no growth and minimal thoughtfulness throughout the semester\n\n\nSelf-reflection in collaborative learning (groupwork)\n\n\nWeekly homework\nShow strong understanding of concepts across all homework assignments\nShow strong understanding of concepts across most homework assignments\nShow adequate understanding of concepts across most homework assignments\n\n\nFinal project\nComplete a project that is high quality in all of the following aspects:\n\nData wrangling, visualization, analysis, and interpretation\nWorkflow and organization\nAddressing peer and instructor feedback\nGiving feedback to peers\nEthical consideration and communication of results\n\nComplete a project that is at least ok quality in the aforementioned aspects and high quality in some aspects\nComplete a project that is ok quality in the aforementioned aspects\n\n\n\n\n\n\n\n\n\nComparing Options 1 and 2\n\n\n\nBoth options satisfy my goal to have high standards for your learning that are achievable through thoughtful revision. No matter what option we use, you’ll have a personal Google Sheet for tracking your progress over time.\nMy other goals for our grading system are for it to motivate you to learn as much as possible and to reduce stress. For these goals, your input during our Day 1 discussion will be very valuable."
  },
  {
    "objectID": "syllabus_prelim.html#late-work",
    "href": "syllabus_prelim.html#late-work",
    "title": "Preliminary Syllabus",
    "section": "Late work",
    "text": "Late work\nHomework assignments will be due weekly on Wednesdays at midnight. If you anticipate needing more time to complete an assignment, please email me ahead of time to discuss. Limited extensions will always be granted:\n\nMy ideal extension: Turn in the homework by the following Monday morning at 9am. (A 4 day, 9 hour extension)\n\nWhy is this ideal for me? I want to return feedback on homework to everyone before the following Tuesday’s class because we will be briefly reviewing homework feedback in small groups.\n\nFirm limit on extensions: You must turn in the homework by 2 weeks after the due date (Wednesdays at 9am).\n\nWhy is this my firm limit? I post solutions to the homework at this point.\nWhat if it’s past the 2-week limit and you still want to turn in the homework in some form? If this is the case, you need to create your own equivalent homework. This involves mapping the original homework’s exercises to a new dataset and completing those exercises. Note that I can’t make any guarantees about when I can get you feedback on this late submission. (Only guarantee = by the end of the semester)"
  },
  {
    "objectID": "syllabus_prelim.html#academic-integrity",
    "href": "syllabus_prelim.html#academic-integrity",
    "title": "Preliminary Syllabus",
    "section": "Academic integrity",
    "text": "Academic integrity\nAcademic integrity is the cornerstone of our learning community. Students are expected to be familiar with the college’s standards on academic integrity.\nI encourage you to work with your classmates to discuss material and ideas for assignments, but in order for you to receive individualized feedback on your own learning, you must submit your own work. This involves writing your own code and putting explanations into your own words. Always cite any sources you use, including AI (see section below)."
  },
  {
    "objectID": "syllabus_prelim.html#artificial-intelligence-ai-use",
    "href": "syllabus_prelim.html#artificial-intelligence-ai-use",
    "title": "Preliminary Syllabus",
    "section": "Artificial intelligence (AI) use",
    "text": "Artificial intelligence (AI) use\nLearning to use AI tools is an emerging skill that we will explore together in this course. I expect you to use AI (ChatGPT, Google Bard)—in fact, some assignments may require it.\nHowever, you should be aware of the limits of AI:\n\nAI is a tool, but one that you need to acknowledge using. Any ideas, language, or code that is produced by AI must be cited, just like any other resource. [sample suggestion: Please include a paragraph at the end of any assignment that uses AI explaining what you used the AI for and what prompts you used to get the results.] Failure to do so is in violation of the academic integrity policy at Macalester College.\nDon’t trust anything AI says. If it gives you a number, fact, or code, assume it is wrong unless you either know the answer or can check in with another source. AI works best for topics you understand.\nIf you provide minimum effort prompts, you will get low quality results. You will need to refine your prompts in order to get good outcomes. This will take work.\nBe thoughtful about when this tool is useful. Don’t use it if it isn’t appropriate for the case or circumstance.\nThe environmental impact of AI should not be ignored. The building and usage of AI tools consumes a lot of energy (see here and here). For this reason, we will be very thoughtful about when we use AI and will discuss other sustainability behaviors that we can incorporate into our lives to offset this usage.\n\nHow to cite usage of AI: Please copy and paste all prompts and output into an Appendix section accompanying each problem of an assignment.\nIf you have any questions about your use of AI tools, please contact me to discuss them."
  },
  {
    "objectID": "tech_setup.html",
    "href": "tech_setup.html",
    "title": "Tech Setup",
    "section": "",
    "text": "Ideally before class on Tuesday, September 5 and definitely before class on Thursday, September 7, you should follow these instructions to set up the software that we’ll be using throughout the semester. Even if you’ve already downloaded both R and RStudio, you’ll want to re-download to make sure that you have the most current versions.\n\nRequired: Change the default file download location for your internet browser.\n\nGenerally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\nRequired: (Re)Download R and RStudio\n\nFIRST: Download R here.\n\nIn the top section, tou will see three links “Download R for …”\nChoose the link that corresponds to your computer.\nAs of September 1, 2023, the latest version of R is 4.3.1 (“Beagle Scouts”).\n\nSECOND: Download RStudio here.\n\nClick the button under step 2 to install the version of RStudio recommended for your computer.\nAs of September 1, 2023, the latest version of RStudio is 2023.06.2+561.\n\nTHIRD: Check that when you go to File &gt; New Project &gt; New Directory, you see “Quarto Website” as an option.\n\n\nSuggested: Watch this video describing key configuration options for RStudio.\n\nRequired: Install required packages.\n\nAn R package is an extra bit of functionality that will help us in our data analysis efforts in a variety of ways.\nOpen RStudio and click inside the Console pane (by default, the bottom left pane). Copy and paste the following command into the Console. You should see the text below appear to the right of the &gt;, which is called the R prompt. After you paste, hit Enter.\n\n\ninstall.packages(c(\"tidyverse\"))\n\n\nYou will see a lot of text from status messages appearing in the Console as the packages are being installed. Wait until you see the &gt; again.\nEnter the command library(tidyverse) and hit Enter.\nIf you see an error message, then there was a problem installing the package. Post the full error message in the #questions channel in our Slack workspace and\nQuit RStudio. You’re done setting up!\n\nOptional: For a refresher on RStudio features, watch this video. It also shows you how to customize the layout and color scheme of RStudio."
  },
  {
    "objectID": "workflow_files_rstudio.html",
    "href": "workflow_files_rstudio.html",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers.\n\n\n\n\nWhen working on any data science project, I recommend setting up the directory (folder) structure below. Sub-bullets indicate folders that are inside other folders.\n\nDocuments (This should be some place you can find easily through your Finder (Mac) or File Explorer (Windows).)\n\ndescriptive_project_name\n\ncode\n\nraw: For messy code that you’re actively working on\nclean: For code that you have cleaned up, documented, organized, and tested to run as expected\n\ndata\n\nraw: Original data that hasn’t been cleaned\nclean: Any non-original data that has been processed in some way\n\nresults\n\nfigures: Plots that will be used in communicating your project should go here. (Using screenshots of output in RStudio is not a good practice.)\ntables: Any sort of plain text file results (e.g., CSVs)\n\n\n\n\nFrom this point onward, we will use a simplified version of this directory structure for all of our class activities.\n\n\nCreate a folder for this course in a place you can find easily through your Finder (Mac) or File Explorer (Windows). The name of this folder should not have spaces (use underscores _ instead). Suggestion: STAT212 or COMP212\nOrganize your files from class using the following directory structure:\n\nSTAT212 (or COMP212)\n\nadvanced_ggplot (For our Advanced visualization in ggplot2 activity)\n\ncode\n\n02-adv-ggplot.qmd\n\ndata\n\nadvanced_maps (For our Advanced map visualization activity)\n\ncode\n\n03-adv-maps.qmd\n\ndata\n\napportionment.csv\nshp_loc_pop_centers (From shp_loc_pop_centers.zip)\nshp_water_lakes_rivers (From shp_water_lakes_rivers.zip)\nus_states_hexgrid.geojson\n\n\n\n\n\n\n\nIn a code file, when you read in data from a source on your computer, you need to specify the file path correctly. The file path is a text string that tells you how to get from your code file to the data. There are two types of paths: absolute and relative.\nAbsolute file paths start at the “root” directory in a computer system. Examples:\n\nMac: /Users/lesliemyint/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nOn a Mac the tilde ~ in a file path refers to the “Home” directory, which is /Users/lesliemyint. In this case, the path becomes ~/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nWindows: C:/Users/lesliemyint/Documents/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nNote: Windows uses both / (forward slash) and \\ (backward slash) to separate folders in a file path.\n\n\n\nRelative file paths start wherever you are right now (the working directory (WD)). The WD when you’re working in a code file may be different from the working directory in the Console.\nDirectory setup 1: Data is in same folder as code file\n\nsome_folder\n\nyour_code_file.qmd\ndata.csv\n\n\nThere are two options for the relative path:\n\n./data.csv (The ./ refers to the current working directory.)\ndata.csv\n\nDirectory setup 2: Data is within a subfolder called data\n\nsome_folder\n\nyour_code_file.qmd\ndata\n\ndata.csv\n\n\n\nThe relative path would be data/data.csv. (Note: ./data/data.csv would also work.)\nDirectory setup 3: Need to go to a “parent” folder first to get to the data\n\nsome_folder\n\ndata.csv\ncode\n\nyour_code_file.qmd\n\n\n\nTo go “up” a folder in a relative path we use ../.\nThe relative path here would be ../data.csv.\n\n\n\nIn 03-adv-maps.qmd, navigate to the code chunk where you read in us_states_hexgrid.geojson, apportionment.csv, shp_loc_pop_centers, and shp_water_lakes_rivers.\nUpdate the file paths to correctly find the data in the new directory structure."
  },
  {
    "objectID": "workflow_files_rstudio.html#change-the-default-file-download-location-for-your-internet-browser",
    "href": "workflow_files_rstudio.html#change-the-default-file-download-location-for-your-internet-browser",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "Generally by default, internet browsers automatically save all files to the Downloads folder on your computer. This does not encourage good file organization practices. You need to change this option so that your browser asks you where to save each file before downloading it.\nThis page has information on how to do this for the most common browsers."
  },
  {
    "objectID": "workflow_files_rstudio.html#folderdirectory-structure",
    "href": "workflow_files_rstudio.html#folderdirectory-structure",
    "title": "Workflow: Files and RStudio setup",
    "section": "",
    "text": "When working on any data science project, I recommend setting up the directory (folder) structure below. Sub-bullets indicate folders that are inside other folders.\n\nDocuments (This should be some place you can find easily through your Finder (Mac) or File Explorer (Windows).)\n\ndescriptive_project_name\n\ncode\n\nraw: For messy code that you’re actively working on\nclean: For code that you have cleaned up, documented, organized, and tested to run as expected\n\ndata\n\nraw: Original data that hasn’t been cleaned\nclean: Any non-original data that has been processed in some way\n\nresults\n\nfigures: Plots that will be used in communicating your project should go here. (Using screenshots of output in RStudio is not a good practice.)\ntables: Any sort of plain text file results (e.g., CSVs)\n\n\n\n\nFrom this point onward, we will use a simplified version of this directory structure for all of our class activities.\n\n\nCreate a folder for this course in a place you can find easily through your Finder (Mac) or File Explorer (Windows). The name of this folder should not have spaces (use underscores _ instead). Suggestion: STAT212 or COMP212\nOrganize your files from class using the following directory structure:\n\nSTAT212 (or COMP212)\n\nadvanced_ggplot (For our Advanced visualization in ggplot2 activity)\n\ncode\n\n02-adv-ggplot.qmd\n\ndata\n\nadvanced_maps (For our Advanced map visualization activity)\n\ncode\n\n03-adv-maps.qmd\n\ndata\n\napportionment.csv\nshp_loc_pop_centers (From shp_loc_pop_centers.zip)\nshp_water_lakes_rivers (From shp_water_lakes_rivers.zip)\nus_states_hexgrid.geojson\n\n\n\n\n\n\n\nIn a code file, when you read in data from a source on your computer, you need to specify the file path correctly. The file path is a text string that tells you how to get from your code file to the data. There are two types of paths: absolute and relative.\nAbsolute file paths start at the “root” directory in a computer system. Examples:\n\nMac: /Users/lesliemyint/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nOn a Mac the tilde ~ in a file path refers to the “Home” directory, which is /Users/lesliemyint. In this case, the path becomes ~/Desktop/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nWindows: C:/Users/lesliemyint/Documents/teaching/STAT212/2023_fall/class_activities/advanced_maps/us_states_hexgrid.geojson\n\nNote: Windows uses both / (forward slash) and \\ (backward slash) to separate folders in a file path.\n\n\n\nRelative file paths start wherever you are right now (the working directory (WD)). The WD when you’re working in a code file may be different from the working directory in the Console.\nDirectory setup 1: Data is in same folder as code file\n\nsome_folder\n\nyour_code_file.qmd\ndata.csv\n\n\nThere are two options for the relative path:\n\n./data.csv (The ./ refers to the current working directory.)\ndata.csv\n\nDirectory setup 2: Data is within a subfolder called data\n\nsome_folder\n\nyour_code_file.qmd\ndata\n\ndata.csv\n\n\n\nThe relative path would be data/data.csv. (Note: ./data/data.csv would also work.)\nDirectory setup 3: Need to go to a “parent” folder first to get to the data\n\nsome_folder\n\ndata.csv\ncode\n\nyour_code_file.qmd\n\n\n\nTo go “up” a folder in a relative path we use ../.\nThe relative path here would be ../data.csv.\n\n\n\nIn 03-adv-maps.qmd, navigate to the code chunk where you read in us_states_hexgrid.geojson, apportionment.csv, shp_loc_pop_centers, and shp_water_lakes_rivers.\nUpdate the file paths to correctly find the data in the new directory structure."
  },
  {
    "objectID": "workflow_files_rstudio.html#in-rstudio",
    "href": "workflow_files_rstudio.html#in-rstudio",
    "title": "Workflow: Files and RStudio setup",
    "section": "In RStudio",
    "text": "In RStudio\n\nWhen you’re in the Console, hitting the up and down arrow keys allows you to cycle through previous commands\nTab completion\n\nType part of a function or object name (in the Editor or Console) and then hit Tab. A menu of autocomplete options will popup. Select your choice with arrow keys and hit Tab or Enter. (e.g., Type ggp and hit Tab.)\nType part of a function argument and then hit Tab for a menu of autocomplete options."
  },
  {
    "objectID": "workflow_files_rstudio.html#in-general-for-typing",
    "href": "workflow_files_rstudio.html#in-general-for-typing",
    "title": "Workflow: Files and RStudio setup",
    "section": "In general for typing",
    "text": "In general for typing\n\nMoving your cursor to the beginning/end of a word\n\nMac: Option + Left/Right\nWindows: Ctrl + Left/Right\n\nDeleting one word at a time\n\nMac: Option + Backspace\nWindows: Ctrl + Backspace\n\nMoving your cursor to the beginning/end of a line\n\nMac: Command + Left/Right\nWindows: Alt + Left/Right\n\nDeleting a whole line at a time\n\nMac: Command + Backspace\nWindows: Alt + Backspace"
  }
]